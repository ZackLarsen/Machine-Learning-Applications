{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC 478 Final Project - Zack Larsen\n",
    "\n",
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project goals:\n",
    "\n",
    "My goals in this project were to explore the dataset, determine appropriate uses of machine learning techniques to apply to the dataset, and apply those uses optimally by conducting a systematic search for the best parameters to use for each method. Also, for one method, I wanted to construct the application by hand instead of using a library such as scikit-learn or a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods used:\n",
    "\n",
    "After exploring the dataset, I found that I had information on 192 numerical attributes in addition to a categorical attribute (species of the leaf sample). Based on this information, I thought it would be appropriate to use classification methods to attempt to achieve the highest classification accuracy on the dataset. I also wanted to explore an unsupervised technique, and I chose KMeans clustering for that task. \n",
    "\n",
    "I performed KMeans clustering in two different approaches to evaluate the difference in results:\n",
    "\n",
    "1) KMeans clustering without normalization\n",
    "\n",
    "2) KMeans clustering with normalized and PCA dimensionality-reduced data\n",
    "\n",
    "\n",
    "\n",
    "I thought about using an estimation model such as multiple linear regression, but the numerical results would not have practical significance for this dataset. The target attribute of interest is the species of the leaf, which is categorical. I therefore decided against running multiple linear regression on the dataset. I did, however, use logistic regression for a classification task on the dataset. Logistic regression allows for the classification of a binary categorical class variable. I decided to perform this task using a binary variable that I constructed, named \"maple\". This value assumes a value of 1 for all species in the maple family of trees, and a 0 otherwise. My goal was to determine the classification accuracy of the model in separating the maple leaves from other families of tree leaves.\n",
    "\n",
    "\n",
    "The classification techniques that I used are as follows:\n",
    "\n",
    "1) LDA classification model built by hand\n",
    "\n",
    "2) LDA classification model via scikit-learn\n",
    "\n",
    "3) Decision Trees Classification with grid search\n",
    "\n",
    "4) Random Forest Classification\n",
    "\n",
    "5) Gradient-boosted regression trees\n",
    "\n",
    "6) Support Vector Machines Classification with grid search\n",
    "\n",
    "7) Logistic regression classification via scikit-learn with stochastic gradient descent\n",
    "\n",
    "8) Classification via scikit-learn with stochastic gradient descent AND grid search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions: for a detailed review of results and conclusions, please see the bottom of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zacklarsen/Desktop/Sandisk/DePaul/Past Classes/CSC 478/Project/Leaf classification kaggle data\n"
     ]
    }
   ],
   "source": [
    "cd /Users/zacklarsen/Desktop/Sandisk/DePaul/Past Classes/CSC 478/Project/Leaf classification kaggle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists approximately 1,584 images of leaf specimens (16 samples each of 99 species) which have been converted to binary black leaves against white backgrounds. Three sets of features are also provided per image: a shape contiguous descriptor, an interior texture histogram, and a ﬁne-scale margin histogram. For each feature, a 64-attribute vector is given per leaf sample.\n",
    "\n",
    "Data fields\n",
    "\n",
    "id - an anonymous id unique to an image\n",
    "margin_1, margin_2, margin_3, ..., margin_64 - each of the 64 attribute vectors for the margin feature\n",
    "shape_1, shape_2, shape_3, ..., shape_64 - each of the 64 attribute vectors for the shape feature\n",
    "texture_1, texture_2, texture_3, ..., texture_64 - each of the 64 attribute vectors for the texture feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "testDF = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.053711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.037109</td>\n",
       "      <td>0.044922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "0   4  0.019531  0.009766  0.078125  0.011719  0.003906  0.015625  0.005859   \n",
       "1   7  0.007812  0.005859  0.064453  0.009766  0.003906  0.013672  0.007812   \n",
       "\n",
       "   margin8   margin9    ...      texture55  texture56  texture57  texture58  \\\n",
       "0      0.0  0.005859    ...       0.006836        0.0   0.015625   0.000977   \n",
       "1      0.0  0.033203    ...       0.000000        0.0   0.006836   0.001953   \n",
       "\n",
       "   texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "0   0.015625        0.0        0.0   0.000000   0.003906   0.053711  \n",
       "1   0.013672        0.0        0.0   0.000977   0.037109   0.044922  \n",
       "\n",
       "[2 rows x 193 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                species   margin1   margin2   margin3   margin4  \\\n",
       "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "\n",
       "    margin5   margin6   margin7  margin8    ...      texture55  texture56  \\\n",
       "0  0.011719  0.009766  0.027344      0.0    ...       0.007812        0.0   \n",
       "1  0.025391  0.001953  0.019531      0.0    ...       0.000977        0.0   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0    0.00293   0.002930   0.035156        0.0        0.0   0.004883   \n",
       "1    0.00000   0.000977   0.023438        0.0        0.0   0.000977   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "\n",
       "[2 rows x 194 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "trainDF = pd.DataFrame(train)\n",
    "trainDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = trainDF['species']\n",
    "unique_classes =  set(target) # build a collection of unique elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_list = []\n",
    "for name in (unique_classes):\n",
    "    unique_list.append(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Populus_Nigra', 'Acer_Saccharinum', 'Quercus_Pontica', 'Alnus_Viridis', 'Olea_Europaea', 'Acer_Rufinerve', 'Acer_Rubrum', 'Cotinus_Coggygria', 'Quercus_Castaneifolia', 'Cornus_Macrophylla', 'Quercus_Pyrenaica', 'Quercus_Rubra', 'Quercus_Semecarpifolia', 'Quercus_Afares', 'Quercus_Pubescens', 'Acer_Pictum', 'Ginkgo_Biloba', 'Quercus_Suber', 'Quercus_x_Turneri', 'Salix_Fragilis', 'Alnus_Cordata', 'Quercus_Agrifolia', 'Sorbus_Aria', 'Acer_Opalus', 'Alnus_Maximowiczii', 'Tilia_Oliveri', 'Quercus_Trojana', 'Quercus_Phellos', 'Tilia_Tomentosa', 'Quercus_Greggii', 'Rhododendron_x_Russellianum', 'Quercus_Rhysophylla', 'Quercus_Crassifolia', 'Alnus_Sieboldiana', 'Castanea_Sativa', 'Callicarpa_Bodinieri', 'Quercus_Shumardii', 'Zelkova_Serrata', 'Eucalyptus_Urnigera', 'Liriodendron_Tulipifera', 'Fagus_Sylvatica', 'Betula_Austrosinensis', 'Crataegus_Monogyna', 'Populus_Adenopoda', 'Acer_Mono', 'Prunus_Avium', 'Acer_Circinatum', 'Magnolia_Heptapeta', 'Quercus_Texana', 'Ilex_Aquifolium', 'Lithocarpus_Cleistocarpus', 'Quercus_Coccifera', 'Quercus_Kewensis', 'Populus_Grandidentata', 'Cornus_Controversa', 'Quercus_Vulcanica', 'Cytisus_Battandieri', 'Celtis_Koraiensis', 'Acer_Capillipes', 'Quercus_Dolicholepis', 'Arundinaria_Simonii', 'Pterocarya_Stenoptera', 'Quercus_Canariensis', 'Alnus_Rubra', 'Quercus_Cerris', 'Quercus_Ellipsoidalis', 'Quercus_Palustris', 'Quercus_Ilex', 'Prunus_X_Shmittii', 'Quercus_Coccinea', 'Quercus_Variabilis', 'Lithocarpus_Edulis', 'Quercus_x_Hispanica', 'Magnolia_Salicifolia', 'Phildelphus', 'Acer_Platanoids', 'Tilia_Platyphyllos', 'Acer_Palmatum', 'Eucalyptus_Glaucescens', 'Ilex_Cornuta', 'Betula_Pendula', 'Cercis_Siliquastrum', 'Quercus_Phillyraeoides', 'Quercus_Alnifolia', 'Quercus_Brantii', 'Viburnum_x_Rhytidophylloides', 'Quercus_Chrysolepis', 'Quercus_Nigra', 'Morus_Nigra', 'Cornus_Chinensis', 'Ulmus_Bergmanniana', 'Liquidambar_Styraciflua', 'Eucalyptus_Neglecta', 'Quercus_Infectoria_sub', 'Quercus_Hartwissiana', 'Viburnum_Tinus', 'Quercus_Imbricaria', 'Quercus_Crassipes', 'Salix_Intergra']\n"
     ]
    }
   ],
   "source": [
    "print unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                species   margin1   margin2   margin3   margin4  \\\n",
      "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
      "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
      "2   3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
      "3   5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
      "4   6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
      "\n",
      "    margin5   margin6   margin7  margin8    ...      texture55  texture56  \\\n",
      "0  0.011719  0.009766  0.027344      0.0    ...       0.007812   0.000000   \n",
      "1  0.025391  0.001953  0.019531      0.0    ...       0.000977   0.000000   \n",
      "2  0.003906  0.005859  0.068359      0.0    ...       0.154300   0.000000   \n",
      "3  0.021484  0.019531  0.023438      0.0    ...       0.000000   0.000977   \n",
      "4  0.013672  0.015625  0.005859      0.0    ...       0.096680   0.000000   \n",
      "\n",
      "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
      "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
      "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
      "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
      "3   0.000000   0.000000   0.020508        0.0        0.0   0.017578   \n",
      "4   0.021484   0.000000   0.000000        0.0        0.0   0.000000   \n",
      "\n",
      "   texture63  texture64  \n",
      "0   0.000000   0.025391  \n",
      "1   0.039062   0.022461  \n",
      "2   0.020508   0.002930  \n",
      "3   0.000000   0.047852  \n",
      "4   0.000000   0.031250  \n",
      "\n",
      "[5 rows x 194 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(990, 194)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train.head()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
      "0   4  0.019531  0.009766  0.078125  0.011719  0.003906  0.015625  0.005859   \n",
      "1   7  0.007812  0.005859  0.064453  0.009766  0.003906  0.013672  0.007812   \n",
      "2   9  0.000000  0.000000  0.001953  0.021484  0.041016  0.000000  0.023438   \n",
      "3  12  0.000000  0.000000  0.009766  0.011719  0.017578  0.000000  0.003906   \n",
      "4  13  0.001953  0.000000  0.015625  0.009766  0.039062  0.000000  0.009766   \n",
      "\n",
      "   margin8   margin9    ...      texture55  texture56  texture57  texture58  \\\n",
      "0      0.0  0.005859    ...       0.006836   0.000000   0.015625   0.000977   \n",
      "1      0.0  0.033203    ...       0.000000   0.000000   0.006836   0.001953   \n",
      "2      0.0  0.011719    ...       0.128910   0.000000   0.000977   0.000000   \n",
      "3      0.0  0.003906    ...       0.012695   0.015625   0.002930   0.036133   \n",
      "4      0.0  0.005859    ...       0.000000   0.042969   0.016602   0.010742   \n",
      "\n",
      "   texture59  texture60  texture61  texture62  texture63  texture64  \n",
      "0   0.015625        0.0        0.0   0.000000   0.003906   0.053711  \n",
      "1   0.013672        0.0        0.0   0.000977   0.037109   0.044922  \n",
      "2   0.000000        0.0        0.0   0.015625   0.000000   0.000000  \n",
      "3   0.013672        0.0        0.0   0.089844   0.000000   0.008789  \n",
      "4   0.041016        0.0        0.0   0.007812   0.009766   0.007812  \n",
      "\n",
      "[5 rows x 193 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(594, 193)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print test.head()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We need to separate the target attribute, which is 'Species'\n",
    "target = trainDF['species']\n",
    "trainDF = trainDF.drop('species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Acer_Opalus\n",
       "1    Pterocarya_Stenoptera\n",
       "2     Quercus_Hartwissiana\n",
       "3          Tilia_Tomentosa\n",
       "4       Quercus_Variabilis\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>990.0</td>\n",
       "      <td>799.595960</td>\n",
       "      <td>452.477568</td>\n",
       "      <td>1.0</td>\n",
       "      <td>415.250000</td>\n",
       "      <td>802.500000</td>\n",
       "      <td>1195.500000</td>\n",
       "      <td>1584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin1</th>\n",
       "      <td>990.0</td>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.019739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.087891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin2</th>\n",
       "      <td>990.0</td>\n",
       "      <td>0.028539</td>\n",
       "      <td>0.038855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.205080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin3</th>\n",
       "      <td>990.0</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin4</th>\n",
       "      <td>990.0</td>\n",
       "      <td>0.023280</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.169920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std  min         25%         50%  \\\n",
       "id       990.0  799.595960  452.477568  1.0  415.250000  802.500000   \n",
       "margin1  990.0    0.017412    0.019739  0.0    0.001953    0.009766   \n",
       "margin2  990.0    0.028539    0.038855  0.0    0.001953    0.011719   \n",
       "margin3  990.0    0.031988    0.025847  0.0    0.013672    0.025391   \n",
       "margin4  990.0    0.023280    0.028411  0.0    0.005859    0.013672   \n",
       "\n",
       "                 75%          max  \n",
       "id       1195.500000  1584.000000  \n",
       "margin1     0.025391     0.087891  \n",
       "margin2     0.041016     0.205080  \n",
       "margin3     0.044922     0.156250  \n",
       "margin4     0.029297     0.169920  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.describe().T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 193)\n"
     ]
    }
   ],
   "source": [
    "print trainDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(trainDF)\n",
    "trainDF_norm = min_max_scaler.transform(trainDF)\n",
    "testDF_norm = min_max_scaler.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.       0.08888  0.11429 ...,  0.01299  0.       0.17931]\n",
      " [ 0.00063  0.06666  0.      ...,  0.0026   0.44943  0.15862]\n",
      " [ 0.00126  0.06666  0.04762 ...,  0.       0.23596  0.02069]\n",
      " ..., \n",
      " [ 0.9981   0.02222  0.01905 ...,  0.07273  0.       0.01379]\n",
      " [ 0.99874  0.       0.      ...,  0.       0.02247  0.02069]\n",
      " [ 1.       0.26667  0.09524 ...,  0.06234  0.29214  0.15862]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(990, 193)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=5,suppress=True)\n",
    "\n",
    "print trainDF_norm\n",
    "trainDF_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0019   0.22222  0.04762 ...,  0.       0.04494  0.37931]\n",
      " [ 0.00379  0.08888  0.02857 ...,  0.0026   0.42696  0.31725]\n",
      " [ 0.00505  0.       0.      ...,  0.04156  0.       0.     ]\n",
      " ..., \n",
      " [ 0.99684  0.2      0.14286 ...,  0.       0.49439  0.04828]\n",
      " [ 0.99747  0.15556  0.04762 ...,  0.       0.13483  0.13104]\n",
      " [ 0.99937  0.       0.57144 ...,  0.04156  0.       0.12414]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(594, 193)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=5,suppress=True)\n",
    "\n",
    "print testDF_norm\n",
    "testDF_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00063,  0.06666,  0.     ,  0.2    ,  0.09196,  0.22807,\n",
       "        0.00629,  0.21276,  0.     ,  0.     ,  0.08   ,  0.03125,\n",
       "        0.51853,  0.0603 ,  0.     ,  0.51515,  0.     ,  0.1613 ,\n",
       "        0.04274,  0.0625 ,  0.14814,  0.19231,  0.12499,  0.     ,\n",
       "        0.     ,  0.09523,  0.31818,  0.04762,  0.46341,  0.05263,\n",
       "        0.40984,  0.48277,  0.21539,  0.05   ,  0.     ,  0.     ,\n",
       "        0.04348,  0.2    ,  0.2361 ,  0.53125,  0.3125 ,  0.14954,\n",
       "        0.10639,  0.06666,  0.48485,  0.01099,  0.43478,  0.27778,\n",
       "        0.21052,  0.32728,  0.     ,  0.0597 ,  0.     ,  0.54545,\n",
       "        0.36363,  0.20833,  0.17858,  0.28125,  0.06896,  0.06035,\n",
       "        0.21739,  0.     ,  0.     ,  0.03125,  0.     ,  0.26171,\n",
       "        0.24312,  0.29103,  0.30455,  0.27298,  0.24606,  0.23994,\n",
       "        0.2142 ,  0.19241,  0.16368,  0.15922,  0.13577,  0.13202,\n",
       "        0.13107,  0.13678,  0.15038,  0.15903,  0.16947,  0.18256,\n",
       "        0.17819,  0.19448,  0.19401,  0.21486,  0.21182,  0.24974,\n",
       "        0.29755,  0.31657,  0.34829,  0.3769 ,  0.39366,  0.39523,\n",
       "        0.40141,  0.39689,  0.41733,  0.44057,  0.39269,  0.34178,\n",
       "        0.30113,  0.28216,  0.25566,  0.22088,  0.21302,  0.19388,\n",
       "        0.18973,  0.17468,  0.17526,  0.17003,  0.15891,  0.18036,\n",
       "        0.17743,  0.17324,  0.18417,  0.20296,  0.19993,  0.21632,\n",
       "        0.24371,  0.27422,  0.3043 ,  0.34459,  0.36801,  0.33565,\n",
       "        0.29314,  0.24827,  0.2564 ,  0.     ,  0.     ,  0.09999,\n",
       "        0.49092,  0.     ,  0.26667,  0.00599,  0.     ,  0.1393 ,\n",
       "        0.01333,  0.     ,  0.     ,  0.13274,  0.22222,  0.     ,\n",
       "        0.     ,  0.0199 ,  0.     ,  0.06818,  0.06863,  0.     ,\n",
       "        0.01099,  0.135  ,  0.15217,  0.33121,  0.00645,  0.09442,\n",
       "        0.03252,  0.12728,  0.27273,  0.27826,  0.     ,  0.08844,\n",
       "        0.     ,  0.25316,  0.     ,  0.00351,  0.01794,  0.10596,\n",
       "        0.02941,  0.25415,  0.     ,  0.34806,  0.01896,  0.06475,\n",
       "        0.07778,  0.11881,  0.00784,  0.32728,  0.03603,  0.     ,\n",
       "        0.     ,  0.32544,  0.13214,  0.00227,  0.     ,  0.     ,\n",
       "        0.00488,  0.22018,  0.     ,  0.     ,  0.0026 ,  0.44943,  0.15862])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF_norm[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 192)\n"
     ]
    }
   ],
   "source": [
    "viz = pd.read_csv(\"train.csv\")\n",
    "vizDF = pd.DataFrame(viz)\n",
    "vizDF = vizDF.iloc[:,1:]  #Getting rid of the id column. It is meaningless here because we want to take the mean of the attributes by class\n",
    "\n",
    "\n",
    "viz_MV_DF = pd.DataFrame(vizDF.groupby(['species']).mean())\n",
    "\n",
    "print viz_MV_DF.shape\n",
    "\n",
    "\n",
    "viz_MV_DF.reset_index(inplace=True)    #This reset_index gets rid of the first empty row and uses numerical indexing instead of species as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer_Capillipes</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.029492</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer_Circinatum</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer_Mono</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.015039</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.024609</td>\n",
       "      <td>0.026953</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.010352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>0.026953</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.028516</td>\n",
       "      <td>0.043164</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.028711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.027344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer_Palmatum</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.089453</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "0  Acer_Capillipes  0.001562  0.000391  0.017383  0.017578  0.035937   \n",
       "1  Acer_Circinatum  0.000195  0.000586  0.000977  0.016211  0.032227   \n",
       "2        Acer_Mono  0.021875  0.015039  0.032813  0.026367  0.003125   \n",
       "3      Acer_Opalus  0.014453  0.026953  0.035937  0.007422  0.008594   \n",
       "4    Acer_Palmatum  0.000195  0.000000  0.002930  0.040625  0.089453   \n",
       "\n",
       "    margin6   margin7   margin8   margin9    ...      texture55  texture56  \\\n",
       "0  0.001172  0.029492  0.000391  0.007422    ...       0.054981        0.0   \n",
       "1  0.000000  0.010156  0.000000  0.005664    ...       0.111817        0.0   \n",
       "2  0.024609  0.026953  0.000391  0.002148    ...       0.158303        0.0   \n",
       "3  0.028516  0.043164  0.000977  0.001562    ...       0.003906        0.0   \n",
       "4  0.000391  0.000781  0.001367  0.032227    ...       0.011914        0.0   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.008692   0.000000   0.016992        0.0        0.0   0.000293   \n",
       "1   0.005664   0.000781   0.006738        0.0        0.0   0.018457   \n",
       "2   0.021094   0.003320   0.005371        0.0        0.0   0.000879   \n",
       "3   0.005859   0.001074   0.028711        0.0        0.0   0.003125   \n",
       "4   0.104980   0.000000   0.000781        0.0        0.0   0.002344   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.024023   0.007813  \n",
       "1   0.000000   0.015137  \n",
       "2   0.000195   0.010352  \n",
       "3   0.002246   0.027344  \n",
       "4   0.000000   0.016699  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_MV_DF.head()     #This DF gives us the mean vector for all species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add an index column\n",
    "viz_MV_DF['index'] = np.linspace(0,98,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer_Capillipes</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.029492</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer_Circinatum</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "0  Acer_Capillipes  0.001562  0.000391  0.017383  0.017578  0.035937   \n",
       "1  Acer_Circinatum  0.000195  0.000586  0.000977  0.016211  0.032227   \n",
       "\n",
       "    margin6   margin7   margin8   margin9  ...    texture56  texture57  \\\n",
       "0  0.001172  0.029492  0.000391  0.007422  ...          0.0   0.008692   \n",
       "1  0.000000  0.010156  0.000000  0.005664  ...          0.0   0.005664   \n",
       "\n",
       "   texture58  texture59  texture60  texture61  texture62  texture63  \\\n",
       "0   0.000000   0.016992        0.0        0.0   0.000293   0.024023   \n",
       "1   0.000781   0.006738        0.0        0.0   0.018457   0.000000   \n",
       "\n",
       "   texture64  index  \n",
       "0   0.007813    0.0  \n",
       "1   0.015137    1.0  \n",
       "\n",
       "[2 rows x 194 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_MV_DF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmbWECcQMzNryP8HpICIHZDIwV8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117384f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = viz_MV_DF['index']\n",
    "y = viz_MV_DF['margin1']\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(X, y, align='center', alpha=0.5)\n",
    "\n",
    "plt.ylabel('Margin1 measurement')\n",
    "plt.title('Margin1 value for all species')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOIGYmVlD/j8c0BVljqUm3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aa8fc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sorting the x axis of the plot above by the value for y \n",
    "y = y.sort_values(ascending=0)\n",
    "\n",
    "plt.bar(X, y, align='center', alpha=0.5)\n",
    "\n",
    "plt.ylabel('Margin1 measurement')\n",
    "plt.title('Margin1 value for all species')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12035c390>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12052bc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make a scatterplot to see if the first two margin measurements are correlated\n",
    "plt.scatter(viz_MV_DF['margin1'],viz_MV_DF['margin2'], color=\"red\", marker=\"*\")\n",
    "plt.title('Scatter plot of the first two margin measurements')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11402e850>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAFsCAYAAADffY7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aeab750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing the mean margin 1 value for the top 10 species\n",
    "\n",
    "\n",
    "marginDF = train['margin1'].groupby(train['species']).mean()\n",
    "newDF = marginDF[1:10]\n",
    "newDF.sort_values(ascending=0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#my_plot = newDF.plot(kind='bar')\n",
    "\n",
    "my_plot = newDF.sort_values(ascending=False).plot(kind='bar',title=\"Mean margin 1 by species\")\n",
    "my_plot.set_xlabel(\"Species\")\n",
    "my_plot.set_ylabel(\"Margin 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11eb3bd10>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAFsCAYAAAAJ2FStAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e6d0d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing the mean shape 1 value for the top 10 species\n",
    "\n",
    "\n",
    "\n",
    "shapeDF = train['shape1'].groupby(train['species']).mean()\n",
    "newDF = shapeDF[1:10]\n",
    "newDF.sort_values(ascending=0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#my_plot = newDF.plot(kind='bar')\n",
    "\n",
    "my_plot = newDF.sort_values(ascending=False).plot(kind='bar',title=\"Mean shape 1 by species\")\n",
    "my_plot.set_xlabel(\"Species\")\n",
    "my_plot.set_ylabel(\"Shape 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11e49df90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAFsCAYAAADIXx4BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4MRgZmYN/x/igIQsbff9QgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1025b0e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing the mean texture 1 value for the top 10 species\n",
    "\n",
    "\n",
    "textureDF = train['texture1'].groupby(train['species']).mean()\n",
    "newDF = textureDF[1:10]\n",
    "newDF.sort_values(ascending=0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#my_plot = newDF.plot(kind='bar')\n",
    "\n",
    "my_plot = newDF.sort_values(ascending=False).plot(kind='bar',title=\"Mean texture 1 by species\")\n",
    "my_plot.set_xlabel(\"Species\")\n",
    "my_plot.set_ylabel(\"Texture 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It looks like from the above plots that species with the surname Acer have the highest values for the first measure of each attribute family (texture, shape, margin). This is the genus that contains all maple species. These visualizations might help us to understand that we can easily classify the maple species using the first measure of each attribute family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape2</th>\n",
       "      <th>shape3</th>\n",
       "      <th>shape4</th>\n",
       "      <th>shape5</th>\n",
       "      <th>shape6</th>\n",
       "      <th>shape7</th>\n",
       "      <th>shape8</th>\n",
       "      <th>shape9</th>\n",
       "      <th>shape10</th>\n",
       "      <th>shape11</th>\n",
       "      <th>...</th>\n",
       "      <th>shape56</th>\n",
       "      <th>shape57</th>\n",
       "      <th>shape58</th>\n",
       "      <th>shape59</th>\n",
       "      <th>shape60</th>\n",
       "      <th>shape61</th>\n",
       "      <th>shape62</th>\n",
       "      <th>shape63</th>\n",
       "      <th>shape64</th>\n",
       "      <th>texture1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     shape2    shape3    shape4    shape5    shape6    shape7    shape8  \\\n",
       "0  0.000609  0.000576  0.000553  0.000516  0.000496  0.000474  0.000453   \n",
       "1  0.000695  0.000720  0.000709  0.000688  0.000660  0.000624  0.000585   \n",
       "\n",
       "     shape9   shape10   shape11    ...      shape56   shape57   shape58  \\\n",
       "0  0.000454  0.000429  0.000418    ...     0.000434  0.000452  0.000471   \n",
       "1  0.000556  0.000531  0.000506    ...     0.000546  0.000574  0.000608   \n",
       "\n",
       "    shape59   shape60   shape61   shape62   shape63   shape64  texture1  \n",
       "0  0.000485  0.000512  0.000536  0.000553  0.000610  0.000661  0.049805  \n",
       "1  0.000641  0.000674  0.000703  0.000707  0.000688  0.000747  0.000000  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a dataframe of the shape columns\n",
    "\n",
    "shapes = trainDF.iloc[:,66:130]\n",
    "shapes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture2</th>\n",
       "      <th>texture3</th>\n",
       "      <th>texture4</th>\n",
       "      <th>texture5</th>\n",
       "      <th>texture6</th>\n",
       "      <th>texture7</th>\n",
       "      <th>texture8</th>\n",
       "      <th>texture9</th>\n",
       "      <th>texture10</th>\n",
       "      <th>texture11</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.079102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture2  texture3  texture4  texture5  texture6  texture7  texture8  \\\n",
       "0  0.017578  0.003906  0.024414  0.001953  0.010742  0.035156  0.007812   \n",
       "1  0.000000  0.007812  0.079102  0.000000  0.039062  0.000977  0.000000   \n",
       "\n",
       "   texture9  texture10  texture11    ...      texture55  texture56  texture57  \\\n",
       "0  0.039062   0.062500        0.0    ...       0.007812        0.0    0.00293   \n",
       "1  0.027344   0.003906        0.0    ...       0.000977        0.0    0.00000   \n",
       "\n",
       "   texture58  texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "0   0.002930   0.035156        0.0        0.0   0.004883   0.000000   0.025391  \n",
       "1   0.000977   0.023438        0.0        0.0   0.000977   0.039062   0.022461  \n",
       "\n",
       "[2 rows x 63 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a dataframe of the texture columns\n",
    "\n",
    "textures = trainDF.iloc[:,130:199]\n",
    "textures.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of two or more machine learning techniques on the data (e.g., classification, estimation, clustering, association rule discovery, etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "X_train = data.iloc[:,2:]\n",
    "target = data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "0  0.007812  0.023438  0.023438  0.003906  0.011719  0.009766  0.027344   \n",
       "1  0.005859  0.000000  0.031250  0.015625  0.025391  0.001953  0.019531   \n",
       "\n",
       "   margin8   margin9  margin10    ...      texture55  texture56  texture57  \\\n",
       "0      0.0  0.001953  0.033203    ...       0.007812        0.0    0.00293   \n",
       "1      0.0  0.000000  0.007812    ...       0.000977        0.0    0.00000   \n",
       "\n",
       "   texture58  texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "0   0.002930   0.035156        0.0        0.0   0.004883   0.000000   0.025391  \n",
       "1   0.000977   0.023438        0.0        0.0   0.000977   0.039062   0.022461  \n",
       "\n",
       "[2 rows x 192 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Acer_Opalus\n",
       "1    Pterocarya_Stenoptera\n",
       "2     Quercus_Hartwissiana\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=7, max_iter=500, verbose=1) # initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 88.716\n",
      "Iteration  1, inertia 61.819\n",
      "Iteration  2, inertia 59.600\n",
      "Iteration  3, inertia 59.061\n",
      "Iteration  4, inertia 58.819\n",
      "Iteration  5, inertia 58.649\n",
      "Iteration  6, inertia 58.520\n",
      "Iteration  7, inertia 58.357\n",
      "Iteration  8, inertia 58.103\n",
      "Iteration  9, inertia 58.003\n",
      "Iteration 10, inertia 57.945\n",
      "Iteration 11, inertia 57.915\n",
      "Iteration 12, inertia 57.900\n",
      "Iteration 13, inertia 57.883\n",
      "Iteration 14, inertia 57.859\n",
      "Iteration 15, inertia 57.845\n",
      "Iteration 16, inertia 57.838\n",
      "Iteration 17, inertia 57.834\n",
      "Iteration 18, inertia 57.833\n",
      "Converged at iteration 18\n",
      "Initialization complete\n",
      "Iteration  0, inertia 88.546\n",
      "Iteration  1, inertia 61.117\n",
      "Iteration  2, inertia 58.521\n",
      "Iteration  3, inertia 57.277\n",
      "Iteration  4, inertia 56.728\n",
      "Iteration  5, inertia 56.405\n",
      "Iteration  6, inertia 56.311\n",
      "Iteration  7, inertia 56.264\n",
      "Iteration  8, inertia 56.196\n",
      "Iteration  9, inertia 56.133\n",
      "Iteration 10, inertia 56.114\n",
      "Iteration 11, inertia 56.108\n",
      "Iteration 12, inertia 56.106\n",
      "Iteration 13, inertia 56.105\n",
      "Converged at iteration 13\n",
      "Initialization complete\n",
      "Iteration  0, inertia 83.255\n",
      "Iteration  1, inertia 59.996\n",
      "Iteration  2, inertia 59.364\n",
      "Iteration  3, inertia 58.967\n",
      "Iteration  4, inertia 58.785\n",
      "Iteration  5, inertia 58.715\n",
      "Iteration  6, inertia 58.627\n",
      "Iteration  7, inertia 58.569\n",
      "Iteration  8, inertia 58.524\n",
      "Iteration  9, inertia 58.450\n",
      "Iteration 10, inertia 58.300\n",
      "Iteration 11, inertia 58.070\n",
      "Iteration 12, inertia 57.726\n",
      "Iteration 13, inertia 57.276\n",
      "Iteration 14, inertia 57.003\n",
      "Iteration 15, inertia 56.882\n",
      "Iteration 16, inertia 56.779\n",
      "Iteration 17, inertia 56.690\n",
      "Iteration 18, inertia 56.585\n",
      "Iteration 19, inertia 56.470\n",
      "Iteration 20, inertia 56.429\n",
      "Iteration 21, inertia 56.377\n",
      "Iteration 22, inertia 56.319\n",
      "Iteration 23, inertia 56.247\n",
      "Iteration 24, inertia 56.191\n",
      "Iteration 25, inertia 56.129\n",
      "Iteration 26, inertia 56.100\n",
      "Iteration 27, inertia 56.050\n",
      "Iteration 28, inertia 56.022\n",
      "Iteration 29, inertia 56.001\n",
      "Iteration 30, inertia 55.972\n",
      "Iteration 31, inertia 55.942\n",
      "Iteration 32, inertia 55.918\n",
      "Iteration 33, inertia 55.896\n",
      "Iteration 34, inertia 55.864\n",
      "Iteration 35, inertia 55.854\n",
      "Iteration 36, inertia 55.849\n",
      "Iteration 37, inertia 55.848\n",
      "Iteration 38, inertia 55.846\n",
      "Iteration 39, inertia 55.844\n",
      "Converged at iteration 39\n",
      "Initialization complete\n",
      "Iteration  0, inertia 87.218\n",
      "Iteration  1, inertia 58.344\n",
      "Iteration  2, inertia 56.666\n",
      "Iteration  3, inertia 55.948\n",
      "Iteration  4, inertia 55.774\n",
      "Iteration  5, inertia 55.688\n",
      "Iteration  6, inertia 55.668\n",
      "Iteration  7, inertia 55.657\n",
      "Iteration  8, inertia 55.651\n",
      "Iteration  9, inertia 55.647\n",
      "Iteration 10, inertia 55.636\n",
      "Iteration 11, inertia 55.622\n",
      "Iteration 12, inertia 55.610\n",
      "Iteration 13, inertia 55.607\n",
      "Iteration 14, inertia 55.607\n",
      "Converged at iteration 14\n",
      "Initialization complete\n",
      "Iteration  0, inertia 94.864\n",
      "Iteration  1, inertia 60.412\n",
      "Iteration  2, inertia 58.047\n",
      "Iteration  3, inertia 57.589\n",
      "Iteration  4, inertia 57.431\n",
      "Iteration  5, inertia 57.335\n",
      "Iteration  6, inertia 57.252\n",
      "Iteration  7, inertia 57.166\n",
      "Iteration  8, inertia 57.093\n",
      "Iteration  9, inertia 57.061\n",
      "Iteration 10, inertia 57.046\n",
      "Iteration 11, inertia 57.027\n",
      "Iteration 12, inertia 57.010\n",
      "Iteration 13, inertia 56.970\n",
      "Iteration 14, inertia 56.868\n",
      "Iteration 15, inertia 56.795\n",
      "Iteration 16, inertia 56.761\n",
      "Iteration 17, inertia 56.713\n",
      "Iteration 18, inertia 56.657\n",
      "Iteration 19, inertia 56.530\n",
      "Iteration 20, inertia 56.113\n",
      "Iteration 21, inertia 55.810\n",
      "Iteration 22, inertia 55.727\n",
      "Iteration 23, inertia 55.674\n",
      "Iteration 24, inertia 55.663\n",
      "Iteration 25, inertia 55.657\n",
      "Iteration 26, inertia 55.653\n",
      "Iteration 27, inertia 55.649\n",
      "Iteration 28, inertia 55.645\n",
      "Iteration 29, inertia 55.638\n",
      "Iteration 30, inertia 55.632\n",
      "Iteration 31, inertia 55.627\n",
      "Iteration 32, inertia 55.623\n",
      "Iteration 33, inertia 55.622\n",
      "Iteration 34, inertia 55.617\n",
      "Iteration 35, inertia 55.616\n",
      "Iteration 36, inertia 55.615\n",
      "Iteration 37, inertia 55.614\n",
      "Iteration 38, inertia 55.613\n",
      "Iteration 39, inertia 55.602\n",
      "Iteration 40, inertia 55.595\n",
      "Iteration 41, inertia 55.584\n",
      "Iteration 42, inertia 55.576\n",
      "Iteration 43, inertia 55.566\n",
      "Iteration 44, inertia 55.549\n",
      "Iteration 45, inertia 55.536\n",
      "Iteration 46, inertia 55.521\n",
      "Iteration 47, inertia 55.516\n",
      "Iteration 48, inertia 55.515\n",
      "Iteration 49, inertia 55.512\n",
      "Iteration 50, inertia 55.510\n",
      "Converged at iteration 50\n",
      "Initialization complete\n",
      "Iteration  0, inertia 84.071\n",
      "Iteration  1, inertia 58.069\n",
      "Iteration  2, inertia 56.695\n",
      "Iteration  3, inertia 56.448\n",
      "Iteration  4, inertia 56.319\n",
      "Iteration  5, inertia 56.244\n",
      "Iteration  6, inertia 56.170\n",
      "Iteration  7, inertia 56.118\n",
      "Iteration  8, inertia 56.061\n",
      "Iteration  9, inertia 56.004\n",
      "Iteration 10, inertia 55.914\n",
      "Iteration 11, inertia 55.810\n",
      "Iteration 12, inertia 55.720\n",
      "Iteration 13, inertia 55.558\n",
      "Iteration 14, inertia 55.304\n",
      "Iteration 15, inertia 54.884\n",
      "Iteration 16, inertia 54.752\n",
      "Iteration 17, inertia 54.667\n",
      "Iteration 18, inertia 54.551\n",
      "Iteration 19, inertia 54.454\n",
      "Iteration 20, inertia 54.402\n",
      "Iteration 21, inertia 54.345\n",
      "Iteration 22, inertia 54.283\n",
      "Iteration 23, inertia 54.261\n",
      "Iteration 24, inertia 54.239\n",
      "Iteration 25, inertia 54.226\n",
      "Iteration 26, inertia 54.217\n",
      "Iteration 27, inertia 54.210\n",
      "Iteration 28, inertia 54.201\n",
      "Iteration 29, inertia 54.191\n",
      "Iteration 30, inertia 54.185\n",
      "Iteration 31, inertia 54.180\n",
      "Iteration 32, inertia 54.176\n",
      "Iteration 33, inertia 54.175\n",
      "Iteration 34, inertia 54.174\n",
      "Converged at iteration 34\n",
      "Initialization complete\n",
      "Iteration  0, inertia 93.236\n",
      "Iteration  1, inertia 64.188\n",
      "Iteration  2, inertia 61.054\n",
      "Iteration  3, inertia 59.604\n",
      "Iteration  4, inertia 58.579\n",
      "Iteration  5, inertia 58.073\n",
      "Iteration  6, inertia 57.737\n",
      "Iteration  7, inertia 57.569\n",
      "Iteration  8, inertia 57.413\n",
      "Iteration  9, inertia 57.297\n",
      "Iteration 10, inertia 57.204\n",
      "Iteration 11, inertia 57.097\n",
      "Iteration 12, inertia 56.977\n",
      "Iteration 13, inertia 56.938\n",
      "Iteration 14, inertia 56.912\n",
      "Iteration 15, inertia 56.889\n",
      "Iteration 16, inertia 56.873\n",
      "Iteration 17, inertia 56.844\n",
      "Iteration 18, inertia 56.828\n",
      "Iteration 19, inertia 56.823\n",
      "Iteration 20, inertia 56.812\n",
      "Iteration 21, inertia 56.788\n",
      "Iteration 22, inertia 56.748\n",
      "Iteration 23, inertia 56.680\n",
      "Iteration 24, inertia 56.572\n",
      "Iteration 25, inertia 56.438\n",
      "Iteration 26, inertia 56.349\n",
      "Iteration 27, inertia 56.241\n",
      "Iteration 28, inertia 56.153\n",
      "Iteration 29, inertia 56.077\n",
      "Iteration 30, inertia 55.998\n",
      "Iteration 31, inertia 55.962\n",
      "Iteration 32, inertia 55.950\n",
      "Iteration 33, inertia 55.948\n",
      "Iteration 34, inertia 55.944\n",
      "Iteration 35, inertia 55.941\n",
      "Iteration 36, inertia 55.938\n",
      "Iteration 37, inertia 55.937\n",
      "Converged at iteration 37\n",
      "Initialization complete\n",
      "Iteration  0, inertia 84.764\n",
      "Iteration  1, inertia 58.896\n",
      "Iteration  2, inertia 56.364\n",
      "Iteration  3, inertia 55.519\n",
      "Iteration  4, inertia 55.156\n",
      "Iteration  5, inertia 54.806\n",
      "Iteration  6, inertia 54.703\n",
      "Iteration  7, inertia 54.651\n",
      "Iteration  8, inertia 54.645\n",
      "Iteration  9, inertia 54.642\n",
      "Iteration 10, inertia 54.640\n",
      "Converged at iteration 10\n",
      "Initialization complete\n",
      "Iteration  0, inertia 87.462\n",
      "Iteration  1, inertia 60.828\n",
      "Iteration  2, inertia 58.038\n",
      "Iteration  3, inertia 57.508\n",
      "Iteration  4, inertia 57.291\n",
      "Iteration  5, inertia 57.091\n",
      "Iteration  6, inertia 56.961\n",
      "Iteration  7, inertia 56.755\n",
      "Iteration  8, inertia 56.509\n",
      "Iteration  9, inertia 56.399\n",
      "Iteration 10, inertia 56.270\n",
      "Iteration 11, inertia 56.139\n",
      "Iteration 12, inertia 56.007\n",
      "Iteration 13, inertia 55.933\n",
      "Iteration 14, inertia 55.897\n",
      "Iteration 15, inertia 55.878\n",
      "Iteration 16, inertia 55.863\n",
      "Iteration 17, inertia 55.850\n",
      "Iteration 18, inertia 55.834\n",
      "Iteration 19, inertia 55.816\n",
      "Iteration 20, inertia 55.783\n",
      "Iteration 21, inertia 55.756\n",
      "Iteration 22, inertia 55.733\n",
      "Iteration 23, inertia 55.722\n",
      "Iteration 24, inertia 55.711\n",
      "Iteration 25, inertia 55.669\n",
      "Iteration 26, inertia 55.633\n",
      "Iteration 27, inertia 55.623\n",
      "Iteration 28, inertia 55.615\n",
      "Iteration 29, inertia 55.608\n",
      "Iteration 30, inertia 55.575\n",
      "Iteration 31, inertia 55.546\n",
      "Iteration 32, inertia 55.474\n",
      "Iteration 33, inertia 55.333\n",
      "Iteration 34, inertia 55.107\n",
      "Iteration 35, inertia 54.654\n",
      "Iteration 36, inertia 54.472\n",
      "Iteration 37, inertia 54.360\n",
      "Iteration 38, inertia 54.267\n",
      "Iteration 39, inertia 54.217\n",
      "Iteration 40, inertia 54.187\n",
      "Iteration 41, inertia 54.169\n",
      "Iteration 42, inertia 54.165\n",
      "Iteration 43, inertia 54.163\n",
      "Iteration 44, inertia 54.162\n",
      "Converged at iteration 44\n",
      "Initialization complete\n",
      "Iteration  0, inertia 79.229\n",
      "Iteration  1, inertia 56.804\n",
      "Iteration  2, inertia 56.064\n",
      "Iteration  3, inertia 55.882\n",
      "Iteration  4, inertia 55.765\n",
      "Iteration  5, inertia 55.725\n",
      "Iteration  6, inertia 55.697\n",
      "Iteration  7, inertia 55.657\n",
      "Iteration  8, inertia 55.626\n",
      "Iteration  9, inertia 55.603\n",
      "Iteration 10, inertia 55.582\n",
      "Iteration 11, inertia 55.573\n",
      "Iteration 12, inertia 55.569\n",
      "Iteration 13, inertia 55.567\n",
      "Converged at iteration 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=500, n_clusters=7, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=1)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = kmeans.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 6 4 6 3 6 6 4 1 4 1 6 4 1 4 4 3 4 1 4 6 1 1 2 4 0 2 4 3 2 1 4 0 6 4 4\n",
      " 2 6 1 6 6 6 1 2 6 1 4 6 6 6 4 6 4 4 4 0 2 0 6 1 0 3 0 4 6 6 6 3 6 2 3 3 4\n",
      " 6 2 4 4 6 1 6 1 6 6 3 2 1 6 3 6 6 6 4 6 6 5 6 6 2 6 6 6 1 4 4 6 6 6 2 4 2\n",
      " 6 4 3 6 6 4 4 2 1 6 2 6 3 2 4 6 4 3 2 6 3 0 1 4 2 2 4 4 4 6 3 6 2 6 3 1 3\n",
      " 4 4 6 2 2 1 6 4 2 2 6 6 2 4 5 6 3 2 4 2 5 6 2 4 6 2 2 4 2 3 1 1 4 4 4 6 6\n",
      " 3 2 5 6 2 6 4 6 6 1 3 4 3 5 2 1 0 6 0 2 6 4 6 6 6 1 3 2 6 2 6 6 4 5 1 1 1\n",
      " 1 1 6 6 1 4 6 0 6 4 6 1 4 2 1 3 4 2 6 4 0 2 2 3 4 5 6 6 4 1 6 2 1 1 2 2 1\n",
      " 4 6 2 1 6 6 4 6 4 6 6 4 2 6 4 2 5 6 0 4 6 0 6 2 2 1 2 6 6 4 1 4 1 4 6 4 1\n",
      " 3 6 4 6 1 4 6 2 6 3 2 0 4 6 4 6 6 2 0 4 6 2 4 4 4 2 0 2 6 6 4 2 0 4 0 0 4\n",
      " 4 4 4 2 1 1 4 1 4 2 6 6 6 3 6 6 0 2 3 6 6 4 2 2 6 4 6 4 6 2 1 3 4 4 6 2 4\n",
      " 6 2 5 2 4 2 4 0 2 4 6 4 0 0 0 4 4 2 1 1 6 4 6 1 4 4 6 6 6 5 6 4 1 2 1 4 4\n",
      " 4 4 1 4 5 1 2 2 6 6 4 2 0 2 6 6 4 4 2 0 0 1 6 4 5 6 6 6 1 4 1 4 2 6 2 2 6\n",
      " 0 4 2 4 1 2 1 0 1 4 2 1 3 3 2 2 6 4 1 2 1 4 2 4 6 4 4 6 1 4 2 2 6 6 1 0 6\n",
      " 0 4 4 4 2 1 1 2 2 2 1 2 6 6 1 1 4 4 4 2 6 2 2 0 6 6 5 6 6 6 4 6 3 0 2 2 2\n",
      " 4 0 6 2 1 6 4 6 4 4 6 2 1 2 6 4 6 4 6 4 6 0 6 1 1 2 6 6 0 2 0 1 1 4 4 2 2\n",
      " 4 4 4 6 1 0 4 6 1 1 6 6 2 4 0 2 3 0 6 2 6 6 2 6 4 1 0 6 4 0 4 4 2 5 2 6 0\n",
      " 6 2 4 4 6 6 4 4 4 4 6 4 0 3 6 6 3 0 0 6 5 1 2 4 1 6 4 0 1 4 4 4 6 1 4 5 6\n",
      " 2 4 6 4 4 6 1 3 0 6 4 6 0 4 4 4 6 4 4 6 1 4 1 2 4 2 2 6 2 1 3 6 0 4 2 6 5\n",
      " 2 4 5 4 4 0 4 5 0 1 2 6 4 3 6 3 6 6 6 2 6 0 6 2 4 1 6 2 6 0 4 1 1 6 1 1 4\n",
      " 6 3 2 4 4 1 4 4 2 0 2 2 1 6 0 4 4 4 1 1 0 4 4 6 2 6 6 4 4 4 6 1 4 2 6 6 2\n",
      " 6 2 6 3 6 1 6 4 4 2 2 4 2 0 0 1 4 2 4 4 2 4 4 1 4 4 6 1 4 1 1 2 2 6 0 4 0\n",
      " 1 2 0 4 4 1 2 1 4 6 1 4 3 1 4 4 6 6 4 6 4 6 2 4 0 6 1 3 5 0 1 6 4 1 4 1 4\n",
      " 1 4 4 1 4 4 6 4 4 1 4 6 0 4 0 6 4 4 1 4 4 6 4 2 2 3 2 1 3 3 0 4 1 4 6 6 2\n",
      " 2 6 4 3 6 2 4 4 6 2 6 2 1 2 2 2 0 3 1 5 2 1 1 2 1 4 1 2 4 6 4 4 4 6 6 1 6\n",
      " 4 6 2 6 4 6 3 4 4 6 6 1 6 1 4 4 2 6 6 2 1 2 3 6 4 2 4 1 0 1 2 6 4 5 6 4 2\n",
      " 2 0 2 4 0 0 6 3 4 4 4 6 4 6 4 6 6 4 0 6 0 6 6 6 6 0 6 2 4 6 6 6 6 6 6 4 0\n",
      " 4 6 4 4 0 1 3 1 4 6 6 6 2 0 6 4 1 4 4 1 2 2 2 3 6 1 6 4]\n"
     ]
    }
   ],
   "source": [
    "print clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01442  0.01803  0.02942 ...,  0.02519  0.01138  0.00224]\n",
      " [ 0.013    0.01893  0.02375 ...,  0.08411  0.00917  0.00516]\n",
      " [ 0.04464  0.08928  0.01669 ...,  0.0084   0.00724  0.02339]\n",
      " ..., \n",
      " [ 0.01268  0.01708  0.03805 ...,  0.00852  0.01097  0.03167]\n",
      " [ 0.02654  0.05238  0.02974 ...,  0.05176  0.00182 -0.     ]\n",
      " [ 0.00683  0.00734  0.04181 ...,  0.00642  0.00955  0.02082]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=5,suppress=True)\n",
    "print centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t  Species Name\tCluster 0\tCluster 1\n",
      "                   Acer_Opalus\t0.01442303\t0.01299685\n",
      "         Pterocarya_Stenoptera\t0.01802882\t0.01892803\n",
      "          Quercus_Hartwissiana\t0.02942200\t0.02375344\n",
      "               Tilia_Tomentosa\t0.02356269\t0.01901418\n",
      "            Quercus_Variabilis\t0.01727760\t0.02866499\n",
      "          Magnolia_Salicifolia\t0.03470545\t0.02516087\n",
      "           Quercus_Canariensis\t0.01727762\t0.02113964\n",
      "                 Quercus_Rubra\t0.00180282\t0.00089035\n",
      "               Quercus_Brantii\t0.00555874\t0.00521292\n",
      "                Salix_Fragilis\t0.01735272\t0.01845413\n",
      "               Zelkova_Serrata\t0.02238581\t0.01685999\n",
      "         Betula_Austrosinensis\t0.01752797\t0.01585471\n",
      "               Quercus_Pontica\t0.02631705\t0.02534749\n",
      "                Quercus_Afares\t0.00578418\t0.00578746\n",
      "             Quercus_Coccifera\t0.02296167\t0.02063703\n",
      "               Fagus_Sylvatica\t0.00022536\t0.00025850\n",
      "                   Phildelphus\t0.01459831\t0.01437555\n",
      "                 Acer_Palmatum\t0.01647629\t0.01414572\n",
      "             Quercus_Pubescens\t0.00979067\t0.01041181\n",
      "             Populus_Adenopoda\t0.01489879\t0.01273829\n",
      "               Quercus_Trojana\t0.02060795\t0.01882749\n",
      "            Quercus_Variabilis\t0.00836335\t0.00871719\n",
      "             Alnus_Sieboldiana\t0.00090144\t0.00077550\n",
      "                  Quercus_Ilex\t0.00888917\t0.00567258\n",
      "           Arundinaria_Simonii\t0.00921467\t0.01542392\n",
      "               Acer_Platanoids\t0.02196015\t0.02270512\n",
      "        Quercus_Phillyraeoides\t0.00608471\t0.00840125\n",
      "              Cornus_Chinensis\t0.01855462\t0.02057956\n",
      "        Quercus_Phillyraeoides\t0.02343746\t0.01828174\n",
      "               Fagus_Sylvatica\t0.02125904\t0.02215932\n",
      "       Liriodendron_Tulipifera\t0.01494885\t0.02439965\n",
      "           Cytisus_Battandieri\t0.00996592\t0.02620917\n",
      "               Tilia_Tomentosa\t0.02035751\t0.01693176\n",
      "   Rhododendron_x_Russellianum\t0.00107667\t0.00081854\n",
      "                   Alnus_Rubra\t0.01166864\t0.01131660\n",
      "        Eucalyptus_Glaucescens\t0.01369685\t0.01263783\n",
      "           Cercis_Siliquastrum\t0.01752806\t0.01370052\n",
      "             Cotinus_Coggygria\t0.03352864\t0.03364830\n",
      "             Celtis_Koraiensis\t0.02110872\t0.01967482\n",
      "           Quercus_Crassifolia\t0.01119283\t0.01459096\n",
      "            Quercus_Variabilis\t0.01387215\t0.02169971\n",
      "          Quercus_Hartwissiana\t0.01529941\t0.01193409\n",
      "              Quercus_Kewensis\t0.02073310\t0.01125912\n",
      "             Quercus_Coccifera\t0.01600062\t0.01884189\n",
      "            Cornus_Controversa\t0.02594142\t0.01628551\n",
      "             Quercus_Pyrenaica\t0.01312095\t0.01967480\n",
      "          Callicarpa_Bodinieri\t0.02824514\t0.03004362\n",
      "             Quercus_Alnifolia\t0.03130003\t0.02539062\n",
      "           Quercus_Canariensis\t0.01016623\t0.02013442\n",
      "              Acer_Saccharinum\t0.01497390\t0.01268089\n",
      "             Prunus_X_Shmittii\t0.01737773\t0.01723341\n",
      "                  Prunus_Avium\t0.00295465\t0.00159402\n",
      "               Quercus_Greggii\t0.02559095\t0.02886606\n",
      "                 Quercus_Suber\t0.01352155\t0.02142695\n",
      "               Quercus_Trojana\t0.01692705\t0.01961737\n",
      "       Liriodendron_Tulipifera\t0.00898935\t0.00939221\n",
      "             Quercus_Coccifera\t0.01467340\t0.01273834\n",
      "           Cercis_Siliquastrum\t0.01988178\t0.01282446\n",
      "                 Quercus_Suber\t0.02421372\t0.01960298\n",
      "             Celtis_Koraiensis\t0.00941499\t0.01299677\n",
      "          Quercus_Dolicholepis\t0.00125194\t0.00137860\n",
      "   Rhododendron_x_Russellianum\t0.00495791\t0.00508380\n",
      "                  Ilex_Cornuta\t0.02145927\t0.01970355\n",
      "                 Tilia_Oliveri\t0.00440696\t0.00348971\n",
      "        Quercus_Semecarpifolia\t0.00080947\t0.00075923\n",
      "                Quercus_Texana\t0.00078708\t0.00074143\n",
      "             Celtis_Koraiensis\t0.00076411\t0.00072257\n",
      "                 Ginkgo_Biloba\t0.00074252\t0.00070071\n",
      "                 Acer_Palmatum\t0.00071966\t0.00067940\n",
      "            Quercus_Variabilis\t0.00070138\t0.00065860\n",
      "       Liriodendron_Tulipifera\t0.00068345\t0.00064242\n",
      "       Liquidambar_Styraciflua\t0.00066701\t0.00062697\n",
      "               Quercus_Phellos\t0.00065126\t0.00060949\n",
      "           Quercus_Crassifolia\t0.00063759\t0.00059454\n",
      "             Quercus_Palustris\t0.00062846\t0.00058152\n",
      "               Quercus_Phellos\t0.00061885\t0.00057447\n",
      "             Quercus_Alnifolia\t0.00060942\t0.00057106\n",
      "                Quercus_Afares\t0.00060309\t0.00056747\n",
      "           Quercus_Canariensis\t0.00059973\t0.00056404\n",
      "            Alnus_Maximowiczii\t0.00059348\t0.00056002\n",
      "             Quercus_Agrifolia\t0.00058402\t0.00055832\n",
      "          Callicarpa_Bodinieri\t0.00056698\t0.00056023\n",
      "                  Prunus_Avium\t0.00055526\t0.00056244\n",
      "                   Acer_Pictum\t0.00055112\t0.00056297\n",
      "                Acer_Rufinerve\t0.00055574\t0.00056938\n",
      "     Lithocarpus_Cleistocarpus\t0.00056354\t0.00058042\n",
      "  Viburnum_x_Rhytidophylloides\t0.00057431\t0.00059351\n",
      "             Celtis_Koraiensis\t0.00058692\t0.00060871\n",
      "               Ilex_Aquifolium\t0.00059957\t0.00062682\n",
      "               Acer_Circinatum\t0.00061499\t0.00064802\n",
      "              Quercus_Coccinea\t0.00063486\t0.00066919\n",
      "               Acer_Circinatum\t0.00066050\t0.00069256\n",
      "                Quercus_Cerris\t0.00068867\t0.00071694\n",
      "               Acer_Circinatum\t0.00071961\t0.00074441\n",
      "              Acer_Saccharinum\t0.00075124\t0.00076734\n",
      "           Quercus_Chrysolepis\t0.00078273\t0.00078844\n",
      "             Celtis_Koraiensis\t0.00078619\t0.00079056\n",
      "        Quercus_Semecarpifolia\t0.00075877\t0.00076397\n",
      "           Eucalyptus_Neglecta\t0.00072812\t0.00073252\n",
      "         Betula_Austrosinensis\t0.00070252\t0.00070441\n",
      "                 Ginkgo_Biloba\t0.00068050\t0.00067912\n",
      "           Quercus_Canariensis\t0.00065983\t0.00065475\n",
      "            Tilia_Platyphyllos\t0.00063858\t0.00063342\n",
      "                 Alnus_Cordata\t0.00062413\t0.00061562\n",
      "                 Populus_Nigra\t0.00061628\t0.00059997\n",
      "              Quercus_Coccinea\t0.00060633\t0.00058906\n",
      "            Quercus_Variabilis\t0.00059605\t0.00058175\n",
      "             Quercus_Pyrenaica\t0.00058689\t0.00057298\n",
      "           Arundinaria_Simonii\t0.00057947\t0.00056670\n",
      "                 Alnus_Cordata\t0.00057297\t0.00056200\n",
      "           Arundinaria_Simonii\t0.00057083\t0.00055814\n",
      "               Acer_Capillipes\t0.00057238\t0.00055703\n",
      "              Quercus_Kewensis\t0.00056965\t0.00056104\n",
      "                 Acer_Palmatum\t0.00056343\t0.00056519\n",
      "             Quercus_Agrifolia\t0.00055698\t0.00057006\n",
      "             Quercus_Agrifolia\t0.00055797\t0.00057347\n",
      "               Tilia_Tomentosa\t0.00056127\t0.00058015\n",
      "       Liriodendron_Tulipifera\t0.00056174\t0.00058852\n",
      "            Magnolia_Heptapeta\t0.00056956\t0.00059477\n",
      "          Quercus_Dolicholepis\t0.00058158\t0.00060474\n",
      "                     Acer_Mono\t0.00059838\t0.00061870\n",
      "            Cornus_Macrophylla\t0.00061989\t0.00063677\n",
      "            Crataegus_Monogyna\t0.00064472\t0.00065384\n",
      "       Liquidambar_Styraciflua\t0.00067023\t0.00067273\n",
      "             Cotinus_Coggygria\t0.00070061\t0.00069429\n",
      "             Quercus_x_Turneri\t0.00073496\t0.00071643\n",
      "               Acer_Capillipes\t0.00076951\t0.00073718\n",
      "         Quercus_Castaneifolia\t0.00079995\t0.00075764\n",
      "                  Ilex_Cornuta\t0.00192810\t0.00185980\n",
      "            Lithocarpus_Edulis\t0.00257922\t0.00619692\n",
      "               Acer_Circinatum\t0.00028800\t0.00302304\n",
      "         Populus_Grandidentata\t0.03915026\t0.01252297\n",
      "                   Acer_Rubrum\t0.00002504\t0.00503362\n",
      "            Tilia_Platyphyllos\t0.00772491\t0.01116585\n",
      "                Quercus_Cerris\t0.00219108\t0.00499053\n",
      "            Lithocarpus_Edulis\t0.00036310\t0.00508387\n",
      "           Cercis_Siliquastrum\t0.00893933\t0.02261172\n",
      "             Quercus_Agrifolia\t0.05766749\t0.00417192\n",
      "             Quercus_Pubescens\t0.01287064\t0.07122456\n",
      "                 Quercus_Suber\t-0.00000000\t0.00071807\n",
      "               Quercus_Pontica\t0.00678587\t0.00366217\n",
      "               Ilex_Aquifolium\t0.00984069\t0.02127615\n",
      "             Celtis_Koraiensis\t0.00444463\t0.02615181\n",
      "     Lithocarpus_Cleistocarpus\t0.01081733\t0.00137151\n",
      "              Acer_Saccharinum\t0.00508321\t0.01445470\n",
      "          Magnolia_Salicifolia\t0.00086390\t0.00132845\n",
      "           Quercus_Crassifolia\t0.03609528\t0.01925845\n",
      "               Fagus_Sylvatica\t0.00150247\t0.00447351\n",
      "               Quercus_Trojana\t0.00072617\t0.00010053\n",
      "                Quercus_Afares\t0.00371845\t0.03374171\n",
      "             Quercus_Palustris\t0.00413164\t0.00417915\n",
      "            Quercus_Imbricaria\t0.03131262\t0.01937334\n",
      "           Eucalyptus_Urnigera\t0.01204426\t0.00460998\n",
      "                  Quercus_Ilex\t0.06128577\t0.08471673\n",
      "               Acer_Circinatum\t0.00418168\t0.00258506\n",
      "                   Phildelphus\t0.00015024\t0.00211830\n",
      "             Quercus_Crassipes\t0.01169372\t0.04303331\n",
      "            Cornus_Controversa\t0.00583433\t0.00396376\n",
      "          Quercus_Hartwissiana\t0.01742792\t0.03242039\n",
      "            Quercus_Variabilis\t0.00027546\t0.01129512\n",
      "             Quercus_x_Turneri\t0.18659886\t0.00973691\n",
      "                 Populus_Nigra\t0.00012522\t0.00226908\n",
      "           Quercus_Chrysolepis\t0.00264179\t0.00285791\n",
      "         Betula_Austrosinensis\t0.00013773\t0.00078988\n",
      "                     Acer_Mono\t0.15718937\t0.02908153\n",
      "        Eucalyptus_Glaucescens\t0.00038815\t0.00684313\n",
      "                   Alnus_Rubra\t0.00996597\t0.00463868\n",
      "                Viburnum_Tinus\t0.02606668\t0.00804230\n",
      "             Populus_Adenopoda\t0.03658360\t0.00170901\n",
      "             Quercus_Pyrenaica\t0.00801286\t0.00539269\n",
      "           Eucalyptus_Neglecta\t0.00702379\t0.00638354\n",
      "             Quercus_Pubescens\t0.00102669\t0.00153668\n",
      "                   Morus_Nigra\t0.00289221\t0.00262815\n",
      "             Quercus_x_Turneri\t0.00007514\t0.00506953\n",
      "            Quercus_Imbricaria\t0.00364336\t0.01143153\n",
      "             Quercus_Crassipes\t0.00000000\t0.00264249\n",
      "           Eucalyptus_Urnigera\t0.01365937\t0.02483771\n",
      "                   Acer_Pictum\t0.00903945\t0.04343553\n",
      "                   Alnus_Rubra\t0.00375610\t0.05727248\n",
      "          Quercus_Dolicholepis\t0.00380609\t0.00884651\n",
      "                   Acer_Opalus\t0.04117837\t0.03048882\n",
      "               Quercus_Trojana\t0.01825424\t0.02625230\n",
      "                 Quercus_Suber\t0.00003756\t0.00269991\n",
      "               Acer_Platanoids\t0.00016278\t0.01936603\n",
      "             Quercus_Vulcanica\t0.00086394\t0.00299436\n",
      "                 Acer_Palmatum\t0.02138426\t0.05322260\n",
      "     Lithocarpus_Cleistocarpus\t0.01184396\t0.02055810\n",
      "           Quercus_Chrysolepis\t0.03287763\t0.02758794\n",
      "            Quercus_Variabilis\t0.00001253\t0.00022260\n",
      "            Magnolia_Heptapeta\t0.02519032\t0.08411412\n",
      "             Quercus_Palustris\t0.01138069\t0.00916963\n",
      "             Quercus_Crassipes\t0.00224114\t0.00516288\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 192 is out of bounds for axis 0 with size 192",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-315-acd0ddaa712e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\t\\t  Species Name\\tCluster 0\\tCluster 1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"%30s\\t%.8f\\t%.8f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 192 is out of bounds for axis 0 with size 192"
     ]
    }
   ],
   "source": [
    "print \"\\t\\t  Species Name\\tCluster 0\\tCluster 1\"\n",
    "for i in range(len(target)):\n",
    "    print \"%30s\\t%.8f\\t%.8f\" %(target[i],centroids[0][i],centroids[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The completeness score approaches 1 when most of the data points that are members of a given class are elements of the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761555573476\n"
     ]
    }
   ],
   "source": [
    "print completeness_score(target,clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The homogeneity score approaches 1 when all the clusters contain almost only data points that are members of a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.285422666406\n"
     ]
    }
   ],
   "source": [
    "print homogeneity_score(target,clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing PCA on data to do reduced-dimensionality clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "X_train = data.iloc[:,2:]\n",
    "target = data.iloc[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data by scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "image = min_max_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=40)\n",
    "X_train_trans = pca.fit(X_train).transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0344, -0.044 , -0.0782, ..., -0.0077,  0.008 ,  0.014 ],\n",
       "       [-0.0983, -0.0767, -0.0165, ..., -0.0023,  0.0068,  0.0044],\n",
       "       [ 0.0871, -0.084 ,  0.072 , ...,  0.0305, -0.0137, -0.0146],\n",
       "       ..., \n",
       "       [-0.1177, -0.0553,  0.0512, ...,  0.0157,  0.0054, -0.0008],\n",
       "       [ 0.0509, -0.0504,  0.0687, ...,  0.0293,  0.0242,  0.0675],\n",
       "       [-0.0539, -0.0364, -0.0733, ..., -0.0072, -0.0165, -0.0071]])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=4,suppress=True)\n",
    "X_train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14980004  0.101889    0.08671815  0.06781204  0.05548522  0.04619595\n",
      "  0.04204927  0.03934713  0.03282465  0.02917133  0.02656111  0.02310864\n",
      "  0.01881984  0.01794017  0.01612851  0.01545189  0.01433372  0.01412917\n",
      "  0.01286679  0.01108844  0.00942185  0.00919093  0.00848232  0.00773148\n",
      "  0.00727613  0.00703049  0.00656127  0.00616554  0.00578171  0.005361\n",
      "  0.00516237  0.00461435  0.0041706   0.00407401  0.00360426  0.00353355\n",
      "  0.00335529  0.00316332  0.0031      0.00291555]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=8,suppress=True)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative variance with 32 components is:  0.904500523121\n"
     ]
    }
   ],
   "source": [
    "num_PC = 32\n",
    "cumulative_variance = 0\n",
    "for i in range(num_PC):\n",
    "    cumulative_variance += pca.explained_variance_ratio_[i]\n",
    "    \n",
    "print \"Cumulative variance with\",num_PC,\"components is: \",cumulative_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=32)\n",
    "X_train_trans = pca.fit(X_train).transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=7, max_iter=500, verbose=1) # initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 66.129\n",
      "Iteration  1, inertia 51.032\n",
      "Iteration  2, inertia 49.590\n",
      "Iteration  3, inertia 49.151\n",
      "Iteration  4, inertia 48.794\n",
      "Iteration  5, inertia 48.424\n",
      "Iteration  6, inertia 48.202\n",
      "Iteration  7, inertia 48.114\n",
      "Iteration  8, inertia 47.992\n",
      "Iteration  9, inertia 47.906\n",
      "Iteration 10, inertia 47.847\n",
      "Iteration 11, inertia 47.778\n",
      "Iteration 12, inertia 47.758\n",
      "Iteration 13, inertia 47.750\n",
      "Iteration 14, inertia 47.738\n",
      "Iteration 15, inertia 47.732\n",
      "Iteration 16, inertia 47.727\n",
      "Iteration 17, inertia 47.722\n",
      "Iteration 18, inertia 47.717\n",
      "Iteration 19, inertia 47.716\n",
      "Converged at iteration 19\n",
      "Initialization complete\n",
      "Iteration  0, inertia 64.148\n",
      "Iteration  1, inertia 49.050\n",
      "Iteration  2, inertia 48.275\n",
      "Iteration  3, inertia 47.806\n",
      "Iteration  4, inertia 47.366\n",
      "Iteration  5, inertia 47.015\n",
      "Iteration  6, inertia 46.746\n",
      "Iteration  7, inertia 46.519\n",
      "Iteration  8, inertia 46.390\n",
      "Iteration  9, inertia 46.331\n",
      "Iteration 10, inertia 46.305\n",
      "Iteration 11, inertia 46.288\n",
      "Iteration 12, inertia 46.274\n",
      "Iteration 13, inertia 46.263\n",
      "Iteration 14, inertia 46.258\n",
      "Iteration 15, inertia 46.255\n",
      "Iteration 16, inertia 46.255\n",
      "Iteration 17, inertia 46.255\n",
      "Converged at iteration 17\n",
      "Initialization complete\n",
      "Iteration  0, inertia 71.404\n",
      "Iteration  1, inertia 50.592\n",
      "Iteration  2, inertia 49.214\n",
      "Iteration  3, inertia 48.302\n",
      "Iteration  4, inertia 47.790\n",
      "Iteration  5, inertia 47.357\n",
      "Iteration  6, inertia 47.099\n",
      "Iteration  7, inertia 46.963\n",
      "Iteration  8, inertia 46.927\n",
      "Iteration  9, inertia 46.900\n",
      "Iteration 10, inertia 46.857\n",
      "Iteration 11, inertia 46.809\n",
      "Iteration 12, inertia 46.784\n",
      "Iteration 13, inertia 46.774\n",
      "Iteration 14, inertia 46.766\n",
      "Iteration 15, inertia 46.764\n",
      "Iteration 16, inertia 46.761\n",
      "Iteration 17, inertia 46.761\n",
      "Converged at iteration 17\n",
      "Initialization complete\n",
      "Iteration  0, inertia 70.533\n",
      "Iteration  1, inertia 50.898\n",
      "Iteration  2, inertia 49.164\n",
      "Iteration  3, inertia 48.750\n",
      "Iteration  4, inertia 48.587\n",
      "Iteration  5, inertia 48.457\n",
      "Iteration  6, inertia 48.349\n",
      "Iteration  7, inertia 48.236\n",
      "Iteration  8, inertia 48.171\n",
      "Iteration  9, inertia 48.122\n",
      "Iteration 10, inertia 48.087\n",
      "Iteration 11, inertia 48.066\n",
      "Iteration 12, inertia 48.051\n",
      "Iteration 13, inertia 48.035\n",
      "Iteration 14, inertia 48.029\n",
      "Iteration 15, inertia 48.014\n",
      "Iteration 16, inertia 48.001\n",
      "Iteration 17, inertia 47.993\n",
      "Iteration 18, inertia 47.987\n",
      "Iteration 19, inertia 47.978\n",
      "Iteration 20, inertia 47.975\n",
      "Iteration 21, inertia 47.972\n",
      "Iteration 22, inertia 47.956\n",
      "Iteration 23, inertia 47.944\n",
      "Iteration 24, inertia 47.931\n",
      "Iteration 25, inertia 47.906\n",
      "Iteration 26, inertia 47.870\n",
      "Iteration 27, inertia 47.826\n",
      "Iteration 28, inertia 47.767\n",
      "Iteration 29, inertia 47.698\n",
      "Iteration 30, inertia 47.571\n",
      "Iteration 31, inertia 47.452\n",
      "Iteration 32, inertia 47.376\n",
      "Iteration 33, inertia 47.326\n",
      "Iteration 34, inertia 47.307\n",
      "Iteration 35, inertia 47.276\n",
      "Iteration 36, inertia 47.227\n",
      "Iteration 37, inertia 47.183\n",
      "Iteration 38, inertia 47.141\n",
      "Iteration 39, inertia 47.102\n",
      "Iteration 40, inertia 47.080\n",
      "Iteration 41, inertia 47.071\n",
      "Iteration 42, inertia 47.068\n",
      "Iteration 43, inertia 47.064\n",
      "Iteration 44, inertia 47.059\n",
      "Iteration 45, inertia 47.058\n",
      "Iteration 46, inertia 47.056\n",
      "Iteration 47, inertia 47.055\n",
      "Iteration 48, inertia 47.053\n",
      "Iteration 49, inertia 47.048\n",
      "Iteration 50, inertia 47.044\n",
      "Iteration 51, inertia 47.034\n",
      "Iteration 52, inertia 47.032\n",
      "Iteration 53, inertia 47.026\n",
      "Iteration 54, inertia 47.024\n",
      "Iteration 55, inertia 47.022\n",
      "Iteration 56, inertia 47.018\n",
      "Iteration 57, inertia 47.016\n",
      "Iteration 58, inertia 47.015\n",
      "Iteration 59, inertia 47.014\n",
      "Iteration 60, inertia 47.012\n",
      "Converged at iteration 60\n",
      "Initialization complete\n",
      "Iteration  0, inertia 69.119\n",
      "Iteration  1, inertia 51.740\n",
      "Iteration  2, inertia 50.217\n",
      "Iteration  3, inertia 49.732\n",
      "Iteration  4, inertia 49.539\n",
      "Iteration  5, inertia 49.150\n",
      "Iteration  6, inertia 48.728\n",
      "Iteration  7, inertia 48.474\n",
      "Iteration  8, inertia 48.380\n",
      "Iteration  9, inertia 48.357\n",
      "Iteration 10, inertia 48.342\n",
      "Iteration 11, inertia 48.329\n",
      "Iteration 12, inertia 48.315\n",
      "Iteration 13, inertia 48.305\n",
      "Iteration 14, inertia 48.288\n",
      "Iteration 15, inertia 48.268\n",
      "Iteration 16, inertia 48.246\n",
      "Iteration 17, inertia 48.210\n",
      "Iteration 18, inertia 48.186\n",
      "Iteration 19, inertia 48.174\n",
      "Iteration 20, inertia 48.159\n",
      "Iteration 21, inertia 48.149\n",
      "Iteration 22, inertia 48.143\n",
      "Iteration 23, inertia 48.139\n",
      "Iteration 24, inertia 48.135\n",
      "Iteration 25, inertia 48.133\n",
      "Iteration 26, inertia 48.131\n",
      "Iteration 27, inertia 48.127\n",
      "Iteration 28, inertia 48.124\n",
      "Iteration 29, inertia 48.119\n",
      "Iteration 30, inertia 48.111\n",
      "Iteration 31, inertia 48.108\n",
      "Iteration 32, inertia 48.095\n",
      "Iteration 33, inertia 48.074\n",
      "Iteration 34, inertia 48.046\n",
      "Iteration 35, inertia 48.029\n",
      "Iteration 36, inertia 48.010\n",
      "Iteration 37, inertia 47.999\n",
      "Iteration 38, inertia 47.984\n",
      "Iteration 39, inertia 47.975\n",
      "Iteration 40, inertia 47.971\n",
      "Converged at iteration 40\n",
      "Initialization complete\n",
      "Iteration  0, inertia 77.016\n",
      "Iteration  1, inertia 54.076\n",
      "Iteration  2, inertia 51.580\n",
      "Iteration  3, inertia 50.069\n",
      "Iteration  4, inertia 49.274\n",
      "Iteration  5, inertia 48.834\n",
      "Iteration  6, inertia 48.658\n",
      "Iteration  7, inertia 48.619\n",
      "Iteration  8, inertia 48.606\n",
      "Iteration  9, inertia 48.594\n",
      "Iteration 10, inertia 48.586\n",
      "Iteration 11, inertia 48.584\n",
      "Iteration 12, inertia 48.582\n",
      "Iteration 13, inertia 48.579\n",
      "Iteration 14, inertia 48.572\n",
      "Iteration 15, inertia 48.567\n",
      "Iteration 16, inertia 48.562\n",
      "Iteration 17, inertia 48.553\n",
      "Iteration 18, inertia 48.547\n",
      "Iteration 19, inertia 48.544\n",
      "Iteration 20, inertia 48.537\n",
      "Iteration 21, inertia 48.534\n",
      "Iteration 22, inertia 48.533\n",
      "Iteration 23, inertia 48.528\n",
      "Iteration 24, inertia 48.520\n",
      "Iteration 25, inertia 48.505\n",
      "Iteration 26, inertia 48.473\n",
      "Iteration 27, inertia 48.397\n",
      "Iteration 28, inertia 48.225\n",
      "Iteration 29, inertia 47.894\n",
      "Iteration 30, inertia 47.464\n",
      "Iteration 31, inertia 47.312\n",
      "Iteration 32, inertia 47.254\n",
      "Iteration 33, inertia 47.202\n",
      "Iteration 34, inertia 47.156\n",
      "Iteration 35, inertia 47.104\n",
      "Iteration 36, inertia 47.042\n",
      "Iteration 37, inertia 47.003\n",
      "Iteration 38, inertia 46.988\n",
      "Iteration 39, inertia 46.968\n",
      "Iteration 40, inertia 46.932\n",
      "Iteration 41, inertia 46.880\n",
      "Iteration 42, inertia 46.845\n",
      "Iteration 43, inertia 46.815\n",
      "Iteration 44, inertia 46.795\n",
      "Iteration 45, inertia 46.783\n",
      "Iteration 46, inertia 46.765\n",
      "Iteration 47, inertia 46.756\n",
      "Iteration 48, inertia 46.755\n",
      "Iteration 49, inertia 46.755\n",
      "Converged at iteration 49\n",
      "Initialization complete\n",
      "Iteration  0, inertia 74.858\n",
      "Iteration  1, inertia 53.550\n",
      "Iteration  2, inertia 52.070\n",
      "Iteration  3, inertia 51.365\n",
      "Iteration  4, inertia 50.632\n",
      "Iteration  5, inertia 50.218\n",
      "Iteration  6, inertia 49.770\n",
      "Iteration  7, inertia 49.157\n",
      "Iteration  8, inertia 48.777\n",
      "Iteration  9, inertia 48.671\n",
      "Iteration 10, inertia 48.543\n",
      "Iteration 11, inertia 48.400\n",
      "Iteration 12, inertia 48.225\n",
      "Iteration 13, inertia 48.022\n",
      "Iteration 14, inertia 47.896\n",
      "Iteration 15, inertia 47.809\n",
      "Iteration 16, inertia 47.779\n",
      "Iteration 17, inertia 47.753\n",
      "Iteration 18, inertia 47.699\n",
      "Iteration 19, inertia 47.684\n",
      "Iteration 20, inertia 47.680\n",
      "Iteration 21, inertia 47.675\n",
      "Iteration 22, inertia 47.673\n",
      "Iteration 23, inertia 47.671\n",
      "Iteration 24, inertia 47.667\n",
      "Iteration 25, inertia 47.666\n",
      "Iteration 26, inertia 47.664\n",
      "Iteration 27, inertia 47.662\n",
      "Iteration 28, inertia 47.661\n",
      "Iteration 29, inertia 47.661\n",
      "Iteration 30, inertia 47.660\n",
      "Iteration 31, inertia 47.660\n",
      "Iteration 32, inertia 47.659\n",
      "Converged at iteration 32\n",
      "Initialization complete\n",
      "Iteration  0, inertia 70.343\n",
      "Iteration  1, inertia 55.220\n",
      "Iteration  2, inertia 53.836\n",
      "Iteration  3, inertia 53.039\n",
      "Iteration  4, inertia 52.312\n",
      "Iteration  5, inertia 51.086\n",
      "Iteration  6, inertia 49.607\n",
      "Iteration  7, inertia 49.040\n",
      "Iteration  8, inertia 48.622\n",
      "Iteration  9, inertia 48.383\n",
      "Iteration 10, inertia 48.233\n",
      "Iteration 11, inertia 48.148\n",
      "Iteration 12, inertia 48.110\n",
      "Iteration 13, inertia 48.089\n",
      "Iteration 14, inertia 48.081\n",
      "Iteration 15, inertia 48.076\n",
      "Iteration 16, inertia 48.076\n",
      "Converged at iteration 16\n",
      "Initialization complete\n",
      "Iteration  0, inertia 68.694\n",
      "Iteration  1, inertia 50.858\n",
      "Iteration  2, inertia 49.515\n",
      "Iteration  3, inertia 48.947\n",
      "Iteration  4, inertia 48.615\n",
      "Iteration  5, inertia 48.450\n",
      "Iteration  6, inertia 48.303\n",
      "Iteration  7, inertia 48.099\n",
      "Iteration  8, inertia 47.788\n",
      "Iteration  9, inertia 47.358\n",
      "Iteration 10, inertia 47.079\n",
      "Iteration 11, inertia 46.925\n",
      "Iteration 12, inertia 46.858\n",
      "Iteration 13, inertia 46.779\n",
      "Iteration 14, inertia 46.714\n",
      "Iteration 15, inertia 46.679\n",
      "Iteration 16, inertia 46.663\n",
      "Iteration 17, inertia 46.654\n",
      "Iteration 18, inertia 46.628\n",
      "Iteration 19, inertia 46.620\n",
      "Iteration 20, inertia 46.615\n",
      "Iteration 21, inertia 46.614\n",
      "Iteration 22, inertia 46.611\n",
      "Iteration 23, inertia 46.607\n",
      "Iteration 24, inertia 46.601\n",
      "Iteration 25, inertia 46.594\n",
      "Iteration 26, inertia 46.552\n",
      "Iteration 27, inertia 46.438\n",
      "Iteration 28, inertia 46.384\n",
      "Iteration 29, inertia 46.339\n",
      "Iteration 30, inertia 46.323\n",
      "Iteration 31, inertia 46.307\n",
      "Iteration 32, inertia 46.285\n",
      "Iteration 33, inertia 46.282\n",
      "Iteration 34, inertia 46.280\n",
      "Converged at iteration 34\n",
      "Initialization complete\n",
      "Iteration  0, inertia 73.680\n",
      "Iteration  1, inertia 51.342\n",
      "Iteration  2, inertia 50.721\n",
      "Iteration  3, inertia 50.535\n",
      "Iteration  4, inertia 50.455\n",
      "Iteration  5, inertia 50.383\n",
      "Iteration  6, inertia 50.308\n",
      "Iteration  7, inertia 50.176\n",
      "Iteration  8, inertia 50.020\n",
      "Iteration  9, inertia 49.652\n",
      "Iteration 10, inertia 49.227\n",
      "Iteration 11, inertia 49.009\n",
      "Iteration 12, inertia 48.924\n",
      "Iteration 13, inertia 48.856\n",
      "Iteration 14, inertia 48.810\n",
      "Iteration 15, inertia 48.784\n",
      "Iteration 16, inertia 48.727\n",
      "Iteration 17, inertia 48.582\n",
      "Iteration 18, inertia 48.494\n",
      "Iteration 19, inertia 48.438\n",
      "Iteration 20, inertia 48.420\n",
      "Iteration 21, inertia 48.401\n",
      "Iteration 22, inertia 48.375\n",
      "Iteration 23, inertia 48.321\n",
      "Iteration 24, inertia 48.245\n",
      "Iteration 25, inertia 48.186\n",
      "Iteration 26, inertia 48.140\n",
      "Iteration 27, inertia 48.110\n",
      "Iteration 28, inertia 48.081\n",
      "Iteration 29, inertia 48.017\n",
      "Iteration 30, inertia 47.903\n",
      "Iteration 31, inertia 47.803\n",
      "Iteration 32, inertia 47.758\n",
      "Iteration 33, inertia 47.724\n",
      "Iteration 34, inertia 47.658\n",
      "Iteration 35, inertia 47.592\n",
      "Iteration 36, inertia 47.494\n",
      "Iteration 37, inertia 47.380\n",
      "Iteration 38, inertia 47.233\n",
      "Iteration 39, inertia 47.049\n",
      "Iteration 40, inertia 46.906\n",
      "Iteration 41, inertia 46.836\n",
      "Iteration 42, inertia 46.810\n",
      "Iteration 43, inertia 46.796\n",
      "Iteration 44, inertia 46.785\n",
      "Iteration 45, inertia 46.766\n",
      "Iteration 46, inertia 46.755\n",
      "Iteration 47, inertia 46.750\n",
      "Iteration 48, inertia 46.748\n",
      "Converged at iteration 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=500, n_clusters=7, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=1)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(X_train_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = kmeans.predict(X_train_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757622653141\n"
     ]
    }
   ],
   "source": [
    "print completeness_score(target,clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.282731686652\n"
     ]
    }
   ],
   "source": [
    "print homogeneity_score(target,clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It appears that the completeness and homogeneity scores have not dramatically changed even though we reduced the data from 192 dimensions to 32 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the project description for the data analysis project, the instructions say \"At least one of the machine learning techniques used must involve building and evaluating a predictive model.\"\n",
    "\n",
    "## I was uncertain whether this meant to build a model from scratch (e.g., without using an implementation in scikit learn) or if it meant to simply build a model by creating a train/test split, fitting the training data to the classifier model using something like scikit learn, and then computing the accuracy of the classifier model using the test data.\n",
    "\n",
    "## I have successfully used several different implementations in scikit learn of different classifers we saw in class as well as ones we did not see, but I was ultimately unsuccessful in creating a model from scratch without the use of scikit learn. \n",
    "\n",
    "## I tried to perform linear discriminant analysis by computing the overall mean vector on the data, the mean vector for each species class, the within-class scatter matrix, and the between-class scatter matrix. I then planned on selecting the top k eigenvectors based on the largest eigenvalues of the scatter matrices to transform the data onto the new feature subspace.\n",
    "\n",
    "## Unfortunately, I ran into a Type Error when trying to compute the scatter matrices that prevented me from finishing this task. I would appreciate any feedback on what I did wrong in the computations to give me this error.\n",
    "\n",
    "## I have shown my work below, but it is not complete, because I wasn't able to move any further after I encountered the Type Error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LDA built from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: compute mean vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tilia_Tomentosa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quercus_Variabilis</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "0            Acer_Opalus  0.007812  0.023438  0.023438  0.003906  0.011719   \n",
       "1  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625  0.025391   \n",
       "2   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812  0.003906   \n",
       "3        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859  0.021484   \n",
       "4     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766  0.013672   \n",
       "\n",
       "    margin6   margin7  margin8   margin9    ...      texture55  texture56  \\\n",
       "0  0.009766  0.027344      0.0  0.001953    ...       0.007812   0.000000   \n",
       "1  0.001953  0.019531      0.0  0.000000    ...       0.000977   0.000000   \n",
       "2  0.005859  0.068359      0.0  0.000000    ...       0.154300   0.000000   \n",
       "3  0.019531  0.023438      0.0  0.013672    ...       0.000000   0.000977   \n",
       "4  0.015625  0.005859      0.0  0.000000    ...       0.096680   0.000000   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
       "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
       "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
       "3   0.000000   0.000000   0.020508        0.0        0.0   0.017578   \n",
       "4   0.021484   0.000000   0.000000        0.0        0.0   0.000000   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "2   0.020508   0.002930  \n",
       "3   0.000000   0.047852  \n",
       "4   0.000000   0.031250  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_train = pd.read_csv(\"train.csv\")\n",
    "LDA_trainDF = pd.DataFrame(LDA_train)\n",
    "LDA_trainDF = LDA_trainDF.iloc[:,1:]  #Getting rid of the id column. It is meaningless here because we want to take the mean of the attributes by class\n",
    "\n",
    "LDA_trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 192)\n"
     ]
    }
   ],
   "source": [
    "# Create a groupby variable that computes the mean of all attributes, grouped by species class\n",
    "# These are the mean vectors for step one of LDA\n",
    "\n",
    "MV_DF = pd.DataFrame(LDA_trainDF.groupby(['species']).mean())\n",
    "\n",
    "print MV_DF.shape\n",
    "\n",
    "\n",
    "MV_DF.reset_index(inplace=True)    #This reset_index gets rid of the first empty row and uses numerical indexing instead of species as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer_Capillipes</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.029492</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer_Circinatum</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "0  Acer_Capillipes  0.001562  0.000391  0.017383  0.017578  0.035937   \n",
       "1  Acer_Circinatum  0.000195  0.000586  0.000977  0.016211  0.032227   \n",
       "\n",
       "    margin6   margin7   margin8   margin9    ...      texture55  texture56  \\\n",
       "0  0.001172  0.029492  0.000391  0.007422    ...       0.054981        0.0   \n",
       "1  0.000000  0.010156  0.000000  0.005664    ...       0.111817        0.0   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.008692   0.000000   0.016992        0.0        0.0   0.000293   \n",
       "1   0.005664   0.000781   0.006738        0.0        0.0   0.018457   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.024023   0.007813  \n",
       "1   0.000000   0.015137  \n",
       "\n",
       "[2 rows x 193 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MV_DF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>0.026953</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.028516</td>\n",
       "      <td>0.043164</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.028711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.027344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species   margin1   margin2   margin3   margin4   margin5   margin6  \\\n",
       "3  Acer_Opalus  0.014453  0.026953  0.035937  0.007422  0.008594  0.028516   \n",
       "\n",
       "    margin7   margin8   margin9    ...      texture55  texture56  texture57  \\\n",
       "3  0.043164  0.000977  0.001562    ...       0.003906        0.0   0.005859   \n",
       "\n",
       "   texture58  texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "3   0.001074   0.028711        0.0        0.0   0.003125   0.002246   0.027344  \n",
       "\n",
       "[1 rows x 193 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MV_DF[MV_DF['species']=='Acer_Opalus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making the subset of the training data for a given species\n",
    "\n",
    "#Acer_Opalus = pd.DataFrame(LDA_trainDF[LDA_trainDF['species']=='Acer_Opalus'])\n",
    "#Acer_Opalus = Acer_Opalus.iloc[:,1:194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making the mean vector for a given species\n",
    "\n",
    "#Acer_Opalus_MV = MV_DF[MV_DF['species']=='Acer_Opalus'].values\n",
    "#Acer_Opalus_MV = Acer_Opalus_MV[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 2: Compute the scatter matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Within-class scatter matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having problems here because we are trying to add the dot product to the scatter matrix and we receive a type error because the output is the same as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Acer_Saccharinum',\n",
       " 'Quercus_Pontica',\n",
       " 'Alnus_Viridis',\n",
       " 'Olea_Europaea',\n",
       " 'Acer_Rufinerve']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(unique_list)\n",
    "unique_list[1:6] #Print first 5 species names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "0            Acer_Opalus  0.007812  0.023438  0.023438  0.003906  0.011719   \n",
       "1  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625  0.025391   \n",
       "2   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812  0.003906   \n",
       "\n",
       "    margin6   margin7  margin8   margin9    ...      texture55  texture56  \\\n",
       "0  0.009766  0.027344      0.0  0.001953    ...       0.007812        0.0   \n",
       "1  0.001953  0.019531      0.0  0.000000    ...       0.000977        0.0   \n",
       "2  0.005859  0.068359      0.0  0.000000    ...       0.154300        0.0   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
       "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
       "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "2   0.020508   0.002930  \n",
       "\n",
       "[3 rows x 193 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_trainDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer_Capillipes</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.029492</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer_Circinatum</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer_Mono</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.015039</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.024609</td>\n",
       "      <td>0.026953</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.010352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "0  Acer_Capillipes  0.001562  0.000391  0.017383  0.017578  0.035937   \n",
       "1  Acer_Circinatum  0.000195  0.000586  0.000977  0.016211  0.032227   \n",
       "2        Acer_Mono  0.021875  0.015039  0.032813  0.026367  0.003125   \n",
       "\n",
       "    margin6   margin7   margin8   margin9    ...      texture55  texture56  \\\n",
       "0  0.001172  0.029492  0.000391  0.007422    ...       0.054981        0.0   \n",
       "1  0.000000  0.010156  0.000000  0.005664    ...       0.111817        0.0   \n",
       "2  0.024609  0.026953  0.000391  0.002148    ...       0.158303        0.0   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.008692   0.000000   0.016992        0.0        0.0   0.000293   \n",
       "1   0.005664   0.000781   0.006738        0.0        0.0   0.018457   \n",
       "2   0.021094   0.003320   0.005371        0.0        0.0   0.000879   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.024023   0.007813  \n",
       "1   0.000000   0.015137  \n",
       "2   0.000195   0.010352  \n",
       "\n",
       "[3 rows x 193 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MV_DF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pseudocode for the process below\n",
    "\n",
    "\n",
    "### initialize a square zero matrix with dimensions equal to the number of attributes in the data (in this case, 192)\n",
    "\n",
    "### for each species:\n",
    "###    initialize a zero matrix for the scatter matrix for that class\n",
    "    \n",
    "    ###    for each row of data corresponding to that species:\n",
    "    ###        compute the dot product of the difference between that row and the mean vector for that species\n",
    "    ###       add that dot product to the class scatter matrix\n",
    "    \n",
    "###   add the class scatter matrix to the overall within class scatter matrix   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is a function that takes as input the training dataframe, the list of unique class values, and the mean vector data frame. It doesn't return anything as output;  rather, it adds the computations from the nested loop to the within-class scatter matrix S_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_S_W(LDA_trainDF,unique_list,MV_DF):\n",
    "\n",
    "    S_W = np.mat(np.zeros((192,192)))   #Initialize the zero matrix S_W\n",
    "\n",
    "\n",
    "    for name in unique_list:    #For each species class\n",
    "    \n",
    "        species_data = pd.DataFrame(LDA_trainDF[LDA_trainDF['species']==name])  #select rows of the train data for that species\n",
    "        species_data = species_data.iloc[:,1:194]\n",
    "    \n",
    "        species_MV =  MV_DF[MV_DF['species']==name].values  #Define the mean vector for this species\n",
    "        species_MV = species_MV[0,1:] #Remove the species column so we have a numerical vector of length 192\n",
    "    \n",
    "    \n",
    "    \n",
    "        class_scatter_matrix = np.mat(np.zeros((192,192)))\n",
    "    \n",
    "        for i in range(len(species_data)):      #For each row of training data corresponding to the species\n",
    "        \n",
    "            row = species_data.iloc[i,:].values    #This is one of the rows of data for this species\n",
    "            data_col =  row.reshape(192,1)         #Make a column vector out of the data row\n",
    "            MV_col = species_MV.reshape(192,1)     #Make a column vector out of the mean vector for this species\n",
    "   \n",
    "    \n",
    "            row_scat_mat = (data_col-MV_col).dot((data_col-MV_col).T)\n",
    "        \n",
    "            class_scatter_matrix += np.mat(row_scat_mat)  #This is where we are getting the type error\n",
    "      \n",
    "        \n",
    "        S_W += class_scatter_matrix\n",
    "        \n",
    "    return S_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' output (typecode 'O') could not be coerced to provided output parameter (typecode 'd') according to the casting rule ''same_kind''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5f6326697d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_S_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLDA_trainDF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMV_DF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-1b3ac3472c71>\u001b[0m in \u001b[0;36mmake_S_W\u001b[0;34m(LDA_trainDF, unique_list, MV_DF)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mrow_scat_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_col\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mMV_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_col\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mMV_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mclass_scatter_matrix\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_scat_mat\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#This is where we are getting the type error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'add' output (typecode 'O') could not be coerced to provided output parameter (typecode 'd') according to the casting rule ''same_kind''"
     ]
    }
   ],
   "source": [
    "make_S_W(LDA_trainDF,unique_list,MV_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beginning_mat = np.zeros((192,192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat1 = 2*np.ones((192,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat2 = np.ones((192,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_scat_mat = (mat1-mat2).dot((mat1-mat2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 192)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print row_scat_mat.shape\n",
    "row_scat_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beginning_mat += row_scat_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beginning_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S_W = np.zeros((192,192))\n",
    "\n",
    "for name in unique_list:\n",
    "    species_data = pd.DataFrame(LDA_trainDF[LDA_trainDF['species']==name])  #select rows of the train data for that species\n",
    "    species_data = species_data.iloc[:,1:194]\n",
    "    \n",
    "    species_MV =  MV_DF[MV_DF['species']==name].values  #Define the mean vector for this species\n",
    "    species_MV = species_MV[0,1:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    class_scatter_matrix = np.ones((192,192))\n",
    "    S_W += class_scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99.,  99.,  99., ...,  99.,  99.,  99.],\n",
       "       [ 99.,  99.,  99., ...,  99.,  99.,  99.],\n",
       "       [ 99.,  99.,  99., ...,  99.,  99.,  99.],\n",
       "       ..., \n",
       "       [ 99.,  99.,  99., ...,  99.,  99.,  99.],\n",
       "       [ 99.,  99.,  99., ...,  99.,  99.,  99.],\n",
       "       [ 99.,  99.,  99., ...,  99.,  99.,  99.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start0 = 0\n",
    "\n",
    "for i in range(99):     #For all 99 species\n",
    "    \n",
    "    start = 0\n",
    "    \n",
    "    \n",
    "    for i in range(10):    #For all 10 rows corresponding to that species\n",
    "        start += i\n",
    "        \n",
    "        \n",
    "    start0 += start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4455"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Between-class scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The overall mean is the mean of all attributes for the entire training dataset\n",
    "\n",
    "overall_mean = np.mean(train.iloc[:,2:],axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "[ 0.017412  0.028539  0.031988  0.02328   0.014264  0.038579  0.019202\n",
      "  0.001083  0.007167  0.018639  0.024209  0.011975  0.041252  0.008053\n",
      "  0.015609  0.00011   0.015128  0.020107  0.012344  0.013135  0.019131\n",
      "  0.006195  0.000998  0.007647  0.008854  0.018718  0.005628  0.015534\n",
      "  0.028261  0.016501  0.010843  0.009691  0.019502  0.001083  0.013167\n",
      "  0.018042  0.016268  0.031061  0.014846  0.008164  0.010884  0.017495\n",
      "  0.018858  0.012679  0.024688  0.010058  0.02532   0.027002  0.00856\n",
      "  0.013982  0.025657  0.002764  0.024002  0.010002  0.018192  0.00596\n",
      "  0.012559  0.02019   0.03095   0.011851  0.001389  0.004983  0.025389\n",
      "  0.004374  0.000739  0.000718  0.000694  0.000671  0.00065   0.000632\n",
      "  0.000617  0.000604  0.00059   0.000578  0.000569  0.000562  0.000556\n",
      "  0.000551  0.000546  0.000543  0.000542  0.000542  0.000542  0.000546\n",
      "  0.000554  0.000563  0.000575  0.000586  0.000599  0.000613  0.000628\n",
      "  0.000644  0.000663  0.000687  0.000711  0.000734  0.000739  0.000718\n",
      "  0.00069   0.000665  0.000642  0.000621  0.000602  0.000586  0.000572\n",
      "  0.000562  0.000556  0.000551  0.000547  0.000545  0.000545  0.000545\n",
      "  0.000547  0.000547  0.000546  0.000547  0.000551  0.000556  0.000562\n",
      "  0.000569  0.000578  0.000591  0.000607  0.000626  0.000648  0.000675\n",
      "  0.000704  0.000732  0.021944  0.011688  0.010314  0.01539   0.02694\n",
      "  0.00988   0.016712  0.019562  0.014922  0.019961  0.018796  0.026541\n",
      "  0.009814  0.012796  0.01203   0.004544  0.015098  0.006175  0.024458\n",
      "  0.014515  0.002856  0.013171  0.01705   0.010163  0.010437  0.023274\n",
      "  0.020317  0.010097  0.021722  0.011675  0.023895  0.006048  0.023243\n",
      "  0.026518  0.010514  0.003321  0.021123  0.023964  0.01706   0.019187\n",
      "  0.01558   0.005895  0.013875  0.025263  0.016227  0.02176   0.018595\n",
      "  0.016763  0.01168   0.018986  0.01324   0.007289  0.014469  0.022091\n",
      "  0.036501  0.005024  0.015944  0.011586  0.016108  0.014017  0.002688\n",
      "  0.020291  0.008989  0.01942 ]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6,suppress=True)\n",
    "\n",
    "\n",
    "print len(overall_mean)\n",
    "print overall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer_Capillipes</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.029492</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer_Circinatum</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer_Mono</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.015039</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.024609</td>\n",
       "      <td>0.026953</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.010352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           species   margin1   margin2   margin3   margin4   margin5  \\\n",
       "0  Acer_Capillipes  0.001562  0.000391  0.017383  0.017578  0.035937   \n",
       "1  Acer_Circinatum  0.000195  0.000586  0.000977  0.016211  0.032227   \n",
       "2        Acer_Mono  0.021875  0.015039  0.032813  0.026367  0.003125   \n",
       "\n",
       "    margin6   margin7   margin8   margin9    ...      texture55  texture56  \\\n",
       "0  0.001172  0.029492  0.000391  0.007422    ...       0.054981        0.0   \n",
       "1  0.000000  0.010156  0.000000  0.005664    ...       0.111817        0.0   \n",
       "2  0.024609  0.026953  0.000391  0.002148    ...       0.158303        0.0   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.008692   0.000000   0.016992        0.0        0.0   0.000293   \n",
       "1   0.005664   0.000781   0.006738        0.0        0.0   0.018457   \n",
       "2   0.021094   0.003320   0.005371        0.0        0.0   0.000879   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.024023   0.007813  \n",
       "1   0.000000   0.015137  \n",
       "2   0.000195   0.010352  \n",
       "\n",
       "[3 rows x 193 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MV_DF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MV_DF.iloc[3,2:194].values    #This gives us the values for the sample mean for class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculating the sample mean for class i\n",
    "\n",
    "sample_mean_vectors = []\n",
    "\n",
    "for i in range(len(MV_DF)):\n",
    "    mi = MV_DF.iloc[i,2:194].values\n",
    "    \n",
    "    #print mi\n",
    "    sample_mean_vectors.append(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014453100000000002"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mean_vectors[98][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24017860957163706 0.34712806222520076 0.735075496026758 ...,\n",
      "  0.13113549825914553 0.11959890221290014 0.3093799334402877]\n",
      " [0.34712806222520076 0.644586660241965 1.7235851674771236 ...,\n",
      "  0.043846369709509316 0.011759625919264079 0.5395977595274516]\n",
      " [0.735075496026758 1.7235851674771236 5.30929580752508 ...,\n",
      "  -0.27278539024253334 -0.3794155457447787 1.3746877261418098]\n",
      " ..., \n",
      " [0.13113549825914553 0.043846369709509316 -0.27278539024253334 ...,\n",
      "  0.22013341198985387 0.2295492564876086 0.07465532837419599]\n",
      " [0.11959890221290014 0.011759625919264079 -0.3794155457447787 ...,\n",
      "  0.2295492564876086 0.24118183746536326 0.04982182061595075]\n",
      " [0.3093799334402877 0.5395977595274516 1.3746877261418098 ...,\n",
      "  0.07465532837419599 0.04982182061595075 0.4583416901217383]]\n",
      "[[0.39663820587133497 0.39663820587133497 -0.0174974504903604 ...,\n",
      "  0.39663820587133497 0.25925832256320575 0.2931007238429488]\n",
      " [0.39663820587133497 0.39663820587133497 -0.0174974504903604 ...,\n",
      "  0.39663820587133497 0.25925832256320575 0.2931007238429488]\n",
      " [-0.0174974504903604 -0.0174974504903604 0.36055439314794446 ...,\n",
      "  -0.0174974504903604 0.10791246620151039 0.07701876748125332]\n",
      " ..., \n",
      " [0.39663820587133497 0.39663820587133497 -0.0174974504903604 ...,\n",
      "  0.39663820587133497 0.25925832256320575 0.2931007238429488]\n",
      " [0.25925832256320575 0.25925832256320575 0.10791246620151039 ...,\n",
      "  0.25925832256320575 0.20905285059587653 0.22142055457001944]\n",
      " [0.2931007238429488 0.2931007238429488 0.07701876748125332 ...,\n",
      "  0.2931007238429488 0.22142055457001944 0.23907837312336244]]\n",
      "[[0.19743883936522605 0.20757029373116948 -0.029945715237352545 ...,\n",
      "  0.23796177513653505 0.1783020960483831 0.21601134729756163]\n",
      " [0.20757029373116948 0.22363495592431293 -0.15297577652580915 ...,\n",
      "  0.2718243732272786 0.17722664258712648 0.23701928054350477]\n",
      " [-0.029945715237352545 -0.15297577652580915 2.7312704614688705 ...,\n",
      "  -0.5220309669156435 0.20243895710020465 -0.25547866506501704]\n",
      " ..., \n",
      " [0.23796177513653505 0.2718243732272786 -0.5220309669156435 ...,\n",
      "  0.37340253595104456 0.17400058809489222 0.30003710498887043]\n",
      " [0.1783020960483831 0.17722664258712648 0.20243895710020465 ...,\n",
      "  0.17400058809489222 0.18033346055874 0.17633062510071837]\n",
      " [0.21601134729756163 0.23701928054350477 -0.25547866506501704 ...,\n",
      "  0.30003710498887043 0.17633062510071837 0.25452210722989693]]\n",
      "[[0.3586508385298267 0.3694978026362789 0.13446728766062394 ...,\n",
      "  -0.40068478359786575 0.22667111089970268 0.176048242402205]\n",
      " [0.3694978026362789 0.3810038620579316 0.13169216113667656 ...,\n",
      "  -0.43597741636821313 0.22949857578695537 0.17579970416625768]\n",
      " [0.13446728766062394 0.13169216113667656 0.1918232180522214 ...,\n",
      "  0.32873845928653106 0.16823345846890014 0.1811849962178027]\n",
      " ..., \n",
      " [-0.40068478359786575 -0.43597741636821313 0.32873845928653106 ...,\n",
      "  2.069956125525641 0.028736021584810294 0.19344702183611256]\n",
      " [0.22667111089970268 0.22949857578695537 0.16823345846890014 ...,\n",
      "  0.028736021584810294 0.19226811647277886 0.17907231516248134]\n",
      " [0.176048242402205 0.17579970416625768 0.1811849962178027 ...,\n",
      "  0.19344702183611256 0.17907231516248134 0.1802322451033837]]\n",
      "[[0.18335909321723157 0.1712169661057742 0.18287344791938237 ...,\n",
      "  0.1573757021176125 0.1537329893842834 0.2134710910143362]\n",
      " [0.1712169661057742 0.20485284682151675 0.17256229111832513 ...,\n",
      "  0.2431956429549551 0.2532866138248259 0.08780130452367887]\n",
      " [0.18287344791938237 0.17256229111832513 0.18246103543433337 ...,\n",
      "  0.16080821854136354 0.15771480815043412 0.20844471134208678]\n",
      " ..., \n",
      " [0.1573757021176125 0.2431956429549551 0.16080821854136354 ...,\n",
      "  0.3410249973731936 0.3667715068926641 -0.055454376642082796]\n",
      " [0.1537329893842834 0.2532866138248259 0.15771480815043412 ...,\n",
      "  0.3667715068926641 0.39663820587133497 -0.0931560846906122]\n",
      " [0.2134710910143362 0.08780130452367887 0.20844471134208678 ...,\n",
      "  -0.055454376642082796 -0.0931560846906122 0.5251272200626408]]\n",
      "[[0.3887478011518335 0.3887478011518335 0.15030804740468884 ...,\n",
      "  -0.31875228685880586 0.37702004196768807 0.22653247812935534]\n",
      " [0.3887478011518335 0.3887478011518335 0.15030804740468884 ...,\n",
      "  -0.31875228685880586 0.37702004196768807 0.22653247812935534]\n",
      " [0.15030804740468884 0.15030804740468884 0.1844041889727441 ...,\n",
      "  0.2514783547092494 0.15198508041254336 0.17350433297101062]\n",
      " ..., \n",
      " [-0.31875228685880586 -0.31875228685880586 0.2514783547092494 ...,\n",
      "  1.373240020445755 -0.29070525385095125 0.06918699870751605]\n",
      " [0.37702004196768807 0.37702004196768807 0.15198508041254336 ...,\n",
      "  -0.29070525385095125 0.36595160310354236 0.22392426659320994]\n",
      " [0.22653247812935534 0.22653247812935534 0.17350433297101062 ...,\n",
      "  0.06918699870751605 0.22392426659320994 0.19045637269407717]]\n",
      "[[0.3243217841561325 0.3373212605448288 0.015603769885887407 ...,\n",
      "  0.07084780092823763 0.35681797938813375 0.34056904985888636]\n",
      " [0.3373212605448288 0.3514927619383246 0.0007694150233836472 ...,\n",
      "  0.060994214814533876 0.37274729327443 0.3550333699915828]\n",
      " [0.015603769885887407 0.0007694150233836472 0.3678973884284425 ...,\n",
      "  0.30485565228359285 -0.02147926925651128 -0.002936800347358384]\n",
      " ..., \n",
      " [0.07084780092823763 0.060994214814533876 0.30485565228359285 ...,\n",
      "  0.26298074895154283 0.04621572741143895 0.05853239475899188]\n",
      " [0.35681797938813375 0.37274729327443 -0.02147926925651128 ...,\n",
      "  0.04621572741143895 0.39663820587133497 0.3767270732188879]\n",
      " [0.34056904985888636 0.3550333699915828 -0.002936800347358384 ...,\n",
      "  0.05853239475899188 0.3767270732188879 0.35864713588164066]]\n",
      "[[2.9832491194683692 7.281766520942451 0.6190436405084083 ...,\n",
      "  -0.06156430170402302 -0.17617764036770917 -0.5702192230537433]\n",
      " [7.281766520942451 18.171979547805318 1.2920963857648893 ...,\n",
      "  -0.43221104077394135 -0.7225817796104281 -1.7208787215796615]\n",
      " [0.6190436405084083 1.2920963857648893 0.24886135686364805 ...,\n",
      "  0.14229320762401684 0.1243472939459308 0.062649097986297]\n",
      " ..., \n",
      " [-0.06156430170402302 -0.43221104077394135 0.14229320762401684 ...,\n",
      "  0.2009797478435857 0.2108624716438996 0.24483935577386567]\n",
      " [-0.17617764036770917 -0.7225817796104281 0.1243472939459308 ...,\n",
      "  0.2108624716438996 0.2254314955210135 0.2755199171101796]\n",
      " [-0.5702192230537433 -1.7208787215796615 0.062649097986297 ...,\n",
      "  0.24483935577386567 0.2755199171101796 0.3809999344241461]]\n",
      "[[0.2488590595118339 0.2982161020634367 0.42385033074083195 ...,\n",
      "  0.06713660372298094 0.15687845630109704 1.2281591143313355]\n",
      " [0.2982161020634367 0.38302277586623945 0.5988910795388344 ...,\n",
      "  -0.014024588099816195 0.14017241448789985 1.9808772991421368]\n",
      " [0.42385033074083195 0.5988910795388344 1.0444426832306297 ...,\n",
      "  -0.2206136219248208 0.0976485806244952 3.8968585587827342]\n",
      " ..., \n",
      " [0.06713660372298094 -0.014024588099816195 -0.2206136219248208 ...,\n",
      "  0.3659553807469282 0.21838665832984436 -1.5431940703279192]\n",
      " [0.15687845630109704 0.14017241448789985 0.0976485806244952 ...,\n",
      "  0.21838665832984436 0.18801143598956033 -0.1745884796762018]\n",
      " [1.2281591143313355 1.9808772991421368 3.8968585587827342 ...,\n",
      "  -1.5431940703279192 -0.1745884796762018 16.162946969138034]]\n",
      "[[3.491567217830255 6.030049204157898 0.42358562796170623 ...,\n",
      "  -0.658784409135128 1.4592140050284717 0.3846422182744228]\n",
      " [6.030049204157898 10.514486060834349 0.6102078220589533 ...,\n",
      "  -1.301887718922681 2.439730382767319 0.5414110913092702]\n",
      " [0.42358562796170623 0.6102078220589533 0.19803608345635915 ...,\n",
      "  0.11846322367792526 0.27417262531032416 0.1951730713882756]\n",
      " ..., \n",
      " [-0.658784409135128 -1.301887718922681 0.11846322367792526 ...,\n",
      "  0.39267267524029154 -0.14390461686170963 0.12832921280024168]\n",
      " [1.4592140050284717 2.439730382767319 0.27417262531032416 ...,\n",
      "  -0.14390461686170963 0.674195391055489 0.2591303082054404]\n",
      " [0.3846422182744228 0.5414110913092702 0.1951730713882756 ...,\n",
      "  0.12832921280024168 0.2591303082054404 0.1927680456753919]]\n",
      "[[0.24768844982852306 0.2521379011969173 0.11200466817168545 ...,\n",
      "  0.30107047784032903 -0.2516682271898818 0.07307794761292055]\n",
      " [0.2521379011969173 0.2568804338261121 0.10751675389527997 ...,\n",
      "  0.30903615419432356 -0.2801109399046873 0.06602596613011517]\n",
      " [0.11200466817168545 0.10751675389527997 0.24886135686364805 ...,\n",
      "  0.05816118370989157 0.6156779919724805 0.28812457618328324]\n",
      " ..., \n",
      " [0.30107047784032903 0.30903615419432356 0.05816118370989157 ...,\n",
      "  0.39663820587133497 -0.5929079804004758 -0.011527780573673346]\n",
      " [-0.2516682271898818 -0.2801109399046873 0.6156779919724805 ...,\n",
      "  -0.5929079804004758 2.9404238602845134 0.8645135085593167]\n",
      " [0.07307794761292055 0.06602596613011517 0.28812457618328324 ...,\n",
      "  -0.011527780573673346 0.8645135085593167 0.3498199381141182]]\n",
      "[[0.3586508385298267 0.36588214793412843 -0.42961372388245855 ...,\n",
      "  0.28452343746780906 0.3007948092943346 0.07841816010936087]\n",
      " [0.36588214793412843 0.37340638858962993 -0.45431402072455657 ...,\n",
      "  0.28875193906411084 0.305682443703436 0.07429759608006259]\n",
      " [-0.42961372388245855 -0.45431402072455657 2.262895694966059 ...,\n",
      "  -0.17641354836847575 -0.23199237810355033 0.5275891773962758]\n",
      " ..., \n",
      " [0.28452343746780906 0.28875193906411084 -0.17641354836847575 ...,\n",
      "  0.2411775071257917 0.2506921770003171 0.12065763367134351]\n",
      " [0.3007948092943346 0.305682443703436 -0.23199237810355033 ...,\n",
      "  0.2506921770003171 0.26168998007804234 0.11138583713946879]\n",
      " [0.07841816010936087 0.07429759608006259 0.5275891773962758 ...,\n",
      "  0.12065763367134351 0.11138583713946879 0.23810109302969507]]\n",
      "[[0.26798014423204125 0.43538855939404975 0.8209316706510492 ...,\n",
      "  0.19569064853686557 0.04223390864528813 0.8171265502431223]\n",
      " [0.43538855939404975 0.9218436558168575 2.0421541920594586 ...,\n",
      "  0.22532986213727368 -0.22058447931590372 2.031097279459529]\n",
      " [0.8209316706510492 2.0421541920594586 4.8546408283212585 ...,\n",
      "  0.2935892421430735 -0.8258576305613048 4.82688297197733]\n",
      " ..., \n",
      " [0.19569064853686557 0.22532986213727368 0.2935892421430735 ...,\n",
      "  0.18289198604488963 0.15572287935651227 0.29291555571914635]\n",
      " [0.04223390864528813 -0.22058447931590372 -0.8258576305613048 ...,\n",
      "  0.15572287935651227 0.39663820587133497 -0.8198838830012313]\n",
      " [0.8171265502431223 2.031097279459529 4.82688297197733 ...,\n",
      "  0.29291555571914635 -0.8198838830012313 4.799289945713403]]\n",
      "[[0.18841757530845327 0.1946467876624466 0.30600153369711103 ...,\n",
      "  0.16233095444812454 0.23669676191765066 0.24292677166185828]\n",
      " [0.1946467876624466 0.20556290003563985 0.4007016835487038 ...,\n",
      "  0.14893242305811774 0.27925154928604395 0.2901690590110516]\n",
      " [0.30600153369711103 0.4007016835487038 2.0935820248985677 ...,\n",
      "  -0.09058261919521764 1.0399701234295087 1.1346823956761156]\n",
      " ..., \n",
      " [0.16233095444812454 0.14893242305811774 -0.09058261919521764 ...,\n",
      "  0.21844116366779598 0.058486333249322044 0.04508608673752957]\n",
      " [0.23669676191765066 0.27925154928604395 1.0399701234295087 ...,\n",
      "  0.058486333249322044 0.5665154297876482 0.6090756645174557]\n",
      " [0.24292677166185828 0.2901690590110516 1.1346823956761156 ...,\n",
      "  0.04508608673752957 0.6090756645174557 0.6563239992664627]]\n",
      "[[0.2879647277303222 0.310446616681222 -0.1391940400185568 ...,\n",
      "  0.30903799144711436 0.332927066791229 0.24580956725138076]\n",
      " [0.310446616681222 0.3376160056321215 -0.20577525106765718 ...,\n",
      "  0.3359136803980137 0.36478365574212845 0.25950205620228056]\n",
      " [-0.1391940400185568 -0.20577525106765718 1.1258574923093643 ...,\n",
      "  -0.20160353870816491 -0.2723522009192504 -0.014349475454298048]\n",
      " ..., \n",
      " [0.30903799144711436 0.3359136803980137 -0.20160353870816491 ...,\n",
      "  0.3342297572311065 0.36278764930482055 0.2586441396145731]\n",
      " [0.332927066791229 0.36478365574212845 -0.2723522009192504 ...,\n",
      "  0.36278764930482055 0.39663820587133497 0.27319366883388746]\n",
      " [0.24580956725138076 0.25950205620228056 -0.014349475454298048 ...,\n",
      "  0.2586441396145731 0.27319366883388746 0.22013516460923965]]\n",
      "[[0.3243251118283181 0.3113271492757146 -0.08188950331731654 ...,\n",
      "  0.34219315072391565 0.3568200182098267 0.03834996952272914]\n",
      " [0.3113271492757146 0.2995009117279114 -0.058268509633119886 ...,\n",
      "  0.3275844412657124 0.3408927431452231 0.05113175696052575]\n",
      " [-0.08188950331731654 -0.058268509633119886 0.6563179518858487 ...,\n",
      "  -0.11436081043131896 -0.14094198752780804 0.43780864190349456]\n",
      " ..., \n",
      " [0.34219315072391565 0.3275844412657124 -0.11436081043131896 ...,\n",
      "  0.3622754511427131 0.3787149243694241 0.020779102229526676]\n",
      " [0.3568200182098267 0.3408927431452231 -0.14094198752780804 ...,\n",
      "  0.3787149243694241 0.39663820587133497 0.006395500928237634]\n",
      " [0.03834996952272914 0.05113175696052575 0.43780864190349456 ...,\n",
      "  0.020779102229526676 0.006395500928237634 0.31956892723634023]]\n",
      "[[0.21131388747343632 0.2808235944235403 0.5754839722898035 ...,\n",
      "  0.09798344901478573 0.09798344901478573 0.14482691353893795]\n",
      " [0.2808235944235403 0.5053146326248443 1.4569603386191077 ...,\n",
      "  -0.08519244715831051 -0.08519244715831051 0.0660948829914418]\n",
      " [0.5754839722898035 1.4569603386191077 5.193649364933366 ...,\n",
      "  -0.8616980771000473 -0.8616980771000473 -0.26766008288629506]\n",
      " ..., \n",
      " [0.09798344901478573 -0.08519244715831051 -0.8616980771000473 ...,\n",
      "  0.39663820587133497 0.39663820587133497 0.27319366883388746]\n",
      " [0.09798344901478573 -0.08519244715831051 -0.8616980771000473 ...,\n",
      "  0.39663820587133497 0.39663820587133497 0.27319366883388746]\n",
      " [0.14482691353893795 0.0660948829914418 -0.26766008288629506 ...,\n",
      "  0.27319366883388746 0.27319366883388746 0.2201351646092397]]\n",
      "[[0.313251266330242 0.14151830303318852 0.8908992331821054 ...,\n",
      "  0.3725813265961117 0.01037731969438847 0.29608148708753235]\n",
      " [0.14151830303318852 0.19134347254893513 -0.02607565980454702 ...,\n",
      "  0.12430477423025817 0.2293916235845352 0.14649979956647904]\n",
      " [0.8908992331821054 -0.02607565980454702 3.9752732078611723 ...,\n",
      "  1.2076944169295767 -0.7263080837641472 0.7992205235073968]\n",
      " ..., \n",
      " [0.3725813265961117 0.12430477423025817 1.2076944169295767 ...,\n",
      "  0.45835555730678135 -0.06528743097094196 0.347758756057402]\n",
      " [0.01037731969438847 0.2293916235845352 -0.7263080837641472 ...,\n",
      "  -0.06528743097094196 0.39663820587133497 0.03227426467567885]\n",
      " [0.29608148708753235 0.14649979956647904 0.7992205235073968 ...,\n",
      "  0.347758756057402 0.03227426467567885 0.28112638176482263]]\n",
      "[[0.20290578241772705 0.34624309336888265 0.20290578241772705 ...,\n",
      "  0.11961692505456764 0.17191527158864045 0.2810323094723188]\n",
      " [0.34624309336888265 1.3919984371328393 0.34624309336888265 ...,\n",
      "  -0.2614128413318766 0.12014360754459616 0.9162358790218743]\n",
      " [0.20290578241772705 0.34624309336888265 0.20290578241772705 ...,\n",
      "  0.11961692505456764 0.17191527158864045 0.2810323094723188]\n",
      " ..., \n",
      " [0.11961692505456764 -0.2614128413318766 0.11961692505456764 ...,\n",
      "  0.341021482270608 0.20199817682388074 -0.0880647466236409]\n",
      " [0.17191527158864045 0.12014360754459616 0.17191527158864045 ...,\n",
      "  0.20199817682388074 0.18310866083635363 0.14369693621763183]\n",
      " [0.2810323094723188 0.9162358790218743 0.2810323094723188 ...,\n",
      "  -0.0880647466236409 0.14369693621763183 0.6272523448021108]]\n",
      "[[0.39663820587133497 0.3926563871051844 0.030288452346835665 ...,\n",
      "  -1.0150133907595518 0.34885434185583203 0.3627896881265138]\n",
      " [0.3926563871051844 0.3887478011518335 0.033044464831884814 ...,\n",
      "  -0.9930323962521022 0.3457513543408811 0.3594304045155628]\n",
      " [0.030288452346835665 0.033044464831884814 0.283857123827136 ...,\n",
      "  1.0073619088103487 0.0633620133361326 0.05371667522281413]\n",
      " ..., \n",
      " [-1.0150133907595518 -0.9930323962521022 1.0073619088103487 ...,\n",
      "  6.777783774132763 -0.7512302016806547 -0.8281580549619725]\n",
      " [0.34885434185583203 0.3457513543408811 0.0633620133361326 ...,\n",
      "  -0.7512302016806547 0.31161690284512894 0.3224765647318107]\n",
      " [0.3627896881265138 0.3594304045155628 0.05371667522281413 ...,\n",
      "  -0.8281580549619725 0.3224765647318107 0.33423319733849216]]\n",
      "[[0.18960585175761918 0.20542762948356388 0.01889991251028123 ...,\n",
      "  0.19959731931373656 0.19793285635922062 0.07802202889493406]\n",
      " [0.20542762948356388 0.24769072752950858 -0.2505617019557743 ...,\n",
      "  0.23211681575968107 0.22767070595716532 -0.0926348340191213]\n",
      " [0.01889991251028123 -0.2505617019557743 2.9262026685781435 ...,\n",
      "  -0.15126535116560152 -0.1229177860113175 1.9192904740315972]\n",
      " ..., \n",
      " [0.19959731931373656 0.23211681575968107 -0.15126535116560152 ...,\n",
      "  0.22013341198985387 0.2167123364273379 -0.029747940988948646]\n",
      " [0.19793285635922062 0.22767070595716532 -0.1229177860113175 ...,\n",
      "  0.2167123364273379 0.213583892212022 -0.011794710247464582]\n",
      " [0.07802202889493406 -0.0926348340191213 1.9192904740315972 ...,\n",
      "  -0.029747940988948646 -0.011794710247464582 1.2815874873122501]]\n",
      "[[0.29518004975096107 0.32710813391530197 1.3779022097411306 ...,\n",
      "  0.04118956166262841 0.09198498411614214 0.5912568147729534]\n",
      " [0.32710813391530197 0.3678973884284423 1.710323911083071 ...,\n",
      "  0.002626320060569052 0.06751926521488277 0.7053566521084943]\n",
      " [1.3779022097411306 1.710323911083071 12.6507471650465 ...,\n",
      "  -1.2665392713200028 -0.7376788277848885 4.460528196625523]\n",
      " ..., \n",
      " [0.04118956166262841 0.002626320060569052 -1.2665392713200028 ...,\n",
      "  0.34796326303349534 0.28661175386460924 -0.3164166061089796]\n",
      " [0.09198498411614214 0.06751926521488277 -0.7376788277848885 ...,\n",
      "  0.28661175386460924 0.24768844982852295 -0.1348914820362659]\n",
      " [0.5912568147729534 0.7053566521084943 4.460528196625523 ...,\n",
      "  -0.3164166061089796 -0.1348914820362659 1.6493319111037454]]\n",
      "[[0.2272777075110144 0.2254187639583707 0.09720778864663365 ...,\n",
      "  -0.374748867971082 0.25421811873095534 0.2811613840095748]\n",
      " [0.2254187639583707 0.22363312823292708 0.10047817950678993 ...,\n",
      "  -0.35286676779892556 0.2512967744359117 0.2771775264217309]\n",
      " [0.09720778864663365 0.10047817950678993 0.32603640112945276 ...,\n",
      "  1.156337425599737 0.049812226528974414 0.002411643340393884]\n",
      " ..., \n",
      " [-0.374748867971082 -0.35286676779892556 1.156337425599737 ...,\n",
      "  6.711859981590026 -0.6918713411927413 -1.0090274102693213]\n",
      " [0.25421811873095534 0.2512967744359117 0.049812226528974414 ...,\n",
      "  -0.6918713411927413 0.29655518513169615 0.33889673670791565]\n",
      " [0.2811613840095748 0.2771775264217309 0.002411643340393884 ...,\n",
      "  -1.0090274102693213 0.33889673670791565 0.39663820587133497]]\n",
      "[[0.20836368861392382 0.30038518546964826 0.3665227607319378 ...,\n",
      "  0.12497139254652297 0.1185020684953553 0.3032606041933464]\n",
      " [0.30038518546964826 0.6924210824981727 0.9741846326596624 ...,\n",
      "  -0.05488803558335276 -0.08244906582332037 0.7046711262074707]\n",
      " [0.3665227607319378 0.9741846326596624 1.4109226141299505 ...,\n",
      "  -0.18415637907946308 -0.2268764140426308 0.9931723951273609]\n",
      " ..., \n",
      " [0.12497139254652297 -0.05488803558335276 -0.18415637907946308 ...,\n",
      "  0.2879647277303222 0.3006092614967545 -0.06050814811085449]\n",
      " [0.1185020684953553 -0.08244906582332037 -0.2268764140426308 ...,\n",
      "  0.3006092614967545 0.31473659098798684 -0.0887282361684221]\n",
      " [0.3032606041933464 0.7046711262074707 0.9931723951273609 ...,\n",
      "  -0.06050814811085449 -0.0887282361684221 0.717214101167969]]\n",
      "[[0.3887478011518335 0.38093062924513194 0.2206705998613755 ...,\n",
      "  -1.0243010838789088 0.3242531309354051 0.24216281929457306]\n",
      " [0.38093062924513194 0.37340638858962993 0.21915174983627383 ...,\n",
      "  -0.9791673698592107 0.31885275434390326 0.23983859581667133]\n",
      " [0.2206705998613755 0.21915174983627383 0.1880137689197177 ...,\n",
      "  -0.05388001257416705 0.20813950387854713 0.1921896343625151]\n",
      " ..., \n",
      " [-1.0243010838789088 -0.9791673698592107 -0.05388001257416705 ...,\n",
      "  7.134166586271155 -0.651930610760937 -0.17796883870256952]\n",
      " [0.3242531309354051 0.31885275434390326 0.20813950387854713 ...,\n",
      "  -0.651930610760937 0.2796979501781769 0.22298708304294482]\n",
      " [0.24216281929457306 0.23983859581667133 0.1921896343625151 ...,\n",
      "  -0.17796883870256952 0.22298708304294482 0.19857976132851268]]\n",
      "[[0.18311009382411078 0.18544280149095788 0.0632128370536925 ...,\n",
      "  0.19990458581302 0.20550274980932304 0.186141944982752]\n",
      " [0.18544280149095788 0.18960670447300493 -0.028574819362660188 ...,\n",
      "  0.21542111221906687 0.22541388246176997 0.19085468153919902]\n",
      " [0.0632128370536925 -0.028574819362660188 4.780944238254473 ...,\n",
      "  -0.5976188146245981 -0.8178960318506947 -0.056084799941266104]\n",
      " ..., \n",
      " [0.19990458581302 0.21542111221906687 -0.5976188146245981 ...,\n",
      "  0.31161690284512894 0.34885434185583203 0.22007162141326098]\n",
      " [0.20550274980932304 0.22541388246176997 -0.8178960318506947 ...,\n",
      "  0.34885434185583203 0.39663820587133497 0.23138151355676398]\n",
      " [0.186141944982752 0.19085468153919902 -0.056084799941266104 ...,\n",
      "  0.22007162141326098 0.23138151355676398 0.19226715132219319]]\n",
      "[[0.1822495337410375 0.18421606748007038 0.11422433732948377 ...,\n",
      "  0.17792428693008538 0.17438480805355647 0.16888020470664444]\n",
      " [0.18421606748007038 0.1880145466399032 0.05282127583011654 ...,\n",
      "  0.17586159099871845 0.1690248729285892 0.15839239778647723]\n",
      " [0.11422433732948377 0.05282127583011654 2.2382434862811302 ...,\n",
      "  0.24927587021773162 0.35979258031400224 0.5316683488966907]\n",
      " ..., \n",
      " [0.17792428693008538 0.17586159099871845 0.24927587021773162 ...,\n",
      "  0.1824610354343334 0.18617359247460408 0.19194736726529227]\n",
      " [0.17438480805355647 0.1690248729285892 0.35979258031400224 ...,\n",
      "  0.18617359247460408 0.1958207074860751 0.21082391655516336]\n",
      " [0.16888020470664444 0.15839239778647723 0.5316683488966907 ...,\n",
      "  0.19194736726529227 0.21082391655516336 0.24018075693305158]]\n",
      "[[2.3126020172724693 3.9872876967991058 0.5504589730214091 ...,\n",
      "  -0.4555886625892735 -0.14939830432229395 0.01305816575294513]\n",
      " [3.9872876967991058 6.977152807922538 0.8412824056424453 ...,\n",
      "  -0.9548437346914372 -0.40819317170125735 -0.11815490488361838]\n",
      " [0.5504589730214091 0.8412824056424453 0.24444782408554966 ...,\n",
      "  0.06973908300926795 0.12291164674184707 0.15112359651628618]\n",
      " ..., \n",
      " [-0.4555886625892735 -0.9548437346914372 0.06973908300926795 ...,\n",
      "  0.36966066888978627 0.27837960566556547 0.2299482984224045]\n",
      " [-0.14939830432229395 -0.40819317170125735 0.12291164674184707 ...,\n",
      "  0.27837960566556547 0.2310629693981446 0.2059580191725836]\n",
      " [0.01305816575294513 -0.11815490488361838 0.15112359651628618 ...,\n",
      "  0.2299482984224045 0.2059580191725836 0.19322941431022278]]\n",
      "[[0.27702016163710436 0.2397252761419141 0.007973261952875987 ...,\n",
      "  -0.043969532491604804 0.3249654680806196 -0.0572890370352519]\n",
      " [0.2397252761419141 0.2167871719267235 0.0742488108896855 ...,\n",
      "  0.04230155548520475 0.26921388888942926 0.03410943532555763]\n",
      " [0.007973261952875987 0.0742488108896855 0.4860879076894476 ...,\n",
      "  0.5783937874209667 -0.07722880962600877 0.6020634532069198]\n",
      " ..., \n",
      " [-0.043969532491604804 0.04230155548520475 0.5783937874209667 ...,\n",
      "  0.6985486378724858 -0.15487733379848959 0.7293595153704386]\n",
      " [0.3249654680806196 0.26921388888942926 -0.07722880962600877 ...,\n",
      "  -0.15487733379848959 0.39663820587133497 -0.1747884664509366]\n",
      " [-0.0572890370352519 0.03410943532555763 0.6020634532069198 ...,\n",
      "  0.7293595153704386 -0.1747884664509366 0.7620015881835919]]\n",
      "[[0.18841677793743894 0.19075262007738655 0.3371420277451059 ...,\n",
      "  0.13780367549798705 0.13780367549798705 0.3102780490941277]\n",
      " [0.19075262007738655 0.1937475575325341 0.38144308393945286 ...,\n",
      "  0.1258582191995345 0.1258582191995345 0.3469990029460749]\n",
      " [0.3371420277451059 0.38144308393945286 3.1578316353895723 ...,\n",
      "  -0.6227746793791467 -0.6227746793791467 2.6483354637657945]\n",
      " ..., \n",
      " [0.13780367549798705 0.1258582191995345 -0.6227746793791467 ...,\n",
      "  0.39663820587133497 0.39663820587133497 -0.48539275724932446]\n",
      " [0.13780367549798705 0.1258582191995345 -0.6227746793791467 ...,\n",
      "  0.39663820587133497 0.39663820587133497 -0.48539275724932446]\n",
      " [0.3102780490941277 0.3469990029460749 2.6483354637657945 ...,\n",
      "  -0.48539275724932446 -0.48539275724932446 2.226016290970815]]\n",
      "[[3.460527036069384 4.902060566882734 0.608435009516261 ...,\n",
      "  0.4999311203218101 1.2827035093589887 -0.6470895866174843]\n",
      " [4.902060566882734 6.97706141801608 0.7966455653536106 ...,\n",
      "  0.6404607402231597 1.767214533164339 -1.0106066073561348]\n",
      " [0.608435009516261 0.7966455653536106 0.2360580830399387 ...,\n",
      "  0.22189151885028763 0.3240924203802662 0.07213336186299331]\n",
      " ..., \n",
      " [0.4999311203218101 0.6404607402231597 0.22189151885028763 ...,\n",
      "  0.21131388747343632 0.28762338978421503 0.09949520235814205]\n",
      " [1.2827035093589887 1.767214533164339 0.3240924203802662 ...,\n",
      "  0.28762338978421503 0.5507194909237934 -0.09789950313907933]\n",
      " [-0.6470895866174843 -1.0106066073561348 0.07213336186299331 ...,\n",
      "  0.09949520235814205 -0.09789950313907933 0.3887437985228478]]\n",
      "[[1.0286203763881603 1.8405852994767087 0.7211714693069999 ...,\n",
      "  3.4645676161589973 1.044381708909551 -0.23663320486872502]\n",
      " [1.8405852994767087 3.4295698303924578 1.2389194596019488 ...,\n",
      "  6.607641575010744 1.8714296288940986 -0.6354679278665766]\n",
      " [0.7211714693069999 1.2389194596019488 0.5251272200626408 ...,\n",
      "  2.274448897916238 0.7312216549803912 -0.08561522834668486]\n",
      " ..., \n",
      " [3.4645676161589973 6.607641575010744 2.274448897916238 ...,\n",
      "  12.893992603309044 3.5255789140563887 -1.4331631472162871]\n",
      " [1.044381708909551 1.8714296288940986 0.7312216549803912 ...,\n",
      "  3.5255789140563887 1.0604358227109416 -0.2443751238993338]\n",
      " [-0.23663320486872502 -0.6354679278665766 -0.08561522834668486 ...,\n",
      "  -1.4331631472162871 -0.2443751238993338 0.38485554083118956]]\n",
      "[[0.2360580830399387 0.32308111503729503 0.8634321287564756 ...,\n",
      "  0.384805970857769 0.07010867883003696 0.07010867883003696]\n",
      " [0.32308111503729503 0.5455309673546519 1.9267860264178323 ...,\n",
      "  0.7033131630151253 -0.10112176104460675 -0.10112176104460675]\n",
      " [0.8634321287564756 1.9267860264178323 8.529455955925819 ...,\n",
      "  2.6810158494063048 -1.164340769187826 -1.164340769187826]\n",
      " ..., \n",
      " [0.384805970857769 0.7033131630151253 2.6810158494063048 ...,\n",
      "  0.9292281887555999 -0.22257436928813265 -0.22257436928813265]\n",
      " [0.07010867883003696 -0.10112176104460675 -1.164340769187826 ...,\n",
      "  -0.22257436928813265 0.39663820587133497 0.39663820587133497]\n",
      " [0.07010867883003696 -0.10112176104460675 -1.164340769187826 ...,\n",
      "  -0.22257436928813265 0.39663820587133497 0.39663820587133497]]\n",
      "[[0.3243251118283181 0.27557942456466966 -0.026644834777366413 ...,\n",
      "  -0.8520886660781677 0.2625781343206806 0.33407191989707763]\n",
      " [0.27557942456466966 0.2433133701138212 0.043263171712585174 ...,\n",
      "  -0.5031198439338159 0.23470747362343222 0.2820310935742294]\n",
      " [-0.026644834777366413 0.043263171712585174 0.476694243660149 ...,\n",
      "  1.660494000212149 0.06190880651179607 -0.04062309541900673]\n",
      " ..., \n",
      " [-0.8520886660781677 -0.5031198439338159 1.660494000212149 ...,\n",
      "  7.569820090895347 -0.41004402128180517 -0.9218657545214081]\n",
      " [0.2625781343206806 0.23470747362343222 0.06190880651179607 ...,\n",
      "  -0.41004402128180517 0.227273902176243 0.26815093461984035]\n",
      " [0.33407191989707763 0.2820310935742294 -0.04062309541900673 ...,\n",
      "  -0.9218657545214081 0.26815093461984035 0.34447759831463726]]\n",
      "[[0.3376160056321215 0.3274281368408689 0.05233307454544307 ...,\n",
      "  -0.07501789360655307 0.33082061542283403 -0.2550209639942767]\n",
      " [0.3274281368408689 0.31789936336481617 0.06060133698619047 ...,\n",
      "  -0.05851077098660565 0.3210723684939817 -0.22686869921112918]\n",
      " [0.05233307454544307 0.06060133698619047 0.2838627685787648 ...,\n",
      "  0.3872181658987686 0.057848071920155626 0.5333049144230455]\n",
      " ..., \n",
      " [-0.07501789360655307 -0.05851077098660565 0.3872181658987686 ...,\n",
      "  0.5935614247419727 -0.0640075104014405 0.8852154316534491]\n",
      " [0.33082061542283403 0.3210723684939817 0.057848071920155626 ...,\n",
      "  -0.0640075104014405 0.3243184565223467 -0.2362431775507641]\n",
      " [-0.2550209639942767 -0.22686869921112918 0.5333049144230455 ...,\n",
      "  0.8852154316534491 -0.2362431775507641 1.3826201590961267]]\n",
      "[[0.2167871719267235 0.1414215119079346 0.020182159981443248 ...,\n",
      "  0.19712641907992765 -0.005211231527141227 0.26839434133710727]\n",
      " [0.1414215119079346 0.22104063316914552 0.3491224500106543 ...,\n",
      "  0.16219187157313866 0.3759489850300698 0.0869017547903185]\n",
      " [0.020182159981443248 0.3491224500106543 0.8782826481129626 ...,\n",
      "  0.10599330715384739 0.9891144190491783 -0.20506203305297277]\n",
      " ..., \n",
      " [0.19712641907992765 0.16219187157313866 0.10599330715384739 ...,\n",
      "  0.18801299123793175 0.09422260625646275 0.22104809787911162]\n",
      " [-0.005211231527141227 0.3759489850300698 0.9891144190491783 ...,\n",
      "  0.09422260625646275 1.1175409544781938 -0.26621338905435743]\n",
      " [0.26839434133710727 0.0869017547903185 -0.20506203305297277 ...,\n",
      "  0.22104809787911162 -0.26621338905435743 0.39267267524029154]]\n",
      "[[0.39663820587133497 0.39663820587133497 -1.0408921545069925 ...,\n",
      "  -0.12700664125712657 0.14178549426413783 -0.14492176747226596]\n",
      " [0.39663820587133497 0.39663820587133497 -1.0408921545069925 ...,\n",
      "  -0.12700664125712657 0.14178549426413783 -0.14492176747226596]\n",
      " [-1.0408921545069925 -1.0408921545069925 7.06659629294188 ...,\n",
      "  1.912398200726146 0.39644473388581075 2.013437234632606]\n",
      " ..., \n",
      " [-0.12700664125712657 -0.12700664125712657 1.912398200726146 ...,\n",
      "  0.6158812073392124 0.2345494471356763 0.6412971541288724]\n",
      " [0.14178549426413783 0.14178549426413783 0.39644473388581075 ...,\n",
      "  0.2345494471356763 0.18693278265694072 0.23772312092053677]\n",
      " [-0.14492176747226596 -0.14492176747226596 2.013437234632606 ...,\n",
      "  0.6412971541288724 0.23772312092053677 0.6681955592033326]]\n",
      "[[0.20556290003563985 0.20692741408228887 0.13050903806267936 ...,\n",
      "  0.2376314254975698 0.13938012605566658 0.2369481204603846]\n",
      " [0.20692741408228887 0.2083651609417381 0.12784544742452833 ...,\n",
      "  0.24071704188661913 0.13719264244471588 0.23999706419663383]\n",
      " [0.13050903806267936 0.12784544742452833 0.2770174339265187 ...,\n",
      "  0.06790988460620938 0.25970068516430617 0.06924372569382407]\n",
      " ..., \n",
      " [0.2376314254975698 0.24071704188661913 0.06790988460620938 ...,\n",
      "  0.3101489404186998 0.08797034097679667 0.3086037623191147]\n",
      " [0.13938012605566658 0.13719264244471588 0.25970068516430617 ...,\n",
      "  0.08797034097679667 0.24547924153489356 0.08906576287721149]\n",
      " [0.2369481204603846 0.23999706419663383 0.06924372569382407 ...,\n",
      "  0.3086037623191147 0.08906576287721149 0.30707694871232943]]\n",
      "[[2.4137338572794462 3.3985943318769025 0.31611090643973555 ...,\n",
      "  -0.38095532995773235 -0.20188859845523 1.5503838860110175]\n",
      " [3.3985943318769025 4.817709901789561 0.37606528728359173 ...,\n",
      "  -0.628358765510676 -0.370336037131374 2.154566961389275]\n",
      " [0.31611090643973555 0.37606528728359173 0.1884159806048247 ...,\n",
      "  0.14598136606975678 0.15688223506985924 0.2635536007969074]\n",
      " ..., \n",
      " [-0.38095532995773235 -0.628358765510676 0.14598136606975678 ...,\n",
      "  0.3210889941458886 0.2761062522147911 -0.16407613286776093]\n",
      " [-0.20188859845523 -0.370336037131374 0.15688223506985924 ...,\n",
      "  0.2761062522147911 0.24547924153489356 -0.05422393417805851]\n",
      " [1.5503838860110175 2.154566961389275 0.2635536007969074 ...,\n",
      "  -0.16407613286776093 -0.05422393417805851 1.0207439479457907]]\n",
      "[[2.046500936491543 4.8408542206734415 2.584327832728755 ...,\n",
      "  0.46812311293139364 -0.23922595899218368 1.6256017798525466]\n",
      " [4.8408542206734415 11.818966363172139 6.183925770158652 ...,\n",
      "  0.8992991143868903 -0.8671064348742864 3.7897768453336433]\n",
      " [2.584327832728755 6.183925770158652 3.2771395102459646 ...,\n",
      "  0.5511112060646046 -0.3600736017949727 2.0421387886017586]\n",
      " ..., \n",
      " [0.46812311293139364 0.8992991143868903 0.5511112060646046 ...,\n",
      "  0.22457529719844405 0.11542949011966672 0.40317727505079626]\n",
      " [-0.23922595899218368 -0.8671064348742864 -0.3600736017949727 ...,\n",
      "  0.11542949011966672 0.27436811624408924 -0.14465153124718166]\n",
      " [1.6256017798525466 3.7897768453336433 2.0421387886017586 ...,\n",
      "  0.40317727505079626 -0.14465153124718166 1.2996231482183485]]\n",
      "[[0.8086102811184714 1.0596378986521182 2.12481618192227 ...,\n",
      "  -0.16498365099587115 -0.18872992918669673 0.1674642436756873]\n",
      " [1.0596378986521182 1.4109323365057655 2.9015699400959183 ...,\n",
      "  -0.302834232662224 -0.3360653788210495 0.1624018135613342]\n",
      " [2.12481618192227 2.9015699400959183 6.197546864006062 ...,\n",
      "  -0.8877716485920711 -0.9612496627188964 0.14092054918348673]\n",
      " ..., \n",
      " [-0.16498365099587115 -0.302834232662224 -0.8877716485920711 ...,\n",
      "  0.36966066888978627 0.38270082077896084 0.18709854244134466]\n",
      " [-0.18872992918669673 -0.3360653788210495 -0.9612496627188964 ...,\n",
      "  0.38270082077896084 0.39663820587133497 0.18757742948571923]\n",
      " [0.1674642436756873 0.1624018135613342 0.14092054918348673 ...,\n",
      "  0.18709854244134466 0.18757742948571923 0.18039412382010303]]\n",
      "[[0.2717661381784028 0.29248930076200985 0.1525973423843209 ...,\n",
      "  -0.1738136901841718 0.23549662455521247 0.29377985613795987]\n",
      " [0.29248930076200985 0.31789936336481617 0.14636843001112768 ...,\n",
      "  -0.25386607755256485 0.2480168121628193 0.3194818000591668]\n",
      " [0.1525973423843209 0.14636843001112768 0.18841677793743894 ...,\n",
      "  0.2865285266297466 0.16349913506513045 0.1459805183534782]\n",
      " ..., \n",
      " [-0.1738136901841718 -0.25386607755256485 0.2865285266297466 ...,\n",
      "  1.547435606573254 -0.03370664124736207 -0.2588514188806145]\n",
      " [0.23549662455521247 0.2480168121628193 0.16349913506513045 ...,\n",
      "  -0.03370664124736207 0.213583892212022 0.2487965191867696]\n",
      " [0.29377985613795987 0.3194818000591668 0.1459805183534782 ...,\n",
      "  -0.2588514188806145 0.2487965191867696 0.3210824139503174]]\n",
      "[[0.3444811509724228 0.3132584492834655 -0.04756385975521555 ...,\n",
      "  -0.04409644701715753 0.11896609761168948 0.0027438227010039744]\n",
      " [0.3132584492834655 0.28796760543130806 -0.004303728650573158 ...,\n",
      "  -0.0014950737493151867 0.1305879661947318 0.0364462280392464]\n",
      " [-0.04756385975521555 -0.004303728650573158 0.4956280373443459 ...,\n",
      "  0.49082381728880353 0.2648950322280507 0.4259250065077651]\n",
      " ..., \n",
      " [-0.04409644701715753 -0.0014950737493151867 0.49082381728880353 ...,\n",
      "  0.486092755070062 0.2636043746941088 0.4221822122186233]\n",
      " [0.11896609761168948 0.1305879661947318 0.2648950322280507 ...,\n",
      "  0.2636043746941088 0.20290842713095564 0.24616925762827013]\n",
      " [0.0027438227010039744 0.0364462280392464 0.4259250065077651 ...,\n",
      "  0.4221822122186233 0.24616925762827013 0.37162189325838413]]\n",
      "[[0.18054986873810405 0.17759895058676817 0.15451362595192678 ...,\n",
      "  0.09150634676129782 0.18948864905479773 0.1895754747447195]\n",
      " [0.17759895058676817 0.19581741531543226 0.33834226725659106 ...,\n",
      "  0.7273384490259611 0.12241244741546173 0.1218764004333836]\n",
      " [0.15451362595192678 0.33834226725659106 1.7764519145129491 ...,\n",
      "  5.701515888474313 -0.4023313139169795 -0.40774015543345754]\n",
      " ..., \n",
      " [0.09150634676129782 0.7273384490259611 5.701515888474313 ...,\n",
      "  19.277646682755677 -1.8345258876036084 -1.8532341533440866]\n",
      " [0.18948864905479773 0.12241244741546173 -0.4023313139169795 ...,\n",
      "  -1.8345258876036084 0.39267267524029154 0.3946462770774131]\n",
      " [0.1895754747447195 0.1218764004333836 -0.40774015543345754 ...,\n",
      "  -1.8532341533440866 0.3946462770774131 0.39663820587133497]]\n",
      "[[0.42340803762195967 0.2756664148361961 0.6597890149656618 ...,\n",
      "  -0.030361313372678084 -0.04513309833399654 0.174360281688895]\n",
      " [0.2756664148361961 0.21765073741363297 0.36848929217989873 ...,\n",
      "  0.0974787396559588 0.09167810544664032 0.177869504266332]\n",
      " [0.6597890149656618 0.36848929217989873 1.1258574923093643 ...,\n",
      "  -0.2349005360289757 -0.26402582099029415 0.16874565903259783]\n",
      " ..., \n",
      " [-0.030361313372678084 0.0974787396559588 -0.2349005360289757 ...,\n",
      "  0.3622829313574846 0.3750648795801664 0.1851384065086577]\n",
      " [-0.04513309833399654 0.09167810544664032 -0.26402582099029415 ...,\n",
      "  0.3750648795801664 0.3887437985228478 0.1854892722993392]\n",
      " [0.174360281688895 0.177869504266332 0.16874565903259783 ...,\n",
      "  0.1851384065086577 0.1854892722993392 0.18027577111903093]]\n",
      "[[0.29366102576680964 0.27059146045821686 0.09469525221577962 ...,\n",
      "  0.07018623815665102 0.14659955962357352 -0.08552520770903768]\n",
      " [0.27059146045821686 0.2522099951688246 0.11205867445278717 ...,\n",
      "  0.09253027913285844 0.1534152068461809 -0.031538141708830125]\n",
      " [0.09469525221577962 0.11205867445278717 0.24444782408554966 ...,\n",
      "  0.2628946545320211 0.20538179083414349 0.3800916430983326]\n",
      " ..., \n",
      " [0.07018623815665102 0.09253027913285844 0.2628946545320211 ...,\n",
      "  0.2866328744376925 0.21262270722621474 0.4374472864280038]\n",
      " [0.14659955962357352 0.1534152068461809 0.20538179083414349 ...,\n",
      "  0.21262270722621474 0.19004723884353747 0.2586259270245262]\n",
      " [-0.08552520770903768 -0.031538141708830125 0.3800916430983326 ...,\n",
      "  0.4374472864280038 0.2586259270245262 0.8018409796983156]]\n",
      "[[0.3887478011518335 0.38093062924513194 0.3731134573384298 ...,\n",
      "  0.02327199928646133 0.3926563871051844 0.08971996181751847]\n",
      " [0.38093062924513194 0.37340638858962993 0.36588214793412843 ...,\n",
      "  0.029150225818159597 0.38469274957288246 0.09310819771881669]\n",
      " [0.3731134573384298 0.36588214793412843 0.3586508385298267 ...,\n",
      "  0.03502845234985791 0.37672911204058074 0.09649643362011502]\n",
      " ..., \n",
      " [0.02327199928646133 0.029150225818159597 0.03502845234985791 ...,\n",
      "  0.2980963962498888 0.020332886020612125 0.24812996580814622]\n",
      " [0.3926563871051844 0.38469274957288246 0.37672911204058074 ...,\n",
      "  0.020332886020612125 0.39663820587133497 0.08802584386686933]\n",
      " [0.08971996181751847 0.09310819771881669 0.09649643362011502 ...,\n",
      "  0.24812996580814622 0.08802584386686933 0.2193290932032035]]\n",
      "[[3.810342092555233 9.158769283392319 0.27196838372349247 ...,\n",
      "  -0.6819313374443868 -0.7063928734683143 -0.10308623891777424]\n",
      " [9.158769283392319 22.3871053757846 0.4072625374277716 ...,\n",
      "  -1.952030327522508 -2.012531369850435 -0.5203650480806956]\n",
      " [0.27196838372349247 0.4072625374277716 0.18246145779094775 ...,\n",
      "  0.1583315498966685 0.15771276932874126 0.17297405225048135]\n",
      " ..., \n",
      " [-0.6819313374443868 -1.952030327522508 0.1583315498966685 ...,\n",
      "  0.38485554083118956 0.3906644583112625 0.24739633108260245]\n",
      " [-0.7063928734683143 -2.012531369850435 0.15771276932874126 ...,\n",
      "  0.3906644583112625 0.39663820587133497 0.24930479505867514]\n",
      " [-0.10308623891777424 -0.5203650480806956 0.17297405225048135 ...,\n",
      "  0.24739633108260245 0.24930479505867514 0.2022354296092152]]\n",
      "[[0.3514927619383246 0.344407918159623 -1.0974557379551861 ...,\n",
      "  0.3355491426821068 0.3213776412886104 -0.03288812751568153]\n",
      " [0.344407918159623 0.3376160056321215 -1.0446320911226878 ...,\n",
      "  0.329123506711405 0.31553794281550873 -0.024080288491183235]\n",
      " [-1.0974557379551861 -1.0446320911226878 9.705710320122503 ...,\n",
      "  -0.9785822470034043 -0.8729214296193009 1.7684367203540072]\n",
      " ..., \n",
      " [0.3355491426821068 0.329123506711405 -0.9785822470034043 ...,\n",
      "  0.3210889941458886 0.30823607713639245 -0.013067107283899638]\n",
      " [0.3213776412886104 0.31553794281550873 -0.8729214296193009 ...,\n",
      "  0.30823607713639245 0.29655518513169615 0.00455082571620411]\n",
      " [-0.03288812751568153 -0.024080288491183235 1.7684367203540072 ...,\n",
      "  -0.013067107283899638 0.00455082571620411 0.44497209130551224]]\n",
      "[[0.21440907963073477 0.41720693459729036 0.4758211742066947 ...,\n",
      "  0.09400163024863484 0.09400163024863484 0.15658248483596568]\n",
      " [0.41720693459729036 1.8200719905046454 2.2255391417236505 ...,\n",
      "  -0.41571806471760947 -0.41571806471760947 0.01718835869532139]\n",
      " [0.4758211742066947 2.2255391417236505 2.731256464097853 ...,\n",
      "  -0.5630412814218051 -0.5630412814218051 -0.023100433861674333]\n",
      " ..., \n",
      " [0.09400163024863484 -0.41571806471760947 -0.5630412814218051 ...,\n",
      "  0.39663820587133497 0.39663820587133497 0.23934515108906596]\n",
      " [0.09400163024863484 -0.41571806471760947 -0.5630412814218051 ...,\n",
      "  0.39663820587133497 0.39663820587133497 0.23934515108906596]\n",
      " [0.15658248483596568 0.01718835869532139 -0.023100433861674333 ...,\n",
      "  0.23934515108906596 0.23934515108906596 0.19632988576599672]]\n",
      "[[3.7454319399284506 11.388897518839842 0.6589554807511877 ...,\n",
      "  -0.6822727950854559 -0.6984312747577054 -0.21364378990580218]\n",
      " [11.388897518839842 35.41883098063123 1.6854687299345734 ...,\n",
      "  -2.531156031790071 -2.581955919270322 -1.0578552500344183]\n",
      " [0.6589554807511877 1.6854687299345734 0.24444337941072097 ...,\n",
      "  0.06431715510687717 0.062147080119428134 0.12725377434093119]\n",
      " ..., \n",
      " [-0.6822727950854559 -2.531156031790071 0.06431715510687717 ...,\n",
      "  0.3887478011518335 0.3926563871051844 0.2753908032082874]\n",
      " [-0.6984312747577054 -2.581955919270322 0.062147080119428134 ...,\n",
      "  0.3926563871051844 0.39663820587133497 0.2771754876000381]\n",
      " [-0.21364378990580218 -1.0578552500344183 0.12725377434093119 ...,\n",
      "  0.2753908032082874 0.2771754876000381 0.22363130057994146]]\n",
      "[[0.2522099951688246 0.26829407138166617 -0.7265400973819579 ...,\n",
      "  -0.3233253758466734 0.2579528796909553 0.2464635816312153]\n",
      " [0.26829407138166617 0.28796760543130806 -0.9288821305387167 ...,\n",
      "  -0.43568261764983196 0.27531858635499706 0.26126523982805694]\n",
      " [-0.7265400973819579 -0.9288821305387167 11.586401041318457 ...,\n",
      "  6.513850683154542 -0.7987871394262281 -0.6542486593675674]\n",
      " ..., \n",
      " [-0.3233253758466734 -0.43568261764983196 6.513850683154542 ...,\n",
      "  3.6971459270578304 -0.36344298386854273 -0.28318311546428304]\n",
      " [0.2579528796909553 0.27531858635499706 -0.7987871394262281 ...,\n",
      "  -0.36344298386854273 0.26415337555388596 0.25174857360934605]\n",
      " [0.2464635816312153 0.26126523982805694 -0.6542486593675674 ...,\n",
      "  -0.28318311546428304 0.25174857360934605 0.24117534201360613]]\n",
      "[[0.18014849452752915 0.18074303143761927 0.17558149083319288 ...,\n",
      "  0.18062139834530838 0.17687862453859066 0.1751896250112806]\n",
      " [0.18074303143761927 0.21678884962770942 -0.09614706915271691 ...,\n",
      "  0.20941443055139855 -0.01750393544731905 -0.11990526470262913]\n",
      " [0.17558149083319288 -0.09614706915271691 2.262895694966059 ...,\n",
      "  -0.040555592056227746 1.6700506286714545 2.4419949799537455]\n",
      " ..., \n",
      " [0.18062139834530838 0.20941443055139855 -0.040555592056227746 ...,\n",
      "  0.20352381975028738 0.022263741649169944 -0.05953339652774007]\n",
      " [0.17687862453859066 -0.01750393544731905 1.6700506286714545 ...,\n",
      "  0.022263741649169944 1.2459555623768528 1.7981703136591434]\n",
      " [0.1751896250112806 -0.11990526470262913 2.4419949799537455 ...,\n",
      "  -0.05953339652774007 1.7981703136591434 2.6364952700742315]]\n",
      "[[0.20761527698243298 0.15370642022565065 -0.6307861640430685 ...,\n",
      "  0.21612712527783084 0.2558471471126403 0.1005100921127616]\n",
      " [0.15370642022565065 0.20556569481606835 0.9602323449601495 ...,\n",
      "  0.14551818726024854 0.10730829665985803 0.25673953067117944]\n",
      " [-0.6307861640430685 0.9602323449601495 24.113055402931405 ...,\n",
      "  -0.8819973563876706 -2.0542590907128626 2.53022191124726]\n",
      " ..., \n",
      " [0.21612712527783084 0.14551818726024854 -0.8819973563876706 ...,\n",
      "  0.22727580482442872 0.2793004391520381 0.07584250759535952]\n",
      " [0.2558471471126403 0.10730829665985803 -2.0542590907128626 ...,\n",
      "  0.2793004391520381 0.3887437985228478 -0.03926727369303104]\n",
      " [0.1005100921127616 0.25673953067117944 2.53022191124726 ...,\n",
      "  0.07584250759535952 -0.03926727369303104 0.4109040404462905]]\n",
      "[[4.177981323782377 8.438919641801036 0.39628927060191277 ...,\n",
      "  -0.7330904164512959 0.47327391309717337 -0.5533982555798049]\n",
      " [8.438919641801036 17.24120594632851 0.6266647619581731 ...,\n",
      "  -1.7064183784198375 0.7857003578102326 -1.3352086286843459]\n",
      " [0.39628927060191277 0.6266647619581731 0.19182511273665007 ...,\n",
      "  0.13076311631384163 0.19598742946551023 0.1404785045133327]\n",
      " ..., \n",
      " [-0.7330904164512959 -1.7064183784198375 0.13076311631384163 ...,\n",
      "  0.3887478011518335 0.11317748150990214 0.3477006440073244]\n",
      " [0.47327391309717337 0.7857003578102326 0.19598742946551023 ...,\n",
      "  0.11317748150990214 0.2016322044791708 0.12635312001339324]\n",
      " [-0.5533982555798049 -1.3352086286843459 0.1404785045133327 ...,\n",
      "  0.3477006440073244 0.12635312001339324 0.31473016078281557]]\n",
      "[[0.20485009149634542 0.22099584695292704 0.1698722134210376 ...,\n",
      "  0.23982865838374598 0.015831098659019046 0.03870103776607634]\n",
      " [0.22099584695292704 0.24769072752950858 0.16316453143761922 ...,\n",
      "  0.2788283013283277 -0.09152216770839931 -0.053709734905342046]\n",
      " [0.1698722134210376 0.16316453143761922 0.18440361662572982 ...,\n",
      "  0.15534052405243828 0.24839930967171128 0.23889809562676861]\n",
      " ..., \n",
      " [0.23982865838374598 0.2788283013283277 0.15534052405243828 ...,\n",
      "  0.3243184565223467 -0.21674169227118037 -0.16149996253372298]\n",
      " [0.015831098659019046 -0.09152216770839931 0.24839930967171128 ...,\n",
      "  -0.21674169227118037 1.2726200015464926 1.1205575804743504]\n",
      " [0.03870103776607634 -0.053709734905342046 0.23889809562676861 ...,\n",
      "  -0.16149996253372298 1.1205575804743504 0.9896607172390072]]\n",
      "[[0.9973667254979351 0.7807467785647451 0.7265937724110012 ...,\n",
      "  2.471199155651523 -0.13604765214694087 -0.21727914195711057]\n",
      " [0.7807467785647451 0.621545556674754 0.5817467067962099 ...,\n",
      "  1.8639153743631325 -0.05223723968173126 -0.1119369700935009]\n",
      " [0.7265937724110012 0.5817467067962099 0.5455362647448659 ...,\n",
      "  1.7120999815021891 -0.03128540285307531 -0.08560239028244496]\n",
      " ..., \n",
      " [2.471199155651523 1.8639153743631325 1.7120999815021891 ...,\n",
      "  6.603018703392312 -0.706274473935752 -0.9340031156883216]\n",
      " [-0.13604765214694087 -0.05223723968173126 -0.03128540285307531 ...,\n",
      "  -0.706274473935752 0.3024711815489836 0.33389970307961403]\n",
      " [-0.21727914195711057 -0.1119369700935009 -0.08560239028244496 ...,\n",
      "  -0.9340031156883216 0.33389970307961403 0.37340253595104456]]\n",
      "[[0.1844041889727441 0.1760198824827926 0.23359162432974112 ...,\n",
      "  0.15058764830036692 0.1584130391820693 0.1969802194330107]\n",
      " [0.1760198824827926 0.18411520880564106 0.12852778034218942 ...,\n",
      "  0.20867087540401533 0.20111520066011776 0.16387730747745924]\n",
      " [0.23359162432974112 0.12852778034218942 0.8499599597059376 ...,\n",
      "  -0.1901638475938362 -0.09210378171693394 0.39118201106520756]\n",
      " ..., \n",
      " [0.15058764830036692 0.20867087540401533 -0.1901638475938362 ...,\n",
      "  0.38485554083118956 0.33064426452569184 0.06346578149343353]\n",
      " [0.1584130391820693 0.20111520066011776 -0.09210378171693394 ...,\n",
      "  0.33064426452569184 0.29078871947139473 0.09436198330633594]\n",
      " [0.1969802194330107 0.16387730747745924 0.39118201106520756 ...,\n",
      "  0.06346578149343353 0.09436198330633594 0.24663289250447748]]\n",
      "[[0.3376160056321215 0.35799174321462646 0.06252268217758845 ...,\n",
      "  0.35968885192605554 -0.052945047312618905 0.22893497214673708]\n",
      " [0.35799174321462646 0.3810038620579316 0.047304572912093584 ...,\n",
      "  0.38292055671496106 -0.08310332534611384 0.2352486597580422]\n",
      " [0.06252268217758845 0.047304572912093584 0.26798274160305546 ...,\n",
      "  0.04603704648752259 0.3542225901928481 0.1436937237642042]\n",
      " ..., \n",
      " [0.35968885192605554 0.38292055671496106 0.04603704648752259 ...,\n",
      "  0.38485554083118956 -0.08561522834668486 0.23577453099107135]\n",
      " [-0.052945047312618905 -0.08310332534611384 0.3542225901928481 ...,\n",
      "  -0.08561522834668486 0.5251272200626408 0.10791454422599683]\n",
      " [0.22893497214673708 0.2352486597580422 0.1436937237642042 ...,\n",
      "  0.23577453099107135 0.10791454422599683 0.19525873873815283]]\n",
      "[[1.9314219757050501 4.706186974763121 1.206593285988156 ...,\n",
      "  11.733816857637589 -0.16380199247090538 -0.4356149256182067]\n",
      " [4.706186974763121 11.877339544169994 2.8329266725726274 ...,\n",
      "  30.03967260968127 -0.7087475324720349 -1.4112257656193352]\n",
      " [1.206593285988156 2.8329266725726274 0.7817597962904604 ...,\n",
      "  6.951931024637497 -0.021450419685401182 -0.18076425283270234]\n",
      " ..., \n",
      " [11.733816857637589 30.03967260968127 6.951931024637497 ...,\n",
      "  76.40279848099732 -2.0889276784487683 -3.8821492115960687]\n",
      " [-0.16380199247090538 -0.7087475324720349 -0.021450419685401182 ...,\n",
      "  -2.0889276784487683 0.2476861721659372 0.30106843901863617]\n",
      " [-0.4356149256182067 -1.4112257656193352 -0.18076425283270234 ...,\n",
      "  -3.8821492115960687 0.30106843901863617 0.39663820587133497]]\n",
      "[[0.3054841606280273 -0.6580383366699637 0.2933666931531168 ...,\n",
      "  -0.062656632689233 0.3448725230896812 0.1797392568197634]\n",
      " [-0.6580383366699637 5.78496424729284 -0.5770097416232742 ...,\n",
      "  1.8036915028063767 -0.9214253585923095 0.18280839231537255]\n",
      " [0.2933666931531168 -0.5770097416232742 0.2824206507214063 ...,\n",
      "  -0.039185034576943514 0.3289472868467705 0.17977785493205295]\n",
      " ..., \n",
      " [-0.062656632689233 1.8036915028063767 -0.039185034576943514 ...,\n",
      "  0.6504340166047069 -0.1389520975555791 0.18091190611370334]\n",
      " [0.3448725230896812 -0.9214253585923095 0.3289472868467705 ...,\n",
      "  -0.1389520975555791 0.39663820587133497 0.1796137919534173]\n",
      " [0.1797392568197634 0.18280839231537255 0.17977785493205295 ...,\n",
      "  0.18091190611370334 0.1796137919534173 0.18013979562269966]]\n",
      "[[0.2666560026251153 0.2792416276878696 0.03506374641403026 ...,\n",
      "  0.24022167901660652 -0.26952642401152216 0.16344614400757346]\n",
      " [0.2792416276878696 0.29365807307062386 0.013959840244784496 ...,\n",
      "  0.24896192519936078 -0.3349388067567682 0.16101791751832767]\n",
      " [0.03506374641403026 0.013959840244784496 0.4234037152461451 ...,\n",
      "  0.0793895134935213 0.9341485010381922 0.20812874407168835]\n",
      " ..., \n",
      " [0.24022167901660652 0.24896192519936078 0.0793895134935213 ...,\n",
      "  0.22186402932809762 -0.13213697494803134 0.16854628996706467]\n",
      " [-0.26952642401152216 -0.3349388067567682 0.9341485010381922 ...,\n",
      "  -0.13213697494803134 2.51722194466704 0.2668953064397355]\n",
      " [0.16344614400757346 0.16101791751832767 0.20812874407168835 ...,\n",
      "  0.16854628996706467 0.2668953064397355 0.18335909321723157]]\n",
      "[[0.1817090959540207 0.1861184651801811 0.19086680292908353 ...,\n",
      "  0.16220746582620515 0.18306566465261725 0.1874752075306847]\n",
      " [0.1861184651801811 0.2029071047551415 0.22098636438564398 ...,\n",
      "  0.1118661577531655 0.19128359011557752 0.20807289086884528]\n",
      " [0.19086680292908353 0.22098636438564398 0.2534213552673462 ...,\n",
      "  0.05765488144766802 0.20013326536208004 0.23025401300174775]\n",
      " ..., \n",
      " [0.16220746582620515 0.1118661577531655 0.05765488144766802 ...,\n",
      "  0.38485554083118956 0.1467196626336018 0.09637637199486933]\n",
      " [0.18306566465261725 0.19128359011557752 0.20013326536208004 ...,\n",
      "  0.1467196626336018 0.1855939583560139 0.19381220746128147]\n",
      " [0.1874752075306847 0.20807289086884528 0.23025401300174775 ...,\n",
      "  0.09637637199486933 0.19381220746128147 0.21441070198734893]]\n",
      "[[0.31789611068783075 0.30519122937682724 0.14954342268589288 ...,\n",
      "  -0.2236844212648853 0.233722206180201 -0.3475667720205255]\n",
      " [0.30519122937682724 0.29365807307062386 0.15236509761168948 ...,\n",
      "  -0.18644129945268875 0.22878037800199755 -0.29889843146912887]\n",
      " [0.14954342268589288 0.15236509761168948 0.18693350503275488 ...,\n",
      "  0.269825082144377 0.1682379220630631 0.2973385798559367]\n",
      " ..., \n",
      " [-0.2236844212648853 -0.18644129945268875 0.269825082144377 ...,\n",
      "  1.3639061456111992 0.02306317930268502 1.727055187828358]\n",
      " [0.233722206180201 0.22878037800199755 0.1682379220630631 ...,\n",
      "  0.02306317930268502 0.2009810130133715 -0.02512344100175521]\n",
      " [-0.3475667720205255 -0.29889843146912887 0.2973385798559367 ...,\n",
      "  1.727055187828358 -0.02512344100175521 2.201608887882317]]\n",
      "[[0.23500260756121782 0.2370080917346616 0.054589087102527176 ...,\n",
      "  0.24502489668797206 0.0726302338787777 -0.25712617122352616]\n",
      " [0.2370080917346616 0.2390868837353052 0.049999793138370933 ...,\n",
      "  0.2473967324134157 0.06870041022502137 -0.2731098050660825]\n",
      " [0.054589087102527176 0.049999793138370933 0.4674423479046369 ...,\n",
      "  0.03165436061328143 0.4261574915576872 1.1807628380457833]\n",
      " ..., \n",
      " [0.24502489668797206 0.2473967324134157 0.03165436061328143 ...,\n",
      "  0.2568780061347264 0.052991171453531875 -0.337003440656772]\n",
      " [0.0726302338787777 0.06870041022502137 0.4261574915576872 ...,\n",
      "  0.052991171453531875 0.39080516802353743 1.0369755731100334]\n",
      " [-0.25712617122352616 -0.2731098050660825 1.1807628380457833 ...,\n",
      "  -0.337003440656772 1.0369755731100334 3.6651217864717287]]\n",
      "[[0.39663820587133497 0.38867456833903336 -0.7063949122900066 ...,\n",
      "  0.3050522966064797 0.27120174003996533 -0.25443299706072503]\n",
      " [0.38867456833903336 0.3810038620579316 -0.6737850216943088 ...,\n",
      "  0.30045751845337826 0.2678521071924639 -0.23844789241062675]\n",
      " [-0.7063949122900066 -0.6737850216943088 3.810358789868651 ...,\n",
      "  -0.33136447310686223 -0.19275156640937677 1.9596431402339327]\n",
      " ..., \n",
      " [0.3050522966064797 0.30045751845337826 -0.33136447310686223 ...,\n",
      "  0.2522099951688246 0.2326792471719103 -0.07059610868718032]\n",
      " [0.27120174003996533 0.2678521071924639 -0.19275156640937677 ...,\n",
      "  0.2326792471719103 0.21844116366779598 -0.002649182802494597]\n",
      " [-0.25443299706072503 -0.23844789241062675 1.9596431402339327 ...,\n",
      "  -0.07059610868718032 -0.002649182802494597 1.0524372957320154]]\n",
      "[[0.39663820587133497 0.39663820587133497 -0.9931062516697963 ...,\n",
      "  0.2751835588061163 0.13581378552575812 -0.05134596823518182]\n",
      " [0.39663820587133497 0.39663820587133497 -0.9931062516697963 ...,\n",
      "  0.2751835588061163 0.13581378552575812 -0.05134596823518182]\n",
      " [-0.9931062516697963 -0.9931062516697963 6.538130786104269 ...,\n",
      "  -0.3349250073238156 0.42034103657342614 1.4345882687580862]\n",
      " ..., \n",
      " [0.2751835588061163 0.2751835588061163 -0.3349250073238156 ...,\n",
      "  0.22186402932809762 0.16067962087333926 0.07851504134599943]\n",
      " [0.13581378552575812 0.13581378552575812 0.42034103657342614 ...,\n",
      "  0.16067962087333926 0.18921328276738114 0.2275311547728412]\n",
      " [-0.05134596823518182 -0.05134596823518182 1.4345882687580862 ...,\n",
      "  0.07851504134599943 0.2275311547728412 0.4276449846151015]]\n",
      "[[0.4583463124783524 0.36806669044955465 0.60731161784531 ...,\n",
      "  2.3587667928843525 -0.05625585336225785 -0.05625585336225785]\n",
      " [0.36806669044955465 0.30708319342555807 0.46869211457491267 ...,\n",
      "  1.651792564647555 0.02045513710174481 0.02045513710174481]\n",
      " [0.60731161784531 0.46869211457491267 0.8360398310394674 ...,\n",
      "  3.5253050373873105 -0.18283232613290035 -0.18283232613290035]\n",
      " ..., \n",
      " [2.3587667928843525 1.651792564647555 3.5253050373873105 ...,\n",
      "  17.240843968970353 -1.6710514636442564 -1.6710514636442564]\n",
      " [-0.05625585336225785 0.02045513710174481 -0.18283232613290035 ...,\n",
      "  -1.6710514636442564 0.3810038620579316 0.3810038620579316]\n",
      " [-0.05625585336225785 0.02045513710174481 -0.18283232613290035 ...,\n",
      "  -1.6710514636442564 0.3810038620579316 0.3810038620579316]]\n",
      "[[0.3887478011518335 0.38483921519848246 0.2753968071805659 ...,\n",
      "  0.351613232608861 -0.1643541357430297 -0.1330854481162227]\n",
      " [0.38483921519848246 0.3810038620579316 0.273612010296015 ...,\n",
      "  0.3484004146235103 -0.15789958497958043 -0.12721675985517356]\n",
      " [0.2753968071805659 0.273612010296015 0.22363678365409834 ...,\n",
      "  0.2584398659655936 0.02283114133850299 0.03710951641490983]\n",
      " ..., \n",
      " [0.351613232608861 0.3484004146235103 0.2584398659655936 ...,\n",
      "  0.3210889941458886 -0.103030946078002 -0.07732840219519507]\n",
      " [-0.1643541357430297 -0.15789958497958043 0.02283114133850299 ...,\n",
      "  -0.103030946078002 0.7490259387029075 0.6973895325953148]\n",
      " [-0.1330854481162227 -0.12721675985517356 0.03710951641490983 ...,\n",
      "  -0.07732840219519507 0.6973895325953148 0.650440026506921]]\n",
      "[[0.37340638858962993 0.3621200276063775 -0.8418374567585002 ...,\n",
      "  0.12132698967028743 0.3320172859976922 0.2755797020947508]\n",
      " [0.3621200276063775 0.3514927619383246 -0.7821566099337538 ...,\n",
      "  0.12476143649503486 0.3231479453152395 0.2700061754666983]\n",
      " [-0.8418374567585002 -0.7821566099337538 5.584218018213365 ...,\n",
      "  0.49112646464215615 -0.6229771265184385 -0.3245423338453804]\n",
      " ..., \n",
      " [0.12132698967028743 0.12476143649503486 0.49112646464215615 ...,\n",
      "  0.19803491107094484 0.13392171991034948 0.15109571258340823]\n",
      " [0.3320172859976922 0.3231479453152395 -0.6229771265184385 ...,\n",
      "  0.13392171991034948 0.29949182876895397 0.2551405839636128]\n",
      " [0.2755797020947508 0.2700061754666983 -0.3245423338453804 ...,\n",
      "  0.15109571258340823 0.2551405839636128 0.2272700969950715]]\n",
      "[[0.18096997385582003 0.17307296535603564 0.08226014726655935 ...,\n",
      "  0.19355525468917748 0.19355525468917748 0.16678045128744962]\n",
      " [0.17307296535603564 0.24018075693305138 1.0118967388819746 ...,\n",
      "  0.0661248212421932 0.0661248212421932 0.29365375529966553]\n",
      " [0.08226014726655935 1.0118967388819746 11.702390320850105 ...,\n",
      "  -1.399280309320883 -1.399280309320883 1.7526520934661902]\n",
      " ..., \n",
      " [0.19355525468917748 0.0661248212421932 -1.399280309320883 ...,\n",
      "  0.39663820587133497 0.39663820587133497 -0.035414615527192626]\n",
      " [0.19355525468917748 0.0661248212421932 -1.399280309320883 ...,\n",
      "  0.39663820587133497 0.39663820587133497 -0.035414615527192626]\n",
      " [0.16678045128744962 0.29365375529966553 1.7526520934661902 ...,\n",
      "  -0.035414615527192626 -0.035414615527192626 0.39474925879907924]]\n",
      "[[2.6768757391624582 10.41189412260996 0.35094828976644704 ...,\n",
      "  -0.48746097810355044 -0.41308679994742664 1.3110689407873013]\n",
      " [10.41189412260996 42.11039133144621 0.8801255982571408 ...,\n",
      "  -2.555718057177654 -2.250928907130333 4.814748668017197]\n",
      " [0.35094828976644704 0.8801255982571408 0.19182416537523556 ...,\n",
      "  0.1344659099980382 0.13955408503096223 0.2575090851448898]\n",
      " ..., \n",
      " [-0.48746097810355044 -2.555718057177654 0.1344659099980382 ...,\n",
      "  0.35864713588164066 0.3387603155993649 -0.12225957335550766]\n",
      " [-0.41308679994742664 -2.250928907130333 0.13955408503096223 ...,\n",
      "  0.3387603155993649 0.3210889941458886 -0.08857079754178376]\n",
      " [1.3110689407873013 4.814748668017197 0.2575090851448898 ...,\n",
      "  -0.12225957335550766 -0.08857079754178376 0.6924085377273439]]\n",
      "[[0.18526837242932842 0.18894653143761916 0.12887547873984317 ...,\n",
      "  0.16442745901093542 0.12397241746112937 0.2005917334991924]\n",
      " [0.18894653143761916 0.19526197172591006 0.09211930021213419 ...,\n",
      "  0.15316244925122607 0.08370068898142029 0.21525691433148336]\n",
      " [0.12887547873984317 0.09211930021213419 0.6924148100935579 ...,\n",
      "  0.33714062784305 0.7414115487572438 -0.02425226637909269]\n",
      " ..., \n",
      " [0.16442745901093542 0.15316244925122607 0.33714062784305 ...,\n",
      "  0.22825642685334235 0.35215711653553633 0.11749696698639929]\n",
      " [0.12397241746112937 0.08370068898142029 0.7414115487572438 ...,\n",
      "  0.35215711653553633 0.7950945874977304 -0.0438012527394066]\n",
      " [0.2005917334991924 0.21525691433148336 -0.02425226637909269 ...,\n",
      "  0.11749696698639929 -0.0438012527394066 0.26168747746825666]]\n",
      "[[3.307301648358836 5.653111576280918 0.598320379172094 ...,\n",
      "  -0.6048430517423382 -0.31729850624339034 0.5377801993239905]\n",
      " [5.653111576280918 9.758607199767807 0.9120152869469765 ...,\n",
      "  -1.1936890760378553 -0.6904458852525075 0.8060615008140732]\n",
      " [0.598320379172094 0.9120152869469765 0.23606015540615305 ...,\n",
      "  0.07516636899732047 0.11361844416666869 0.22796438178524944]\n",
      " ..., \n",
      " [-0.6048430517423382 -1.1936890760378553 0.07516636899732047 ...,\n",
      "  0.3771848720476878 0.3050053401898361 0.09036318600681673]\n",
      " [-0.31729850624339034 -0.6904458852525075 0.11361844416666869 ...,\n",
      "  0.3050053401898361 0.2592657036471843 0.123248554929765]\n",
      " [0.5377801993239905 0.8060615008140732 0.22796438178524944 ...,\n",
      "  0.09036318600681673 0.123248554929765 0.22104063316914557]]\n",
      "[[0.30708007104974366 0.68213130284441 0.8010478156777557 ...,\n",
      "  0.03112931583586325 0.36653910805557 0.17901505333654363]\n",
      " [0.68213130284441 2.165278580002278 2.6355362068708232 ...,\n",
      "  -0.40912124221906937 0.9172632031334371 0.17569573826401086]\n",
      " [0.8010478156777557 2.6355362068708232 3.2171926415665713 ...,\n",
      "  -0.548710334851324 1.0918798511219823 0.17464329171815632]\n",
      " ..., \n",
      " [0.03112931583586325 -0.40912124221906937 -0.548710334851324 ...,\n",
      "  0.35505165945078276 -0.03866614676791034 0.1814572996842631]\n",
      " [0.36653910805557 0.9172632031334371 1.0918798511219823 ...,\n",
      "  -0.03866614676791034 0.4538485782645956 0.17848882315516984]\n",
      " [0.17901505333654363 0.17569573826401086 0.17464329171815632 ...,\n",
      "  0.1814572996842631 0.17848882315516984 0.1801484668745435]]\n",
      "[[0.18960499908063363 0.16212682294928418 -0.11598371435964192 ...,\n",
      "  0.11299838665194836 0.2254098048183843 0.13756303112950902]\n",
      " [0.16212682294928418 0.21440907963073474 0.7435652517106084 ...,\n",
      "  0.3078849167669988 0.09400163024863492 0.2611461870301596]\n",
      " [-0.11598371435964192 0.7435652517106084 9.443182855675277 ...,\n",
      "  2.280359266792473 -1.2359992352266904 1.511948923193234]\n",
      " ..., \n",
      " [0.11299838665194836 0.3078849167669988 2.280359266792473 ...,\n",
      "  0.6563239992664627 -0.1409440263495009 0.48210143431682384]\n",
      " [0.2254098048183843 0.09400163024863492 -1.2359992352266904 ...,\n",
      "  -0.1409440263495009 0.39663820587133497 -0.023469159228740214]\n",
      " [0.13756303112950902 0.2611461870301596 1.511948923193234 ...,\n",
      "  0.48210143431682384 -0.023469159228740214 0.37162189325838446]]\n",
      "[[0.2770174339265187 0.2530451181831612 0.03194936522263367 ...,\n",
      "  -0.17182691128429547 0.21841298450442873 -0.22377033834246915]\n",
      " [0.2530451181831612 0.23500466027660366 0.06861820569687609 ...,\n",
      "  -0.08473441063085312 0.20894211560907108 -0.12382463534662685]\n",
      " [0.03194936522263367 0.06861820569687609 0.4068135215619483 ...,\n",
      "  0.718516398149419 0.12159265333654362 0.797970767968045]\n",
      " ..., \n",
      " [-0.17182691128429547 -0.08473441063085312 0.718516398149419 ...,\n",
      "  1.4588447704616894 0.041085687741614405 1.6475575758259164]\n",
      " [0.21841298450442873 0.20894211560907108 0.12159265333654362 ...,\n",
      "  0.041085687741614405 0.19525981636233858 0.020564124747440658]\n",
      " [-0.22377033834246915 -0.12382463534662685 0.797970767968045 ...,\n",
      "  1.6475575758259164 0.020564124747440658 1.8641208143933443]]\n",
      "[[0.3887478011518335 0.3926563871051844 0.33402759780492147 ...,\n",
      "  0.34574935301678855 0.3926563871051844 0.058451274190711694]\n",
      " [0.3926563871051844 0.39663820587133497 0.33691092437907244 ...,\n",
      "  0.348852303034139 0.39663820587133497 0.05617129373766252]\n",
      " [0.33402759780492147 0.33691092437907244 0.29366102576680964 ...,\n",
      "  0.3023080527738765 0.33691092437907244 0.09037100053339983]\n",
      " ..., \n",
      " [0.34574935301678855 0.348852303034139 0.3023080527738765 ...,\n",
      "  0.31161372520174324 0.348852303034139 0.08353339402366662]\n",
      " [0.3926563871051844 0.39663820587133497 0.33691092437907244 ...,\n",
      "  0.348852303034139 0.39663820587133497 0.05617129373766252]\n",
      " [0.058451274190711694 0.05617129373766252 0.09037100053339983 ...,\n",
      "  0.08353339402366662 0.05617129373766252 0.25112188043278993]]\n",
      "[[0.5352532122199393 1.8714482965449815 0.173157225263085 ...,\n",
      "  0.012512904062268751 0.05586091576954012 0.8514474644739358]\n",
      " [1.8714482965449815 8.235363612466827 0.14688859395292725 ...,\n",
      "  -0.6182143974430889 -0.41176020609421804 3.3773911549877793]\n",
      " [0.173157225263085 0.14688859395292725 0.18027577111903093 ...,\n",
      "  0.18343392257101462 0.18258173193588606 0.1669410743938824]\n",
      " ..., \n",
      " [0.012512904062268751 -0.6182143974430889 0.18343392257101462 ...,\n",
      "  0.2592632385157986 0.23880157481826983 -0.13674101089013374]\n",
      " [0.05586091576954012 -0.41176020609421804 0.18258173193588606 ...,\n",
      "  0.23880157481826983 0.2236313005799415 -0.05479591323726252]\n",
      " [0.8514474644739358 3.3773911549877793 0.1669410743938824 ...,\n",
      "  -0.13674101089013374 -0.05479591323726252 1.4491811979887335]]\n",
      "[[6.11387106407547 4.195926326475359 1.110568058912156 ...,\n",
      "  -0.7864989404471872 -0.8073446576170368 4.321032650565375]\n",
      " [4.195926326475359 2.897913813918444 0.8098277713408409 ...,\n",
      "  -0.47405525930810205 -0.4881630702315519 2.9825823504436624]\n",
      " [1.110568058912156 0.8098277713408409 0.32603305376803837 ...,\n",
      "  0.028566466882294295 0.025297787210045147 0.829444870387658]\n",
      " ..., \n",
      " [-0.7864989404471872 -0.47405525930810205 0.028566466882294295 ...,\n",
      "  0.33760905034535005 0.341004931613901 -0.4944357633268865]\n",
      " [-0.8073446576170368 -0.4881630702315519 0.025297787210045147 ...,\n",
      "  0.341004931613901 0.3444740456952519 -0.5089830836199357]\n",
      " [4.321032650565375 2.9825823504436624 0.829444870387658 ...,\n",
      "  -0.4944357633268865 -0.5089830836199357 3.069888618316078]]\n",
      "[[0.27702016163710436 0.290336938450966 -0.07194103757922085 ...,\n",
      "  -0.46751641110363257 0.26503042536399357 0.3223018399448687]\n",
      " [0.290336938450966 0.3054841606280273 -0.10659040287095951 ...,\n",
      "  -0.5565392271473711 0.2766991639570549 0.34184276838753025]\n",
      " [-0.07194103757922085 -0.10659040287095951 0.8360327336492529 ...,\n",
      "  1.8652934781408403 -0.04074454328593183 -0.1897609451018564]\n",
      " ..., \n",
      " [-0.46751641110363257 -0.5565392271473711 1.8652934781408403 ...,\n",
      "  4.50971969335243 -0.3873648773223435 -0.7702249849942678]\n",
      " [0.26503042536399357 0.2766991639570549 -0.04074454328593183 ...,\n",
      "  -0.3873648773223435 0.25452449736608257 0.3047081998445582]\n",
      " [0.3223018399448687 0.34184276838753025 -0.1897609451018564 ...,\n",
      "  -0.7702249849942678 0.3047081998445582 0.3887478011518335]]\n",
      "[[4.212258196687063 6.652553362181201 -0.22146498232926504 ...,\n",
      "  -0.6682529462180506 -0.6682617448939577 1.0330414298351944]\n",
      " [6.652553362181201 10.569749259272132 -0.4645210357279281 ...,\n",
      "  -1.1817113181831131 -1.181725441940621 1.5492301858829314]\n",
      " [-0.22146498232926504 -0.4645210357279281 0.22013866996321105 ...,\n",
      "  0.26463923724882593 0.26464011360651873 0.09518846647327059]\n",
      " ..., \n",
      " [-0.6682529462180506 -1.1817113181831131 0.26463923724882593 ...,\n",
      "  0.35864713588164066 0.3586489871961337 0.0006806681716854251]\n",
      " [-0.6682617448939577 -1.181725441940621 0.26464011360651873 ...,\n",
      "  0.3586489871961337 0.3586508385298267 0.0006788070125782936]\n",
      " [1.0330414298351944 1.5492301858829314 0.09518846647327059 ...,\n",
      "  0.0006806681716854251 0.0006788070125782936 0.3605506708105302]]\n",
      "[[0.20556290003563985 0.1891873341240356 0.3038135008016358 ...,\n",
      "  0.21102025754632922 0.2758406135073748 0.1919170608932411]\n",
      " [0.1891873341240356 0.18335909321723157 0.22415578489963162 ...,\n",
      "  0.1911296666491252 0.21419993196057058 0.18433063247923695]\n",
      " [0.3038135008016358 0.22415578489963162 0.7817462015868321 ...,\n",
      "  0.33036040834112557 0.6456741830029705 0.2374343366544374]\n",
      " ..., \n",
      " [0.21102025754632922 0.1911296666491252 0.33036040834112557 ...,\n",
      "  0.21764904010021874 0.29638312411246426 0.19444533089673072]\n",
      " [0.2758406135073748 0.21419993196057058 0.6456741830029705 ...,\n",
      "  0.29638312411246426 0.5403790227039093 0.2244751321825761]\n",
      " [0.1919170608932411 0.18433063247923695 0.2374343366544374 ...,\n",
      "  0.19444533089673072 0.2244751321825761 0.18559525300204244]]\n",
      "[[0.353357863493046 0.6632413366121006 0.8057163918576028 ...,\n",
      "  0.09334111563009367 -0.002830686461061951 0.12183795035990125]\n",
      " [0.6632413366121006 1.5274957425439541 1.9248537977894584 ...,\n",
      "  -0.06193647843805153 -0.3301563445932072 0.017540218794155977]\n",
      " [0.8057163918576028 1.9248537977894584 2.4393993530349594 ...,\n",
      "  -0.1333284231925497 -0.4806507893477052 -0.030412725960342182]\n",
      " ..., \n",
      " [0.09334111563009367 -0.06193647843805153 -0.1333284231925497 ...,\n",
      "  0.2236313005799415 0.2718214344247857 0.2093519978121487]\n",
      " [-0.002830686461061951 -0.3301563445932072 -0.4806507893477052 ...,\n",
      "  0.2718214344247857 0.37340638858962993 0.24172061914499307]\n",
      " [0.12183795035990125 0.017540218794155977 -0.030412725960342182 ...,\n",
      "  0.2093519978121487 0.24172061914499307 0.19976079506355618]]\n",
      "[[0.18801376891971766 0.19257070784551553 0.10902812370752935 ...,\n",
      "  0.19522850096419708 0.12193951547237235 -0.07590722644306976]\n",
      " [0.19257070784551553 0.19976447802251343 0.06788073762852725 ...,\n",
      "  0.203960178949195 0.08826318877257039 -0.22406577037807207]\n",
      " [0.10902812370752935 0.06788073762852725 0.8222377785145414 ...,\n",
      "  0.04388189951520874 0.7056529327625847 2.492132059787942]\n",
      " ..., \n",
      " [0.19522850096419708 0.203960178949195 0.04388189951520874 ...,\n",
      "  0.20905285059587653 0.0686217779872518 -0.31047789153139077]\n",
      " [0.12193951547237235 0.08826318877257039 0.7056529327625847 ...,\n",
      "  0.0686217779872518 0.610236194837827 2.0723474115399836]\n",
      " [-0.07590722644306976 -0.22406577037807207 2.492132059787942 ...,\n",
      "  -0.31047789153139077 2.0723474115399836 8.504885938341339]]\n",
      "[[1.176458047413074 1.4668986009443732 0.5272246081728524 ...,\n",
      "  2.607317112674716 0.41617612378650615 -0.2842996960393956]\n",
      " [1.4668986009443732 1.8420064857268734 0.6284048742161519 ...,\n",
      "  3.314872345886016 0.484984261701806 -0.419689689375296]\n",
      " [0.5272246081728524 0.6284048742161519 0.3010522940526309 ...,\n",
      "  1.0256904702344958 0.26236652838628477 0.018342996048383083]\n",
      " ..., \n",
      " [2.607317112674716 3.314872345886016 1.0256904702344958 ...,\n",
      "  6.093096929936359 0.7551602866481494 -0.9513002128577517]\n",
      " [0.41617612378650615 0.484984261701806 0.26236652838628477 ...,\n",
      "  0.7551602866481494 0.2360580830399387 0.07010867883003696]\n",
      " [-0.2842996960393956 -0.419689689375296 0.018342996048383083 ...,\n",
      "  -0.9513002128577517 0.07010867883003696 0.39663820587133497]]\n",
      "[[3.6173195802130467 9.28162380268317 1.142145526586343 ...,\n",
      "  1.0072764982447648 -0.6825019608714089 -0.6825019608714089]\n",
      " [9.28162380268317 24.280420971073283 2.7274854427524704 ...,\n",
      "  2.370358932426891 -2.104090774433283 -2.104090774433283]\n",
      " [1.142145526586343 2.7274854427524704 0.44938749796444 ...,\n",
      "  0.4116400102436615 -0.06129949573971247 -0.06129949573971247]\n",
      " ..., \n",
      " [1.0072764982447648 2.370358932426891 0.4116400102436615 ...,\n",
      "  0.37918454947968294 -0.027450977994890956 -0.027450977994890956]\n",
      " [-0.6825019608714089 -2.104090774433283 -0.06129949573971247 ...,\n",
      "  -0.027450977994890956 0.39663820587133497 0.39663820587133497]\n",
      " [-0.6825019608714089 -2.104090774433283 -0.06129949573971247 ...,\n",
      "  -0.027450977994890956 0.39663820587133497 0.39663820587133497]]\n",
      "[[0.4150311382490325 1.2031134289035574 0.41088575098709035 ...,\n",
      "  -0.0018181316649394375 0.4399204511127418 0.047958370400971735]\n",
      " [1.2031134289035574 4.635270750905284 1.1850599573152152 ...,\n",
      "  -0.612296320652015 1.3115082480712668 -0.3955159310213038]\n",
      " [0.41088575098709035 1.1850599573152152 0.4068135215619483 ...,\n",
      "  0.001393041252318606 0.4353358170027998 0.05029108710062982]\n",
      " ..., \n",
      " [-0.0018181316649394375 -0.612296320652015 0.001393041252318606 ...,\n",
      "  0.3210889941458886 -0.02109832971323035 0.28253024311739994]\n",
      " [0.4399204511127418 1.3115082480712668 0.4353358170027998 ...,\n",
      "  -0.02109832971323035 0.4674470452564511 0.03395250988868093]\n",
      " [0.047958370400971735 -0.3955159310213038 0.05029108710062982 ...,\n",
      "  0.28253024311739994 0.03395250988868093 0.25451971713211125]]\n",
      "[[0.3376160056321215 0.3410119618958724 0.07610998491437757 ...,\n",
      "  -0.2142642723065878 0.15422045666243275 -0.05124967744208279]\n",
      " [0.3410119618958724 0.3444811509724228 0.07386663961652841 ...,\n",
      "  -0.2227694543212369 0.1536615410541835 -0.05623949695433193]\n",
      " [0.07610998491437757 0.07386663961652841 0.2488590595118339 ...,\n",
      "  0.4406782921404681 0.197259820328689 0.33299197451217344]\n",
      " ..., \n",
      " [-0.2142642723065878 -0.2227694543212369 0.4406782921404681 ...,\n",
      "  1.1679214361099026 0.24505039593972347 0.7596509247472073]\n",
      " [0.15422045666243275 0.1536615410541835 0.197259820328689 ...,\n",
      "  0.24505039593972347 0.1844041889727441 0.2182210158282285]\n",
      " [-0.05124967744208279 -0.05623949695433193 0.33299197451217344 ...,\n",
      "  0.7596509247472073 0.2182210158282285 0.5201268134037129]]\n",
      "[[3.3987593904755324 6.285259908419523 0.9421610306334292 ...,\n",
      "  2.823009503676419 -0.0020955115927962843 1.740569844162443]\n",
      " [6.285259908419523 11.760411151406728 1.6255525985486263 ...,\n",
      "  5.193170130932416 -0.16552533430799848 3.1399846870344406]\n",
      " [0.9421610306334292 1.6255525985486263 0.36055067081053005 ...,\n",
      "  0.8058497376263187 0.13699382233790355 0.5495774343683428]\n",
      " ..., \n",
      " [2.823009503676419 5.193170130932416 0.8058497376263187 ...,\n",
      "  2.3502502907973075 0.030502681736092555 1.461438441843332]\n",
      " [-0.0020955115927962843 -0.16552533430799848 0.13699382233790355 ...,\n",
      "  0.030502681736092555 0.19045637269407717 0.09178897652611677]\n",
      " [1.740569844162443 3.1399846870344406 0.5495774343683428 ...,\n",
      "  1.461438441843332 0.09178897652611677 0.9366569229693561]]\n",
      "[[0.3514927619383246 0.3621200276063775 0.24875708563887167 ...,\n",
      "  -1.6359546525471163 0.04859483128375944 0.37274729327443]\n",
      " [0.3621200276063775 0.37340638858962993 0.2530127591149244 ...,\n",
      "  -1.7485874352310624 0.040436586801412024 0.38469274957288246]\n",
      " [0.24875708563887167 0.2530127591149244 0.2076167296594185 ...,\n",
      "  -0.5471134149265686 0.1274620385683064 0.2572684325909769]\n",
      " ..., \n",
      " [-1.6359546525471163 -1.7485874352310624 -0.5471134149265686 ...,\n",
      "  19.427952068487457 1.5743007287023192 -1.8612202179150097]\n",
      " [0.04859483128375944 0.040436586801412024 0.1274620385683064 ...,\n",
      "  1.5743007287023192 0.28112081196999406 0.032278342319064554]\n",
      " [0.37274729327443 0.38469274957288246 0.2572684325909769 ...,\n",
      "  -1.8612202179150097 0.032278342319064554 0.39663820587133497]]\n",
      "[[0.3659553807469282 0.3659553807469282 -0.047226464565666766 ...,\n",
      "  0.22945898736857526 0.3807109308067317 0.2663478625180838]\n",
      " [0.3659553807469282 0.3659553807469282 -0.047226464565666766 ...,\n",
      "  0.22945898736857526 0.3807109308067317 0.2663478625180838]\n",
      " [-0.047226464565666766 -0.047226464565666766 0.4583416901217383 ...,\n",
      "  0.1197901420559804 -0.06528131450586337 0.07465301720548892]\n",
      " ..., \n",
      " [0.22945898736857526 0.22945898736857526 0.1197901420559804 ...,\n",
      "  0.19322941431022272 0.23337548117237894 0.20302064881973128]\n",
      " [0.3807109308067317 0.3807109308067317 -0.06528131450586337 ...,\n",
      "  0.23337548117237894 0.39663820587133497 0.27319366883388746]\n",
      " [0.2663478625180838 0.2663478625180838 0.07465301720548892 ...,\n",
      "  0.20302064881973128 0.27319366883388746 0.2201351646092397]]\n",
      "[[5.544483722457855 10.995393288021887 0.8864184148067047 ...,\n",
      "  0.23229627664614683 -0.8975344459954048 5.405792048704447]\n",
      " [10.995393288021887 21.985173674117146 1.6040955349691433 ...,\n",
      "  0.28529569842778524 -1.992597810159367 10.715771874825293]\n",
      " [0.8864184148067047 1.6040955349691433 0.2731286775043539 ...,\n",
      "  0.18700571275819605 0.0382500510574444 0.8681580052708959]\n",
      " ..., \n",
      " [0.23229627664614683 0.28529569842778524 0.18700571275819605 ...,\n",
      "  0.18064565583923844 0.16966026444888666 0.23094777169913858]\n",
      " [-0.8975344459954048 -1.992597810159367 0.0382500510574444 ...,\n",
      "  0.16966026444888666 0.39663820587133497 -0.8696719087408135]\n",
      " [5.405792048704447 10.715771874825293 0.8681580052708959 ...,\n",
      "  0.23094777169913858 -0.8696719087408135 5.270686158426239]]\n",
      "[[0.43192290789765786 0.44480506253040536 0.6509283314347925 ...,\n",
      "  -0.05333789702910366 0.06690434099030115 0.7518484368526296]\n",
      " [0.44480506253040536 0.4583463124783524 0.6750155563971406 ...,\n",
      "  -0.06528335332755617 0.06111089093824866 0.7810990813349776]\n",
      " [0.6509283314347925 0.6750155563971406 1.0604276003927282 ...,\n",
      "  -0.2564188093895684 -0.0315882651429635 1.249129362770565]\n",
      " ..., \n",
      " [-0.05333789702910366 -0.06528335332755617 -0.2564188093895684 ...,\n",
      "  0.39663820587133497 0.2851391251323398 -0.35000072509173136]\n",
      " [0.06690434099030115 0.06111089093824866 -0.0315882651429635 ...,\n",
      "  0.2851391251323398 0.23106296939814452 -0.07697474020512633]\n",
      " [0.7518484368526296 0.7810990813349776 1.249129362770565 ...,\n",
      "  -0.35000072509173136 -0.07697474020512633 1.4782818771484036]]\n",
      "[[0.1952608940249243 0.18578807112848805 0.017401369792280987 ...,\n",
      "  0.23735729993852983 0.16105689066900394 0.19105093012902818]\n",
      " [0.18578807112848805 0.182249131112052 0.1193417547038447 ...,\n",
      "  0.2015148145780934 0.17300984044456774 0.18421527600059195]\n",
      " [0.017401369792280987 0.1193417547038447 1.9314103783724375 ...,\n",
      "  -0.4356128867965137 0.38548270159156045 0.06270627464518462]\n",
      " ..., \n",
      " [0.23735729993852983 0.2015148145780934 -0.4356128867965137 ...,\n",
      "  0.39663820587133497 0.10793901534100925 0.22142798605223366]\n",
      " [0.16105689066900394 0.17300984044456774 0.38548270159156045 ...,\n",
      "  0.10793901534100925 0.20421601426988348 0.16636908615230772]\n",
      " [0.19105093012902818 0.18421527600059195 0.06270627464518462 ...,\n",
      "  0.22142798605223366 0.16636908615230772 0.18801299123793175]]\n",
      "[[1.37323044809874 2.1771576134175454 1.0367009052958356 ...,\n",
      "  0.08321090404273619 1.0974708284248227 1.078771286039618]\n",
      " [2.1771576134175454 3.522785609987549 1.6138683081122407 ...,\n",
      "  0.017899300612741795 1.7155861171868296 1.6842864810480227]\n",
      " [1.0367009052958356 1.6138683081122407 0.7950945874977304 ...,\n",
      "  0.11055079873743104 0.8387234387355174 0.8252983838575119]\n",
      " ..., \n",
      " [0.08321090404273619 0.017899300612741795 0.11055079873743104 ...,\n",
      "  0.18801299123793175 0.10561380781201837 0.10713297167321278]\n",
      " [1.0974708284248227 1.7155861171868296 0.8387234387355174 ...,\n",
      "  0.10561380781201837 0.8854475951061048 0.8710700823912989]\n",
      " [1.078771286039618 1.6842864810480227 0.8252983838575119 ...,\n",
      "  0.10713297167321278 0.8710700823912989 0.8569856509372932]]\n",
      "[[2.9832344471021526 4.444717588501038 0.7766601796238561 ...,\n",
      "  2.180833133584945 -0.29081909122693084 1.9444176061437726]\n",
      " [4.444717588501038 6.668191411295121 1.0876757022067416 ...,\n",
      "  3.2239588500366296 -0.5363678107688461 2.864280574128259]\n",
      " [0.7766601796238561 1.0876757022067416 0.30708319342555807 ...,\n",
      "  0.6059026410826461 0.07991490535877108 0.5555914902174744]\n",
      " ..., \n",
      " [2.180833133584945 3.2239588500366296 0.6059026410826461 ...,\n",
      "  1.6081235200869353 -0.1560049359953407 1.4393832113849627]\n",
      " [-0.29081909122693084 -0.5363678107688461 0.07991490535877108 ...,\n",
      "  -0.1560049359953407 0.25926570364718426 -0.11628396460771238]\n",
      " [1.9444176061437726 2.864280574128259 0.5555914902174744 ...,\n",
      "  1.4393832113849627 -0.11628396460771238 1.2905823921421908]]\n",
      "[[0.6329898894528521 0.27592471533645485 0.6041930267900992 ...,\n",
      "  -0.13297834999550628 0.27304384959597683 0.9641420153324824]\n",
      " [0.27592471533645485 0.20039902248085745 0.26983366204330206 ...,\n",
      "  0.11390868525769623 0.19978966767157935 0.345969333408085]\n",
      " [0.6041930267900992 0.26983366204330206 0.5772273594425461 ...,\n",
      "  -0.11306721734305922 0.26713599083722395 0.9142871565737296]\n",
      " ..., \n",
      " [-0.13297834999550628 0.11390868525769623 -0.11306721734305922 ...,\n",
      "  0.39663820587133497 0.11590061405161813 -0.3619482202118765]\n",
      " [0.27304384959597683 0.19978966767157935 0.26713599083722395 ...,\n",
      "  0.11590061405161813 0.1991986398191012 0.34098180555560653]\n",
      " [0.9641420153324824 0.345969333408085 0.9142871565737296 ...,\n",
      "  -0.3619482202118765 0.34098180555560653 1.5374524712921116]]\n",
      "[[0.4493965927256685 0.3028446464428037 0.933444335991712 ...,\n",
      "  -0.04798190938075076 -0.05020104985972176 1.27316836829189]\n",
      " [0.3028446464428037 0.23605808303993875 0.5234345882048472 ...,\n",
      "  0.07617961940838433 0.0751683140654134 0.6782534166010252]\n",
      " [0.933444335991712 0.5234345882048472 2.287669224620953 ...,\n",
      "  -0.4580761410523077 -0.4642846510800785 3.238118320204334]\n",
      " ..., \n",
      " [-0.04798190938075076 0.07617961940838433 -0.4580761410523077 ...,\n",
      "  0.37340638858962993 0.37528648558905914 -0.7458966462497291]\n",
      " [-0.05020104985972176 0.0751683140654134 -0.4642846510800785 ...,\n",
      "  0.37528648558905914 0.3771848720476878 -0.7549050551063008]\n",
      " [1.27316836829189 0.6782534166010252 3.238118320204334 ...,\n",
      "  -0.7458966462497291 -0.7549050551063008 4.617198648990907]]\n"
     ]
    }
   ],
   "source": [
    "#Create the between-class scatter matrix Sb\n",
    "\n",
    "ZM = np.zeros((192,192))   #Initialize the zero matrix\n",
    "\n",
    "for species in(unique_classes):   #For each class:\n",
    "    #print species\n",
    "    n =  len(LDA_trainDF[LDA_trainDF['species']==species])      #n = #rows in class\n",
    "\n",
    "    #make a column vector for the mean vector of that class\n",
    "    species_MV = MV_DF[MV_DF['species']==species].values\n",
    "    species_MV = species_MV[:,1:]\n",
    "    species_MVT = species_MV.T\n",
    "\n",
    "    #make a column vector for the overall mean\n",
    "    overall_MVT = overall_mean.T\n",
    "    \n",
    "    \n",
    "    #compute the difference between the mean vector and the overall mean\n",
    "    difference = species_MVT - overall_MVT\n",
    "    \n",
    "    \n",
    "    #The between-class scatter matrix for class i is n times the dot product of the difference and the difference transpose\n",
    "    SBi = n * difference.dot((difference).T)\n",
    "\n",
    "\n",
    "    #add the between-class scatter matrix for class i to the zero matrix ZM\n",
    "    SBsum = ZM + SBi\n",
    "        \n",
    "    \n",
    "    print SBsum\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here, we are troubleshooting the += operation for the scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 192)\n",
      "(192, 192)\n",
      "('between-class Scatter Matrix:\\n', array([[0.20836368861392382, 0.30038518546964826, 0.3665227607319378, ...,\n",
      "        0.12497139254652297, 0.1185020684953553, 0.3032606041933464],\n",
      "       [0.30038518546964826, 0.6924210824981727, 0.9741846326596624, ...,\n",
      "        -0.05488803558335276, -0.08244906582332037, 0.7046711262074707],\n",
      "       [0.3665227607319378, 0.9741846326596624, 1.4109226141299505, ...,\n",
      "        -0.18415637907946308, -0.2268764140426308, 0.9931723951273609],\n",
      "       ..., \n",
      "       [0.12497139254652297, -0.05488803558335276, -0.18415637907946308,\n",
      "        ..., 0.2879647277303222, 0.3006092614967545, -0.06050814811085449],\n",
      "       [0.1185020684953553, -0.08244906582332037, -0.2268764140426308, ...,\n",
      "        0.3006092614967545, 0.31473659098798684, -0.0887282361684221],\n",
      "       [0.3032606041933464, 0.7046711262074707, 0.9931723951273609, ...,\n",
      "        -0.06050814811085449, -0.0887282361684221, 0.717214101167969]], dtype=object))\n",
      "(192, 192)\n"
     ]
    }
   ],
   "source": [
    "#Create the between-class scatter matrix Sb for Acer_Opalus\n",
    "\n",
    "ZM = np.zeros((192,192))   #Initialize the zero matrix\n",
    "\n",
    "\n",
    "n =  len(LDA_trainDF[LDA_trainDF['species']=='Acer_Opalus'])      #n = #rows in class\n",
    "\n",
    "    #make a column vector for the mean vector of that class\n",
    "species_MV = MV_DF[MV_DF['species']=='Acer_Opalus'].values\n",
    "species_MV = species_MV[:,1:]\n",
    "species_MVT = species_MV.T\n",
    "\n",
    "    #make a column vector for the overall mean\n",
    "overall_MVT = overall_mean.T\n",
    "    \n",
    "    \n",
    "    #compute the difference between the mean vector and the overall mean\n",
    "difference = species_MVT - overall_MVT\n",
    "    \n",
    "    \n",
    "    #The between-class scatter matrix for class i is n times the dot product of the difference and the difference transpose\n",
    "SBi = n * difference.dot((difference).T)\n",
    "\n",
    "\n",
    "print SBi.shape\n",
    "print ZM.shape\n",
    "\n",
    "\n",
    "\n",
    "    #add the between-class scatter matrix for class i to the zero matrix ZM\n",
    "SBsum = ZM + SBi\n",
    "   \n",
    "print('between-class Scatter Matrix:\\n', SBsum)\n",
    "print SBsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20836368861392382, 0.30038518546964826, 0.3665227607319378, ...,\n",
       "        0.12497139254652297, 0.1185020684953553, 0.3032606041933464],\n",
       "       [0.30038518546964826, 0.6924210824981727, 0.9741846326596624, ...,\n",
       "        -0.05488803558335276, -0.08244906582332037, 0.7046711262074707],\n",
       "       [0.3665227607319378, 0.9741846326596624, 1.4109226141299505, ...,\n",
       "        -0.18415637907946308, -0.2268764140426308, 0.9931723951273609],\n",
       "       ..., \n",
       "       [0.12497139254652297, -0.05488803558335276, -0.18415637907946308,\n",
       "        ..., 0.2879647277303222, 0.3006092614967545, -0.06050814811085449],\n",
       "       [0.1185020684953553, -0.08244906582332037, -0.2268764140426308, ...,\n",
       "        0.3006092614967545, 0.31473659098798684, -0.0887282361684221],\n",
       "       [0.3032606041933464, 0.7046711262074707, 0.9931723951273609, ...,\n",
       "        -0.06050814811085449, -0.0887282361684221, 0.717214101167969]], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20836368861392382, 0.30038518546964826, 0.3665227607319378, ...,\n",
       "        0.12497139254652297, 0.1185020684953553, 0.3032606041933464],\n",
       "       [0.30038518546964826, 0.6924210824981727, 0.9741846326596624, ...,\n",
       "        -0.05488803558335276, -0.08244906582332037, 0.7046711262074707],\n",
       "       [0.3665227607319378, 0.9741846326596624, 1.4109226141299505, ...,\n",
       "        -0.18415637907946308, -0.2268764140426308, 0.9931723951273609],\n",
       "       ..., \n",
       "       [0.12497139254652297, -0.05488803558335276, -0.18415637907946308,\n",
       "        ..., 0.2879647277303222, 0.3006092614967545, -0.06050814811085449],\n",
       "       [0.1185020684953553, -0.08244906582332037, -0.2268764140426308, ...,\n",
       "        0.3006092614967545, 0.31473659098798684, -0.0887282361684221],\n",
       "       [0.3032606041933464, 0.7046711262074707, 0.9931723951273609, ...,\n",
       "        -0.06050814811085449, -0.0887282361684221, 0.717214101167969]], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZM + SBi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' output (typecode 'O') could not be coerced to provided output parameter (typecode 'd') according to the casting rule ''same_kind''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-4c147ba5690d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mZM\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mSBi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'add' output (typecode 'O') could not be coerced to provided output parameter (typecode 'd') according to the casting rule ''same_kind''"
     ]
    }
   ],
   "source": [
    "ZM += SBi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Above, we keep getting the \"same_kind\" Type Error when we try to add the class scatter matrix to the overall scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Solve the generalized eigenvalue problem to obtain the linear discriminants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S_W =    #Within-class scatter matrix\n",
    "S_B =    #Between-class scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-66dfcd0be0dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meig_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meig_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_W\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#Compute the eigenvectors and eigenvlues on the dot product of the scatter matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))  \n",
    "#Compute the eigenvectors and eigenvlues on the dot product of the scatter matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(eig_vals)):\n",
    "    eigenvector = eig_vecs[:,i].reshape(4,1)\n",
    "    print eigenvector\n",
    "    print eig_vals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Choose the linear discriminants for the new feature subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue,eigenvector) tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort those tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose k eigenvectors with the largest eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Transform the samples onto the new subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LDA with scikit-learn to compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cross_validation import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because our testing data that came with the \"test.csv\" file in the data distribution from the kaggle competition site does not have labels, we will have to do a train/test split on the training data and remove the class label for the testing portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.iloc[:,2:194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "0  0.007812  0.023438  0.023438  0.003906  0.011719  0.009766  0.027344   \n",
       "1  0.005859  0.000000  0.031250  0.015625  0.025391  0.001953  0.019531   \n",
       "2  0.005859  0.009766  0.019531  0.007812  0.003906  0.005859  0.068359   \n",
       "3  0.000000  0.003906  0.023438  0.005859  0.021484  0.019531  0.023438   \n",
       "\n",
       "   margin8   margin9  margin10    ...      texture55  texture56  texture57  \\\n",
       "0      0.0  0.001953  0.033203    ...       0.007812   0.000000   0.002930   \n",
       "1      0.0  0.000000  0.007812    ...       0.000977   0.000000   0.000000   \n",
       "2      0.0  0.000000  0.044922    ...       0.154300   0.000000   0.005859   \n",
       "3      0.0  0.013672  0.017578    ...       0.000000   0.000977   0.000000   \n",
       "\n",
       "   texture58  texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "0   0.002930   0.035156        0.0        0.0   0.004883   0.000000   0.025391  \n",
       "1   0.000977   0.023438        0.0        0.0   0.000977   0.039062   0.022461  \n",
       "2   0.000977   0.007812        0.0        0.0   0.000000   0.020508   0.002930  \n",
       "3   0.000000   0.020508        0.0        0.0   0.017578   0.000000   0.047852  \n",
       "\n",
       "[4 rows x 192 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Acer_Opalus\n",
       "1    Pterocarya_Stenoptera\n",
       "2     Quercus_Hartwissiana\n",
       "3          Tilia_Tomentosa\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=True, tol=0.0001)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "clf = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Acer_Saccharinum', 'Acer_Mono', 'Prunus_Avium',\n",
       "       'Quercus_Variabilis', 'Acer_Opalus', 'Quercus_Crassifolia',\n",
       "       'Quercus_Imbricaria', 'Quercus_Ellipsoidalis', 'Quercus_x_Turneri',\n",
       "       'Quercus_Palustris'], \n",
       "      dtype='|S28')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print len(predictions)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 2, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 2, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 2]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD3CAYAAAAKcnGEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f6bd0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "plt.matshow(cnf_matrix)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982934793641\n"
     ]
    }
   ],
   "source": [
    "print completeness_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98303404719\n"
     ]
    }
   ],
   "source": [
    "print homogeneity_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print clf.score(X_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954545454545\n"
     ]
    }
   ],
   "source": [
    "print clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=True, tol=0.0001)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "clf = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_scores = cross_validation.cross_val_score(clf, X,y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using decision trees through scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Because we don't have labels for the \"test.csv\" file, \n",
    "#we have to do a train/test split using the \"train.csv\" file provided\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head(2)\n",
    "\n",
    "X = data.iloc[:,2:]\n",
    "y = data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "577  0.015625  0.060547  0.025391  0.011719  0.001953  0.035156  0.019531   \n",
       "660  0.025391  0.027344  0.056641  0.033203  0.003906  0.025391  0.080078   \n",
       "\n",
       "     margin8   margin9  margin10    ...      texture55  texture56  texture57  \\\n",
       "577      0.0  0.005859  0.019531    ...        0.12305        0.0   0.000000   \n",
       "660      0.0  0.000000  0.072266    ...        0.14160        0.0   0.019531   \n",
       "\n",
       "     texture58  texture59  texture60  texture61  texture62  texture63  \\\n",
       "577        0.0   0.003906        0.0   0.008789        0.0   0.000977   \n",
       "660        0.0   0.000977        0.0   0.000000        0.0   0.000000   \n",
       "\n",
       "     texture64  \n",
       "577   0.003906  \n",
       "660   0.016602  \n",
       "\n",
       "[2 rows x 192 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577      Quercus_x_Turneri\n",
       "660         Salix_Intergra\n",
       "383    Quercus_x_Hispanica\n",
       "37       Cotinus_Coggygria\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'criterion': ['entropy','gini'],\n",
    "    'max_depth': np.linspace(1, 10, 10),\n",
    "    'min_samples_leaf': np.linspace(1, 20, 10),\n",
    "    'min_samples_split': np.linspace(2, 10, 5)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(dt, parameters, verbose=1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    4.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:   17.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks       | elapsed:   52.1s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks       | elapsed:  2.0min\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks       | elapsed:  3.7min\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks       | elapsed:  6.1min\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks       | elapsed:  9.0min\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks       | elapsed:  9.5min\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks       | elapsed: 10.3min\n",
      "[Parallel(n_jobs=1)]: Done 4999 tasks       | elapsed: 11.7min\n",
      "[Parallel(n_jobs=1)]: Done 5000 out of 5000 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 43s, sys: 448 ms, total: 11min 43s\n",
      "Wall time: 11min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'criterion': 'entropy',\n",
       "  'max_depth': 9.0,\n",
       "  'min_samples_leaf': 1.0,\n",
       "  'min_samples_split': 2.0},\n",
       " 0.64646464646464652)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time _ = gs.fit(X_train, y_train)\n",
    "\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output from above was:\n",
    "    \n",
    "({'criterion': 'entropy',\n",
    "  'max_depth': 9.0,\n",
    "  'min_samples_leaf': 1.0,\n",
    "  'min_samples_split': 2.0},\n",
    " 0.64646464646464652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred = clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "         print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\"\n",
    "    if show_classification_report:\n",
    "        print \"Classification report\"\n",
    "        print metrics.classification_report(y, y_pred),\"\\n\"\n",
    "      \n",
    "    if show_confusion_matrix:\n",
    "        print \"Confusion matrix\"\n",
    "        print metrics.confusion_matrix(y, y_pred),\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.611 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Acer_Capillipes       0.50      1.00      0.67         1\n",
      "Acer_Circinatum       1.00      1.00      1.00         2\n",
      "  Acer_Mono       0.33      0.50      0.40         2\n",
      "Acer_Opalus       0.50      1.00      0.67         1\n",
      "Acer_Palmatum       0.33      1.00      0.50         1\n",
      "Acer_Pictum       1.00      1.00      1.00         2\n",
      "Acer_Platanoids       0.50      0.25      0.33         4\n",
      "Acer_Rubrum       1.00      1.00      1.00         2\n",
      "Acer_Rufinerve       1.00      0.67      0.80         3\n",
      "Acer_Saccharinum       1.00      0.60      0.75         5\n",
      "Alnus_Cordata       1.00      1.00      1.00         1\n",
      "Alnus_Maximowiczii       0.50      1.00      0.67         1\n",
      "Alnus_Rubra       0.17      1.00      0.29         1\n",
      "Alnus_Sieboldiana       1.00      1.00      1.00         1\n",
      "Alnus_Viridis       1.00      1.00      1.00         1\n",
      "Arundinaria_Simonii       1.00      0.67      0.80         3\n",
      "Betula_Austrosinensis       1.00      1.00      1.00         3\n",
      "Betula_Pendula       0.00      0.00      0.00         2\n",
      "Callicarpa_Bodinieri       1.00      1.00      1.00         1\n",
      "Castanea_Sativa       0.00      0.00      0.00         0\n",
      "Celtis_Koraiensis       1.00      1.00      1.00         2\n",
      "Cercis_Siliquastrum       0.50      1.00      0.67         1\n",
      "Cornus_Chinensis       0.50      0.50      0.50         2\n",
      "Cornus_Controversa       0.67      1.00      0.80         4\n",
      "Cornus_Macrophylla       1.00      1.00      1.00         2\n",
      "Cotinus_Coggygria       0.00      0.00      0.00         1\n",
      "Crataegus_Monogyna       1.00      0.67      0.80         3\n",
      "Cytisus_Battandieri       0.33      0.33      0.33         3\n",
      "Eucalyptus_Glaucescens       0.67      0.50      0.57         4\n",
      "Eucalyptus_Neglecta       0.00      0.00      0.00         2\n",
      "Eucalyptus_Urnigera       0.50      1.00      0.67         2\n",
      "Fagus_Sylvatica       0.33      0.50      0.40         2\n",
      "Ginkgo_Biloba       1.00      0.50      0.67         2\n",
      "Ilex_Aquifolium       1.00      0.67      0.80         6\n",
      "Ilex_Cornuta       0.75      1.00      0.86         3\n",
      "Liquidambar_Styraciflua       0.50      1.00      0.67         1\n",
      "Liriodendron_Tulipifera       0.00      0.00      0.00         2\n",
      "Lithocarpus_Cleistocarpus       0.50      1.00      0.67         1\n",
      "Lithocarpus_Edulis       0.00      0.00      0.00         2\n",
      "Magnolia_Heptapeta       0.67      1.00      0.80         2\n",
      "Magnolia_Salicifolia       0.00      0.00      0.00         1\n",
      "Morus_Nigra       0.50      1.00      0.67         1\n",
      "Olea_Europaea       0.50      1.00      0.67         1\n",
      "Phildelphus       1.00      0.50      0.67         2\n",
      "Populus_Grandidentata       0.33      1.00      0.50         1\n",
      "Populus_Nigra       0.50      0.67      0.57         3\n",
      "Prunus_Avium       1.00      0.75      0.86         8\n",
      "Prunus_X_Shmittii       0.50      0.50      0.50         2\n",
      "Pterocarya_Stenoptera       0.00      0.00      0.00         1\n",
      "Quercus_Afares       1.00      0.67      0.80         3\n",
      "Quercus_Agrifolia       0.67      1.00      0.80         2\n",
      "Quercus_Alnifolia       0.00      0.00      0.00         0\n",
      "Quercus_Brantii       0.67      0.67      0.67         3\n",
      "Quercus_Canariensis       0.00      0.00      0.00         1\n",
      "Quercus_Castaneifolia       0.50      0.33      0.40         3\n",
      "Quercus_Cerris       0.33      0.33      0.33         3\n",
      "Quercus_Chrysolepis       1.00      1.00      1.00         3\n",
      "Quercus_Coccifera       1.00      1.00      1.00         1\n",
      "Quercus_Coccinea       0.33      1.00      0.50         1\n",
      "Quercus_Crassifolia       0.75      1.00      0.86         3\n",
      "Quercus_Crassipes       1.00      1.00      1.00         1\n",
      "Quercus_Dolicholepis       0.33      1.00      0.50         1\n",
      "Quercus_Ellipsoidalis       0.50      0.33      0.40         3\n",
      "Quercus_Greggii       0.00      0.00      0.00         2\n",
      "Quercus_Hartwissiana       1.00      1.00      1.00         1\n",
      "Quercus_Ilex       0.50      0.67      0.57         3\n",
      "Quercus_Imbricaria       1.00      0.33      0.50         3\n",
      "Quercus_Infectoria_sub       0.00      0.00      0.00         1\n",
      "Quercus_Kewensis       0.00      0.00      0.00         1\n",
      "Quercus_Nigra       1.00      1.00      1.00         1\n",
      "Quercus_Palustris       0.00      0.00      0.00         3\n",
      "Quercus_Phellos       1.00      1.00      1.00         1\n",
      "Quercus_Phillyraeoides       1.00      0.67      0.80         3\n",
      "Quercus_Pontica       1.00      0.60      0.75         5\n",
      "Quercus_Pubescens       1.00      0.67      0.80         3\n",
      "Quercus_Pyrenaica       0.00      0.00      0.00         1\n",
      "Quercus_Rhysophylla       0.00      0.00      0.00         1\n",
      "Quercus_Rubra       0.00      0.00      0.00         3\n",
      "Quercus_Semecarpifolia       0.25      0.50      0.33         2\n",
      "Quercus_Suber       0.00      0.00      0.00         2\n",
      "Quercus_Texana       0.00      0.00      0.00         0\n",
      "Quercus_Trojana       0.00      0.00      0.00         0\n",
      "Quercus_Variabilis       0.50      0.60      0.55         5\n",
      "Quercus_Vulcanica       0.50      0.67      0.57         3\n",
      "Quercus_x_Hispanica       0.33      1.00      0.50         1\n",
      "Quercus_x_Turneri       1.00      0.50      0.67         2\n",
      "Rhododendron_x_Russellianum       1.00      0.75      0.86         4\n",
      "Salix_Fragilis       1.00      1.00      1.00         1\n",
      "Salix_Intergra       1.00      0.40      0.57         5\n",
      "Sorbus_Aria       1.00      0.50      0.67         2\n",
      "Tilia_Oliveri       0.00      0.00      0.00         1\n",
      "Tilia_Platyphyllos       0.00      0.00      0.00         1\n",
      "Ulmus_Bergmanniana       1.00      1.00      1.00         1\n",
      "Viburnum_Tinus       0.50      1.00      0.67         1\n",
      "Viburnum_x_Rhytidophylloides       1.00      1.00      1.00         1\n",
      "Zelkova_Serrata       1.00      0.50      0.67         2\n",
      "\n",
      "avg / total       0.66      0.61      0.61       198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_leaf=1, min_samples_split=2)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "measure_performance(X_test, y_test, dt, show_confusion_matrix=False, show_classification_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                species   margin1   margin2   margin3   margin4  \\\n",
      "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
      "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
      "\n",
      "    margin5   margin6   margin7  margin8    ...      texture55  texture56  \\\n",
      "0  0.011719  0.009766  0.027344      0.0    ...       0.007812        0.0   \n",
      "1  0.025391  0.001953  0.019531      0.0    ...       0.000977        0.0   \n",
      "\n",
      "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
      "0    0.00293   0.002930   0.035156        0.0        0.0   0.004883   \n",
      "1    0.00000   0.000977   0.023438        0.0        0.0   0.000977   \n",
      "\n",
      "   texture63  texture64  \n",
      "0   0.000000   0.025391  \n",
      "1   0.039062   0.022461  \n",
      "\n",
      "[2 rows x 194 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "print data.head(2)\n",
    "X = data.iloc[:,2:]\n",
    "y = data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred = clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "         print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\"\n",
    "    if show_classification_report:\n",
    "        print \"Classification report\"\n",
    "        print metrics.classification_report(y, y_pred),\"\\n\"\n",
    "      \n",
    "    if show_confusion_matrix:\n",
    "        print \"Confusion matrix\"\n",
    "        print metrics.confusion_matrix(y, y_pred),\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.803 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(X_test, y_test, rf, show_confusion_matrix=False, show_classification_report=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here, our accuracy from random forests was 0.803, considerably higher than the 0.611 accuracy from the decision trees model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Regression Trees\n",
    "\n",
    "http://www.slideshare.net/DataRobot/gradient-boosted-regression-trees-in-scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in the data \n",
    "data = pd.read_csv(\"train.csv\")\n",
    "#print data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  species   margin1   margin2   margin3   margin4   margin5   margin6  \\\n",
       "0   1        3  0.007812  0.023438  0.023438  0.003906  0.011719  0.009766   \n",
       "1   2       49  0.005859  0.000000  0.031250  0.015625  0.025391  0.001953   \n",
       "2   3       65  0.005859  0.009766  0.019531  0.007812  0.003906  0.005859   \n",
       "3   5       94  0.000000  0.003906  0.023438  0.005859  0.021484  0.019531   \n",
       "\n",
       "    margin7  margin8    ...      texture55  texture56  texture57  texture58  \\\n",
       "0  0.027344      0.0    ...       0.007812   0.000000   0.002930   0.002930   \n",
       "1  0.019531      0.0    ...       0.000977   0.000000   0.000000   0.000977   \n",
       "2  0.068359      0.0    ...       0.154300   0.000000   0.005859   0.000977   \n",
       "3  0.023438      0.0    ...       0.000000   0.000977   0.000000   0.000000   \n",
       "\n",
       "   texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "0   0.035156        0.0        0.0   0.004883   0.000000   0.025391  \n",
       "1   0.023438        0.0        0.0   0.000977   0.039062   0.022461  \n",
       "2   0.007812        0.0        0.0   0.000000   0.020508   0.002930  \n",
       "3   0.020508        0.0        0.0   0.017578   0.000000   0.047852  \n",
       "\n",
       "[4 rows x 194 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to make the target attribute numerical for this to work properly:\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(data['species'])\n",
    "\n",
    "le.classes_\n",
    "\n",
    "data['species'] = le.transform(data['species']) \n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Acer_Opalus', 'Pterocarya_Stenoptera', 'Quercus_Hartwissiana',\n",
       "       'Tilia_Tomentosa', 'Quercus_Variabilis', 'Magnolia_Salicifolia',\n",
       "       'Quercus_Canariensis', 'Quercus_Rubra', 'Quercus_Brantii',\n",
       "       'Salix_Fragilis', 'Zelkova_Serrata', 'Betula_Austrosinensis',\n",
       "       'Quercus_Pontica', 'Quercus_Afares', 'Quercus_Coccifera',\n",
       "       'Fagus_Sylvatica', 'Phildelphus', 'Acer_Palmatum',\n",
       "       'Quercus_Pubescens', 'Populus_Adenopoda', 'Quercus_Trojana',\n",
       "       'Quercus_Variabilis', 'Alnus_Sieboldiana', 'Quercus_Ilex',\n",
       "       'Arundinaria_Simonii', 'Acer_Platanoids', 'Quercus_Phillyraeoides',\n",
       "       'Cornus_Chinensis', 'Quercus_Phillyraeoides', 'Fagus_Sylvatica',\n",
       "       'Liriodendron_Tulipifera', 'Cytisus_Battandieri', 'Tilia_Tomentosa',\n",
       "       'Rhododendron_x_Russellianum', 'Alnus_Rubra',\n",
       "       'Eucalyptus_Glaucescens', 'Cercis_Siliquastrum',\n",
       "       'Cotinus_Coggygria', 'Celtis_Koraiensis', 'Quercus_Crassifolia',\n",
       "       'Quercus_Variabilis', 'Quercus_Hartwissiana', 'Quercus_Kewensis',\n",
       "       'Quercus_Coccifera', 'Cornus_Controversa', 'Quercus_Pyrenaica',\n",
       "       'Callicarpa_Bodinieri', 'Quercus_Alnifolia', 'Quercus_Canariensis',\n",
       "       'Acer_Saccharinum', 'Prunus_X_Shmittii', 'Prunus_Avium',\n",
       "       'Quercus_Greggii', 'Quercus_Suber', 'Quercus_Trojana',\n",
       "       'Liriodendron_Tulipifera', 'Quercus_Coccifera',\n",
       "       'Cercis_Siliquastrum', 'Quercus_Suber', 'Celtis_Koraiensis',\n",
       "       'Quercus_Dolicholepis', 'Rhododendron_x_Russellianum',\n",
       "       'Ilex_Cornuta', 'Tilia_Oliveri', 'Quercus_Semecarpifolia',\n",
       "       'Quercus_Texana', 'Celtis_Koraiensis', 'Ginkgo_Biloba',\n",
       "       'Acer_Palmatum', 'Quercus_Variabilis', 'Liriodendron_Tulipifera',\n",
       "       'Liquidambar_Styraciflua', 'Quercus_Phellos', 'Quercus_Crassifolia',\n",
       "       'Quercus_Palustris', 'Quercus_Phellos', 'Quercus_Alnifolia',\n",
       "       'Quercus_Afares', 'Quercus_Canariensis', 'Alnus_Maximowiczii',\n",
       "       'Quercus_Agrifolia', 'Callicarpa_Bodinieri', 'Prunus_Avium',\n",
       "       'Acer_Pictum', 'Acer_Rufinerve', 'Lithocarpus_Cleistocarpus',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Celtis_Koraiensis',\n",
       "       'Ilex_Aquifolium', 'Acer_Circinatum', 'Quercus_Coccinea',\n",
       "       'Acer_Circinatum', 'Quercus_Cerris', 'Acer_Circinatum',\n",
       "       'Acer_Saccharinum', 'Quercus_Chrysolepis', 'Celtis_Koraiensis',\n",
       "       'Quercus_Semecarpifolia', 'Eucalyptus_Neglecta',\n",
       "       'Betula_Austrosinensis', 'Ginkgo_Biloba', 'Quercus_Canariensis',\n",
       "       'Tilia_Platyphyllos', 'Alnus_Cordata', 'Populus_Nigra',\n",
       "       'Quercus_Coccinea', 'Quercus_Variabilis', 'Quercus_Pyrenaica',\n",
       "       'Arundinaria_Simonii', 'Alnus_Cordata', 'Arundinaria_Simonii',\n",
       "       'Acer_Capillipes', 'Quercus_Kewensis', 'Acer_Palmatum',\n",
       "       'Quercus_Agrifolia', 'Quercus_Agrifolia', 'Tilia_Tomentosa',\n",
       "       'Liriodendron_Tulipifera', 'Magnolia_Heptapeta',\n",
       "       'Quercus_Dolicholepis', 'Acer_Mono', 'Cornus_Macrophylla',\n",
       "       'Crataegus_Monogyna', 'Liquidambar_Styraciflua',\n",
       "       'Cotinus_Coggygria', 'Quercus_x_Turneri', 'Acer_Capillipes',\n",
       "       'Quercus_Castaneifolia', 'Ilex_Cornuta', 'Lithocarpus_Edulis',\n",
       "       'Acer_Circinatum', 'Populus_Grandidentata', 'Acer_Rubrum',\n",
       "       'Tilia_Platyphyllos', 'Quercus_Cerris', 'Lithocarpus_Edulis',\n",
       "       'Cercis_Siliquastrum', 'Quercus_Agrifolia', 'Quercus_Pubescens',\n",
       "       'Quercus_Suber', 'Quercus_Pontica', 'Ilex_Aquifolium',\n",
       "       'Celtis_Koraiensis', 'Lithocarpus_Cleistocarpus',\n",
       "       'Acer_Saccharinum', 'Magnolia_Salicifolia', 'Quercus_Crassifolia',\n",
       "       'Fagus_Sylvatica', 'Quercus_Trojana', 'Quercus_Afares',\n",
       "       'Quercus_Palustris', 'Quercus_Imbricaria', 'Eucalyptus_Urnigera',\n",
       "       'Quercus_Ilex', 'Acer_Circinatum', 'Phildelphus',\n",
       "       'Quercus_Crassipes', 'Cornus_Controversa', 'Quercus_Hartwissiana',\n",
       "       'Quercus_Variabilis', 'Quercus_x_Turneri', 'Populus_Nigra',\n",
       "       'Quercus_Chrysolepis', 'Betula_Austrosinensis', 'Acer_Mono',\n",
       "       'Eucalyptus_Glaucescens', 'Alnus_Rubra', 'Viburnum_Tinus',\n",
       "       'Populus_Adenopoda', 'Quercus_Pyrenaica', 'Eucalyptus_Neglecta',\n",
       "       'Quercus_Pubescens', 'Morus_Nigra', 'Quercus_x_Turneri',\n",
       "       'Quercus_Imbricaria', 'Quercus_Crassipes', 'Eucalyptus_Urnigera',\n",
       "       'Acer_Pictum', 'Alnus_Rubra', 'Quercus_Dolicholepis', 'Acer_Opalus',\n",
       "       'Quercus_Trojana', 'Quercus_Suber', 'Acer_Platanoids',\n",
       "       'Quercus_Vulcanica', 'Acer_Palmatum', 'Lithocarpus_Cleistocarpus',\n",
       "       'Quercus_Chrysolepis', 'Quercus_Variabilis', 'Magnolia_Heptapeta',\n",
       "       'Quercus_Palustris', 'Quercus_Crassipes', 'Acer_Platanoids',\n",
       "       'Quercus_Pyrenaica', 'Alnus_Viridis', 'Fagus_Sylvatica',\n",
       "       'Zelkova_Serrata', 'Magnolia_Salicifolia', 'Betula_Pendula',\n",
       "       'Quercus_Agrifolia', 'Betula_Austrosinensis', 'Olea_Europaea',\n",
       "       'Quercus_Ellipsoidalis', 'Quercus_x_Hispanica',\n",
       "       'Lithocarpus_Cleistocarpus', 'Quercus_Kewensis',\n",
       "       'Quercus_x_Hispanica', 'Quercus_Palustris', 'Quercus_Shumardii',\n",
       "       'Quercus_Rubra', 'Alnus_Viridis', 'Liquidambar_Styraciflua',\n",
       "       'Cotinus_Coggygria', 'Acer_Pictum', 'Magnolia_Heptapeta',\n",
       "       'Acer_Rufinerve', 'Acer_Saccharinum', 'Crataegus_Monogyna',\n",
       "       'Populus_Adenopoda', 'Quercus_Crassifolia', 'Alnus_Sieboldiana',\n",
       "       'Alnus_Viridis', 'Quercus_Rhysophylla', 'Alnus_Sieboldiana',\n",
       "       'Quercus_Shumardii', 'Quercus_x_Turneri', 'Callicarpa_Bodinieri',\n",
       "       'Quercus_Crassifolia', 'Quercus_Rubra', 'Tilia_Oliveri',\n",
       "       'Quercus_Agrifolia', 'Populus_Grandidentata', 'Quercus_Rubra',\n",
       "       'Morus_Nigra', 'Quercus_Agrifolia', 'Eucalyptus_Urnigera',\n",
       "       'Alnus_Viridis', 'Liquidambar_Styraciflua', 'Populus_Nigra',\n",
       "       'Cercis_Siliquastrum', 'Acer_Rufinerve', 'Acer_Platanoids',\n",
       "       'Tilia_Oliveri', 'Lithocarpus_Edulis', 'Magnolia_Salicifolia',\n",
       "       'Arundinaria_Simonii', 'Ginkgo_Biloba', 'Betula_Pendula',\n",
       "       'Tilia_Platyphyllos', 'Quercus_Palustris', 'Tilia_Oliveri',\n",
       "       'Cytisus_Battandieri', 'Quercus_Rubra', 'Arundinaria_Simonii',\n",
       "       'Castanea_Sativa', 'Quercus_Crassifolia', 'Cercis_Siliquastrum',\n",
       "       'Lithocarpus_Edulis', 'Liriodendron_Tulipifera',\n",
       "       'Pterocarya_Stenoptera', 'Quercus_Pontica', 'Quercus_Imbricaria',\n",
       "       'Ulmus_Bergmanniana', 'Fagus_Sylvatica', 'Quercus_Texana',\n",
       "       'Populus_Grandidentata', 'Betula_Austrosinensis', 'Quercus_Trojana',\n",
       "       'Quercus_Ellipsoidalis', 'Quercus_Shumardii', 'Olea_Europaea',\n",
       "       'Cornus_Chinensis', 'Quercus_Pontica', 'Quercus_Brantii',\n",
       "       'Arundinaria_Simonii', 'Populus_Adenopoda', 'Prunus_Avium',\n",
       "       'Quercus_Chrysolepis', 'Tilia_Tomentosa', 'Quercus_Pyrenaica',\n",
       "       'Betula_Pendula', 'Ginkgo_Biloba', 'Cornus_Macrophylla',\n",
       "       'Arundinaria_Simonii', 'Tilia_Platyphyllos', 'Cornus_Macrophylla',\n",
       "       'Quercus_Shumardii', 'Quercus_Coccinea', 'Populus_Nigra',\n",
       "       'Alnus_Rubra', 'Quercus_Agrifolia', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Semecarpifolia', 'Quercus_Nigra', 'Quercus_Kewensis',\n",
       "       'Betula_Austrosinensis', 'Acer_Mono', 'Quercus_Ellipsoidalis',\n",
       "       'Quercus_Trojana', 'Quercus_Castaneifolia', 'Alnus_Rubra',\n",
       "       'Quercus_Brantii', 'Acer_Circinatum', 'Quercus_Imbricaria',\n",
       "       'Acer_Capillipes', 'Acer_Mono', 'Liriodendron_Tulipifera',\n",
       "       'Olea_Europaea', 'Alnus_Cordata', 'Acer_Saccharinum',\n",
       "       'Quercus_Alnifolia', 'Quercus_Coccinea', 'Acer_Platanoids',\n",
       "       'Cornus_Chinensis', 'Quercus_x_Hispanica', 'Fagus_Sylvatica',\n",
       "       'Quercus_Agrifolia', 'Lithocarpus_Cleistocarpus', 'Phildelphus',\n",
       "       'Quercus_Pubescens', 'Salix_Intergra', 'Cornus_Macrophylla',\n",
       "       'Quercus_x_Hispanica', 'Viburnum_Tinus', 'Populus_Grandidentata',\n",
       "       'Ginkgo_Biloba', 'Zelkova_Serrata', 'Liriodendron_Tulipifera',\n",
       "       'Quercus_Ilex', 'Prunus_X_Shmittii', 'Quercus_Phillyraeoides',\n",
       "       'Quercus_Phillyraeoides', 'Quercus_Semecarpifolia',\n",
       "       'Quercus_Cerris', 'Morus_Nigra', 'Cercis_Siliquastrum',\n",
       "       'Cotinus_Coggygria', 'Cytisus_Battandieri',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Callicarpa_Bodinieri',\n",
       "       'Populus_Adenopoda', 'Populus_Grandidentata',\n",
       "       'Magnolia_Salicifolia', 'Quercus_Shumardii',\n",
       "       'Quercus_Ellipsoidalis', 'Celtis_Koraiensis',\n",
       "       'Liquidambar_Styraciflua', 'Acer_Capillipes', 'Acer_Rufinerve',\n",
       "       'Cytisus_Battandieri', 'Cotinus_Coggygria',\n",
       "       'Liquidambar_Styraciflua', 'Quercus_Coccinea', 'Quercus_Crassipes',\n",
       "       'Cercis_Siliquastrum', 'Lithocarpus_Cleistocarpus',\n",
       "       'Eucalyptus_Neglecta', 'Acer_Platanoids', 'Castanea_Sativa',\n",
       "       'Quercus_Rubra', 'Quercus_Afares', 'Quercus_Canariensis',\n",
       "       'Lithocarpus_Cleistocarpus', 'Tilia_Platyphyllos',\n",
       "       'Ilex_Aquifolium', 'Populus_Nigra', 'Quercus_Semecarpifolia',\n",
       "       'Quercus_Coccinea', 'Eucalyptus_Neglecta', 'Phildelphus',\n",
       "       'Acer_Capillipes', 'Cornus_Controversa', 'Betula_Pendula',\n",
       "       'Lithocarpus_Edulis', 'Quercus_Ilex', 'Lithocarpus_Edulis',\n",
       "       'Salix_Fragilis', 'Betula_Pendula', 'Cotinus_Coggygria',\n",
       "       'Fagus_Sylvatica', 'Quercus_Hartwissiana', 'Alnus_Cordata',\n",
       "       'Crataegus_Monogyna', 'Quercus_x_Hispanica', 'Quercus_Coccifera',\n",
       "       'Olea_Europaea', 'Populus_Nigra', 'Cornus_Macrophylla',\n",
       "       'Ulmus_Bergmanniana', 'Tilia_Platyphyllos', 'Acer_Rufinerve',\n",
       "       'Quercus_Brantii', 'Ginkgo_Biloba', 'Alnus_Viridis',\n",
       "       'Alnus_Cordata', 'Tilia_Tomentosa', 'Acer_Rufinerve',\n",
       "       'Acer_Rufinerve', 'Quercus_Greggii', 'Populus_Adenopoda',\n",
       "       'Quercus_Pontica', 'Eucalyptus_Urnigera',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Cornus_Chinensis',\n",
       "       'Alnus_Maximowiczii', 'Quercus_Infectoria_sub', 'Quercus_Cerris',\n",
       "       'Salix_Intergra', 'Viburnum_Tinus', 'Betula_Austrosinensis',\n",
       "       'Phildelphus', 'Quercus_Chrysolepis', 'Sorbus_Aria',\n",
       "       'Cornus_Macrophylla', 'Eucalyptus_Glaucescens', 'Quercus_Texana',\n",
       "       'Salix_Intergra', 'Quercus_Greggii', 'Quercus_Crassipes',\n",
       "       'Tilia_Oliveri', 'Eucalyptus_Glaucescens', 'Quercus_Variabilis',\n",
       "       'Quercus_Nigra', 'Populus_Grandidentata', 'Quercus_Vulcanica',\n",
       "       'Ilex_Cornuta', 'Acer_Rubrum', 'Rhododendron_x_Russellianum',\n",
       "       'Salix_Fragilis', 'Quercus_Crassipes', 'Crataegus_Monogyna',\n",
       "       'Rhododendron_x_Russellianum', 'Morus_Nigra', 'Populus_Nigra',\n",
       "       'Acer_Rufinerve', 'Sorbus_Aria', 'Morus_Nigra', 'Alnus_Viridis',\n",
       "       'Zelkova_Serrata', 'Eucalyptus_Glaucescens', 'Crataegus_Monogyna',\n",
       "       'Liriodendron_Tulipifera', 'Quercus_Nigra', 'Quercus_Pontica',\n",
       "       'Acer_Rubrum', 'Quercus_Alnifolia', 'Quercus_Nigra',\n",
       "       'Olea_Europaea', 'Quercus_Ilex', 'Cornus_Chinensis',\n",
       "       'Alnus_Sieboldiana', 'Populus_Adenopoda', 'Sorbus_Aria',\n",
       "       'Quercus_Brantii', 'Cornus_Chinensis', 'Betula_Austrosinensis',\n",
       "       'Magnolia_Salicifolia', 'Magnolia_Salicifolia',\n",
       "       'Eucalyptus_Glaucescens', 'Quercus_Nigra', 'Acer_Platanoids',\n",
       "       'Quercus_Crassifolia', 'Ulmus_Bergmanniana', 'Cornus_Controversa',\n",
       "       'Betula_Austrosinensis', 'Quercus_Afares', 'Eucalyptus_Neglecta',\n",
       "       'Pterocarya_Stenoptera', 'Acer_Saccharinum', 'Callicarpa_Bodinieri',\n",
       "       'Quercus_Castaneifolia', 'Quercus_Ellipsoidalis',\n",
       "       'Quercus_Crassifolia', 'Castanea_Sativa', 'Eucalyptus_Glaucescens',\n",
       "       'Eucalyptus_Urnigera', 'Fagus_Sylvatica', 'Quercus_Vulcanica',\n",
       "       'Quercus_Ilex', 'Rhododendron_x_Russellianum',\n",
       "       'Quercus_Ellipsoidalis', 'Quercus_Trojana', 'Quercus_Greggii',\n",
       "       'Viburnum_Tinus', 'Alnus_Sieboldiana', 'Ilex_Cornuta',\n",
       "       'Cytisus_Battandieri', 'Ulmus_Bergmanniana',\n",
       "       'Liriodendron_Tulipifera', 'Quercus_Phellos', 'Eucalyptus_Neglecta',\n",
       "       'Sorbus_Aria', 'Cornus_Chinensis', 'Quercus_Hartwissiana',\n",
       "       'Quercus_Palustris', 'Quercus_Ilex', 'Alnus_Maximowiczii',\n",
       "       'Ginkgo_Biloba', 'Acer_Mono', 'Quercus_Pubescens',\n",
       "       'Magnolia_Heptapeta', 'Acer_Pictum', 'Lithocarpus_Cleistocarpus',\n",
       "       'Quercus_Imbricaria', 'Quercus_Suber', 'Quercus_Castaneifolia',\n",
       "       'Quercus_Crassipes', 'Quercus_Chrysolepis', 'Quercus_Suber',\n",
       "       'Quercus_Texana', 'Quercus_Ellipsoidalis', 'Quercus_Castaneifolia',\n",
       "       'Quercus_Canariensis', 'Liquidambar_Styraciflua',\n",
       "       'Quercus_x_Hispanica', 'Cotinus_Coggygria', 'Cornus_Macrophylla',\n",
       "       'Viburnum_Tinus', 'Alnus_Cordata', 'Quercus_Coccifera',\n",
       "       'Quercus_Coccinea', 'Eucalyptus_Glaucescens', 'Salix_Fragilis',\n",
       "       'Quercus_Canariensis', 'Quercus_Alnifolia', 'Quercus_Vulcanica',\n",
       "       'Quercus_Infectoria_sub', 'Quercus_Kewensis', 'Acer_Rufinerve',\n",
       "       'Magnolia_Heptapeta', 'Ulmus_Bergmanniana', 'Magnolia_Heptapeta',\n",
       "       'Quercus_Texana', 'Prunus_X_Shmittii', 'Quercus_Pontica',\n",
       "       'Quercus_Alnifolia', 'Quercus_Pontica', 'Quercus_Castaneifolia',\n",
       "       'Acer_Saccharinum', 'Prunus_Avium', 'Quercus_Variabilis',\n",
       "       'Sorbus_Aria', 'Alnus_Rubra', 'Viburnum_Tinus', 'Quercus_Texana',\n",
       "       'Quercus_Greggii', 'Acer_Rubrum', 'Magnolia_Salicifolia',\n",
       "       'Quercus_Phillyraeoides', 'Quercus_Rhysophylla',\n",
       "       'Alnus_Maximowiczii', 'Liriodendron_Tulipifera',\n",
       "       'Quercus_Infectoria_sub', 'Cornus_Controversa',\n",
       "       'Eucalyptus_Glaucescens', 'Populus_Nigra', 'Quercus_Pubescens',\n",
       "       'Phildelphus', 'Acer_Mono', 'Alnus_Maximowiczii', 'Prunus_Avium',\n",
       "       'Quercus_Brantii', 'Quercus_Cerris', 'Quercus_Dolicholepis',\n",
       "       'Quercus_Dolicholepis', 'Quercus_Shumardii', 'Quercus_Cerris',\n",
       "       'Eucalyptus_Urnigera', 'Acer_Opalus', 'Rhododendron_x_Russellianum',\n",
       "       'Lithocarpus_Cleistocarpus', 'Ilex_Aquifolium',\n",
       "       'Quercus_Phillyraeoides', 'Quercus_Pyrenaica',\n",
       "       'Cercis_Siliquastrum', 'Acer_Pictum', 'Quercus_Pyrenaica',\n",
       "       'Quercus_x_Turneri', 'Quercus_Infectoria_sub', 'Quercus_Trojana',\n",
       "       'Quercus_Dolicholepis', 'Quercus_Chrysolepis', 'Prunus_Avium',\n",
       "       'Castanea_Sativa', 'Rhododendron_x_Russellianum', 'Viburnum_Tinus',\n",
       "       'Olea_Europaea', 'Cornus_Controversa', 'Populus_Adenopoda',\n",
       "       'Quercus_x_Turneri', 'Quercus_Texana', 'Pterocarya_Stenoptera',\n",
       "       'Quercus_Ellipsoidalis', 'Cornus_Macrophylla', 'Tilia_Tomentosa',\n",
       "       'Quercus_Kewensis', 'Quercus_Canariensis', 'Acer_Pictum',\n",
       "       'Quercus_Semecarpifolia', 'Phildelphus', 'Alnus_Rubra',\n",
       "       'Quercus_Afares', 'Acer_Pictum', 'Quercus_Alnifolia',\n",
       "       'Tilia_Oliveri', 'Acer_Palmatum', 'Quercus_Variabilis',\n",
       "       'Acer_Circinatum', 'Ilex_Aquifolium', 'Pterocarya_Stenoptera',\n",
       "       'Crataegus_Monogyna', 'Callicarpa_Bodinieri', 'Populus_Adenopoda',\n",
       "       'Alnus_Sieboldiana', 'Cornus_Macrophylla', 'Quercus_Phillyraeoides',\n",
       "       'Salix_Fragilis', 'Quercus_Rubra', 'Quercus_Imbricaria',\n",
       "       'Morus_Nigra', 'Alnus_Maximowiczii', 'Populus_Nigra',\n",
       "       'Prunus_Avium', 'Quercus_Kewensis', 'Acer_Capillipes',\n",
       "       'Callicarpa_Bodinieri', 'Zelkova_Serrata', 'Populus_Adenopoda',\n",
       "       'Quercus_Vulcanica', 'Eucalyptus_Neglecta', 'Quercus_Brantii',\n",
       "       'Acer_Circinatum', 'Populus_Grandidentata', 'Acer_Opalus',\n",
       "       'Acer_Saccharinum', 'Alnus_Sieboldiana', 'Acer_Mono',\n",
       "       'Quercus_Ilex', 'Quercus_Coccinea', 'Quercus_Semecarpifolia',\n",
       "       'Acer_Platanoids', 'Betula_Pendula', 'Phildelphus',\n",
       "       'Quercus_Trojana', 'Crataegus_Monogyna', 'Acer_Circinatum',\n",
       "       'Alnus_Rubra', 'Pterocarya_Stenoptera', 'Quercus_Palustris',\n",
       "       'Salix_Fragilis', 'Quercus_Coccifera', 'Tilia_Platyphyllos',\n",
       "       'Magnolia_Heptapeta', 'Olea_Europaea', 'Arundinaria_Simonii',\n",
       "       'Lithocarpus_Edulis', 'Quercus_Castaneifolia',\n",
       "       'Arundinaria_Simonii', 'Tilia_Platyphyllos', 'Acer_Palmatum',\n",
       "       'Salix_Intergra', 'Rhododendron_x_Russellianum',\n",
       "       'Quercus_Castaneifolia', 'Magnolia_Salicifolia',\n",
       "       'Quercus_Castaneifolia', 'Betula_Pendula', 'Ilex_Cornuta',\n",
       "       'Tilia_Tomentosa', 'Quercus_Chrysolepis', 'Tilia_Oliveri',\n",
       "       'Quercus_Suber', 'Crataegus_Monogyna', 'Quercus_Crassifolia',\n",
       "       'Salix_Fragilis', 'Pterocarya_Stenoptera', 'Salix_Fragilis',\n",
       "       'Eucalyptus_Urnigera', 'Quercus_Hartwissiana', 'Quercus_Coccifera',\n",
       "       'Acer_Palmatum', 'Castanea_Sativa', 'Acer_Palmatum',\n",
       "       'Quercus_Pyrenaica', 'Quercus_Pontica', 'Quercus_Palustris',\n",
       "       'Cercis_Siliquastrum', 'Quercus_Canariensis', 'Alnus_Sieboldiana',\n",
       "       'Betula_Austrosinensis', 'Quercus_Phellos',\n",
       "       'Quercus_Infectoria_sub', 'Quercus_Dolicholepis',\n",
       "       'Quercus_Crassipes', 'Cotinus_Coggygria', 'Quercus_Phellos',\n",
       "       'Acer_Rubrum', 'Alnus_Rubra', 'Callicarpa_Bodinieri',\n",
       "       'Quercus_Rhysophylla', 'Salix_Intergra', 'Quercus_Dolicholepis',\n",
       "       'Alnus_Viridis', 'Acer_Opalus', 'Quercus_Rubra',\n",
       "       'Quercus_Hartwissiana', 'Lithocarpus_Cleistocarpus',\n",
       "       'Cytisus_Battandieri', 'Quercus_Afares', 'Ulmus_Bergmanniana',\n",
       "       'Zelkova_Serrata', 'Quercus_Crassifolia', 'Quercus_Phellos',\n",
       "       'Quercus_Coccifera', 'Lithocarpus_Edulis', 'Quercus_x_Turneri',\n",
       "       'Tilia_Platyphyllos', 'Castanea_Sativa', 'Acer_Rubrum',\n",
       "       'Quercus_Trojana', 'Quercus_Afares', 'Acer_Opalus', 'Sorbus_Aria',\n",
       "       'Quercus_Rhysophylla', 'Acer_Rubrum', 'Quercus_Greggii',\n",
       "       'Quercus_Crassipes', 'Quercus_Kewensis', 'Cornus_Controversa',\n",
       "       'Quercus_Pyrenaica', 'Quercus_Hartwissiana', 'Prunus_X_Shmittii',\n",
       "       'Morus_Nigra', 'Tilia_Oliveri', 'Celtis_Koraiensis', 'Sorbus_Aria',\n",
       "       'Callicarpa_Bodinieri', 'Quercus_Nigra', 'Acer_Saccharinum',\n",
       "       'Acer_Saccharinum', 'Eucalyptus_Neglecta', 'Quercus_Vulcanica',\n",
       "       'Quercus_Imbricaria', 'Acer_Capillipes', 'Liquidambar_Styraciflua',\n",
       "       'Zelkova_Serrata', 'Sorbus_Aria', 'Salix_Intergra',\n",
       "       'Fagus_Sylvatica', 'Quercus_Brantii', 'Magnolia_Heptapeta',\n",
       "       'Cornus_Macrophylla', 'Quercus_Vulcanica', 'Viburnum_Tinus',\n",
       "       'Betula_Pendula', 'Acer_Rubrum', 'Alnus_Maximowiczii',\n",
       "       'Viburnum_Tinus', 'Magnolia_Heptapeta', 'Quercus_Cerris',\n",
       "       'Salix_Intergra', 'Quercus_Semecarpifolia', 'Populus_Grandidentata',\n",
       "       'Quercus_Greggii', 'Viburnum_x_Rhytidophylloides', 'Morus_Nigra',\n",
       "       'Castanea_Sativa', 'Quercus_Pontica', 'Alnus_Maximowiczii',\n",
       "       'Alnus_Cordata', 'Quercus_Dolicholepis', 'Ulmus_Bergmanniana',\n",
       "       'Eucalyptus_Glaucescens', 'Viburnum_Tinus', 'Alnus_Cordata',\n",
       "       'Acer_Rubrum', 'Quercus_Infectoria_sub', 'Acer_Rubrum',\n",
       "       'Tilia_Platyphyllos', 'Ilex_Cornuta', 'Olea_Europaea',\n",
       "       'Quercus_Infectoria_sub', 'Morus_Nigra', 'Alnus_Viridis',\n",
       "       'Cornus_Chinensis', 'Quercus_Coccifera', 'Alnus_Rubra',\n",
       "       'Quercus_Palustris', 'Cytisus_Battandieri', 'Zelkova_Serrata',\n",
       "       'Quercus_Phellos', 'Sorbus_Aria', 'Acer_Opalus', 'Phildelphus',\n",
       "       'Castanea_Sativa', 'Quercus_Crassipes', 'Quercus_Pubescens',\n",
       "       'Celtis_Koraiensis', 'Quercus_Suber', 'Quercus_Ellipsoidalis',\n",
       "       'Quercus_Imbricaria', 'Quercus_Cerris', 'Crataegus_Monogyna',\n",
       "       'Prunus_Avium', 'Alnus_Maximowiczii', 'Fagus_Sylvatica',\n",
       "       'Quercus_Chrysolepis', 'Quercus_Dolicholepis', 'Quercus_Ilex',\n",
       "       'Castanea_Sativa', 'Quercus_Pubescens',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Tilia_Tomentosa',\n",
       "       'Alnus_Sieboldiana', 'Quercus_Pubescens', 'Ulmus_Bergmanniana',\n",
       "       'Ginkgo_Biloba', 'Quercus_Afares', 'Viburnum_x_Rhytidophylloides',\n",
       "       'Quercus_Alnifolia', 'Quercus_x_Turneri', 'Ginkgo_Biloba',\n",
       "       'Acer_Opalus', 'Prunus_Avium', 'Quercus_Rhysophylla',\n",
       "       'Prunus_X_Shmittii', 'Ilex_Aquifolium', 'Quercus_Phillyraeoides',\n",
       "       'Quercus_Greggii', 'Pterocarya_Stenoptera',\n",
       "       'Quercus_Infectoria_sub', 'Phildelphus', 'Tilia_Tomentosa',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Infectoria_sub', 'Prunus_Avium',\n",
       "       'Quercus_Texana', 'Acer_Mono', 'Eucalyptus_Urnigera',\n",
       "       'Cornus_Controversa', 'Ilex_Aquifolium', 'Ilex_Cornuta',\n",
       "       'Quercus_Ilex', 'Ilex_Aquifolium', 'Liquidambar_Styraciflua',\n",
       "       'Rhododendron_x_Russellianum', 'Quercus_Infectoria_sub',\n",
       "       'Cytisus_Battandieri', 'Quercus_x_Turneri', 'Quercus_Canariensis',\n",
       "       'Quercus_Semecarpifolia', 'Ilex_Cornuta', 'Quercus_Imbricaria',\n",
       "       'Quercus_Hartwissiana', 'Callicarpa_Bodinieri', 'Acer_Palmatum',\n",
       "       'Crataegus_Monogyna', 'Eucalyptus_Urnigera', 'Quercus_Alnifolia',\n",
       "       'Quercus_x_Hispanica', 'Acer_Capillipes', 'Eucalyptus_Neglecta',\n",
       "       'Quercus_Shumardii', 'Quercus_Imbricaria', 'Ulmus_Bergmanniana',\n",
       "       'Magnolia_Heptapeta', 'Cotinus_Coggygria', 'Quercus_Nigra',\n",
       "       'Quercus_Coccifera', 'Liquidambar_Styraciflua',\n",
       "       'Cytisus_Battandieri', 'Betula_Pendula', 'Lithocarpus_Edulis',\n",
       "       'Sorbus_Aria', 'Alnus_Sieboldiana', 'Cornus_Controversa',\n",
       "       'Quercus_Rhysophylla', 'Quercus_Semecarpifolia',\n",
       "       'Quercus_Rhysophylla', 'Cornus_Chinensis', 'Pterocarya_Stenoptera',\n",
       "       'Zelkova_Serrata', 'Prunus_X_Shmittii', 'Populus_Nigra',\n",
       "       'Prunus_X_Shmittii', 'Acer_Pictum', 'Quercus_Ellipsoidalis',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Quercus_Shumardii',\n",
       "       'Quercus_Brantii', 'Celtis_Koraiensis', 'Cotinus_Coggygria',\n",
       "       'Quercus_Rubra', 'Alnus_Cordata', 'Quercus_Hartwissiana',\n",
       "       'Ilex_Aquifolium', 'Morus_Nigra', 'Quercus_Vulcanica',\n",
       "       'Salix_Intergra', 'Zelkova_Serrata', 'Viburnum_x_Rhytidophylloides',\n",
       "       'Quercus_Palustris', 'Ulmus_Bergmanniana', 'Quercus_Alnifolia',\n",
       "       'Acer_Opalus', 'Eucalyptus_Neglecta', 'Quercus_Kewensis',\n",
       "       'Quercus_Agrifolia', 'Quercus_Nigra', 'Cytisus_Battandieri',\n",
       "       'Cornus_Chinensis', 'Ilex_Cornuta', 'Acer_Platanoids',\n",
       "       'Prunus_X_Shmittii', 'Quercus_Phellos', 'Cercis_Siliquastrum',\n",
       "       'Salix_Fragilis', 'Betula_Pendula', 'Viburnum_x_Rhytidophylloides',\n",
       "       'Quercus_Phellos', 'Quercus_Shumardii', 'Alnus_Cordata',\n",
       "       'Quercus_Chrysolepis', 'Quercus_Greggii', 'Tilia_Oliveri',\n",
       "       'Lithocarpus_Edulis', 'Arundinaria_Simonii',\n",
       "       'Quercus_Phillyraeoides', 'Quercus_x_Turneri',\n",
       "       'Quercus_Phillyraeoides', 'Prunus_X_Shmittii', 'Olea_Europaea',\n",
       "       'Quercus_Texana', 'Ilex_Aquifolium', 'Quercus_Cerris',\n",
       "       'Acer_Opalus', 'Olea_Europaea', 'Acer_Circinatum',\n",
       "       'Quercus_Brantii', 'Quercus_Castaneifolia', 'Salix_Intergra',\n",
       "       'Castanea_Sativa', 'Acer_Platanoids', 'Eucalyptus_Urnigera',\n",
       "       'Quercus_x_Hispanica', 'Quercus_Greggii', 'Pterocarya_Stenoptera',\n",
       "       'Acer_Mono', 'Acer_Rufinerve', 'Populus_Grandidentata',\n",
       "       'Quercus_Pyrenaica', 'Tilia_Oliveri', 'Acer_Capillipes',\n",
       "       'Cornus_Controversa', 'Quercus_Kewensis', 'Quercus_Coccinea',\n",
       "       'Quercus_Shumardii', 'Salix_Intergra', 'Ginkgo_Biloba',\n",
       "       'Acer_Pictum', 'Quercus_Coccinea', 'Quercus_Vulcanica',\n",
       "       'Salix_Fragilis', 'Tilia_Tomentosa', 'Populus_Grandidentata',\n",
       "       'Prunus_X_Shmittii', 'Quercus_x_Hispanica', 'Quercus_Suber',\n",
       "       'Alnus_Viridis', 'Acer_Palmatum', 'Quercus_Rhysophylla',\n",
       "       'Quercus_Cerris', 'Quercus_Texana', 'Acer_Mono',\n",
       "       'Quercus_Vulcanica', 'Quercus_Nigra', 'Rhododendron_x_Russellianum',\n",
       "       'Acer_Capillipes', 'Quercus_Pubescens', 'Alnus_Viridis',\n",
       "       'Quercus_x_Hispanica', 'Quercus_Suber',\n",
       "       'Viburnum_x_Rhytidophylloides', 'Quercus_Nigra', 'Quercus_Phellos',\n",
       "       'Ilex_Cornuta', 'Magnolia_Salicifolia', 'Acer_Pictum',\n",
       "       'Alnus_Maximowiczii', 'Quercus_Rubra', 'Quercus_Afares'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(data['species'])   # To obtain the original species names from the numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,2:]\n",
    "y = data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(n_estimators=100,learning_rate=0.15,max_depth=1,min_samples_leaf=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set: 0.775253\n",
      "accuracy on test set: 0.338384\n"
     ]
    }
   ],
   "source": [
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"accuracy on training set: %f\" % gbrt.score(X_train, y_train))\n",
    "print(\"accuracy on test set: %f\" % gbrt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred = clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "        print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\"\n",
    "    if show_classification_report:\n",
    "        print \"Classification report\"\n",
    "        print metrics.classification_report(y, y_pred),\"\\n\"\n",
    "      \n",
    "    if show_confusion_matrix:\n",
    "        print \"Confusion matrix\"\n",
    "        print metrics.confusion_matrix(y, y_pred),\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.338 \n",
      "\n",
      "Confusion matrix\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 1]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(X_test, y_test, gbrt, show_confusion_matrix=True, show_classification_report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "#print data.head(2)\n",
    "X = data.iloc[:,2:]\n",
    "y = data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred = clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "         print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\"\n",
    "    if show_classification_report:\n",
    "        print \"Classification report\"\n",
    "        print metrics.classification_report(y, y_pred),\"\\n\"\n",
    "      \n",
    "    if show_confusion_matrix:\n",
    "        print \"Confusion matrix\"\n",
    "        print metrics.confusion_matrix(y, y_pred),\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using grid search to optimize the gamma, C, and kernel parameters of SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#SVM = SVC(kernel='linear', C=1, gamma=1) \n",
    "\n",
    "\n",
    "SVM = SVC() \n",
    "\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "gs = GridSearchCV(SVM, tuned_parameters, verbose=1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:   10.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 22.9 ms, total: 12.7 s\n",
      "Wall time: 12.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   12.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'C': 100, 'kernel': 'linear'}, 0.93434343434343436)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time _ = gs.fit(X_train, y_train)\n",
    "\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_SVC = SVC(kernel='linear',C=100)\n",
    "\n",
    "optimized_SVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.939 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(X_test, y_test, optimized_SVC, show_confusion_matrix=False, show_classification_report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = optimized_SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93939393939393945"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With support vector machines, we are able to obtain an accuracy of 93.94%. This is better than random forest, but not as good as linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "### Preprocess the data to make a binary value for whether a sample is in the maple family or not\n",
    "\n",
    "maple = ['Acer_Capillipes',\n",
    "         'Acer_Circinatum', \n",
    "         'Acer_Mono', \n",
    "         'Acer_Opalus', \n",
    "         'Acer_Palmatum',\n",
    "         'Acer_Pictum', \n",
    "         'Acer_Platanoids',\n",
    "         'Acer_Rubrum',\n",
    "         'Acer_Rufinerve',\n",
    "         'Acer_Saccharinum']\n",
    "\n",
    "maple_binary = []\n",
    "\n",
    "for i in range(len(data)):        #For each row of the data\n",
    "    if data.iloc[i,1] in maple:   #If the species is in the maple family\n",
    "        maple_binary.append(1)    #Append the binary list with a 1 for 'maple'\n",
    "    else:\n",
    "        maple_binary.append(0)    #Append the binary list with 0 for 'not maple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maple_binaryDF = pd.DataFrame(maple_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binaryDF = pd.concat([data, maple_binaryDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([       u'id',   u'species',   u'margin1',   u'margin2',   u'margin3',\n",
       "         u'margin4',   u'margin5',   u'margin6',   u'margin7',   u'margin8',\n",
       "       ...\n",
       "       u'texture56', u'texture57', u'texture58', u'texture59', u'texture60',\n",
       "       u'texture61', u'texture62', u'texture63', u'texture64',            0],\n",
       "      dtype='object', length=195)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binaryDF = binaryDF.rename(columns={ 0 : 'maple'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SGD_logisticDF = binaryDF.iloc[:,2:195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "      <th>maple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "0  0.007812  0.023438  0.023438  0.003906  0.011719  0.009766  0.027344   \n",
       "1  0.005859  0.000000  0.031250  0.015625  0.025391  0.001953  0.019531   \n",
       "2  0.005859  0.009766  0.019531  0.007812  0.003906  0.005859  0.068359   \n",
       "\n",
       "   margin8   margin9  margin10  ...    texture56  texture57  texture58  \\\n",
       "0      0.0  0.001953  0.033203  ...          0.0   0.002930   0.002930   \n",
       "1      0.0  0.000000  0.007812  ...          0.0   0.000000   0.000977   \n",
       "2      0.0  0.000000  0.044922  ...          0.0   0.005859   0.000977   \n",
       "\n",
       "   texture59  texture60  texture61  texture62  texture63  texture64  maple  \n",
       "0   0.035156        0.0        0.0   0.004883   0.000000   0.025391      1  \n",
       "1   0.023438        0.0        0.0   0.000977   0.039062   0.022461      0  \n",
       "2   0.007812        0.0        0.0   0.000000   0.020508   0.002930      0  \n",
       "\n",
       "[3 rows x 193 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_logisticDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = SGD_logisticDF.iloc[:,:192]\n",
    "y = SGD_logisticDF.iloc[:,192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "\n",
    "print len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss=\"log\", penalty=\"l2\")   #\"log\" loss here is for logisitc regression\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-30.76135, -29.51078,  -1.18862,  -0.32186,   9.79891, -45.60056,\n",
       "         11.11175,  -7.66087,  60.22561,  -4.26151, -16.46279,  -1.00166,\n",
       "        -24.73643,  14.93724,  23.38259, -30.0679 ,  -0.07179,   8.43622,\n",
       "         16.31602,   2.35551, -15.78583, -13.16674,   3.00028,  34.57936,\n",
       "          4.98946,  24.76629,  10.87953,   2.82099,  36.11771, -19.24321,\n",
       "         25.16041,  36.83558,  26.25927,   8.51686, -26.8601 , -15.49195,\n",
       "        -19.36943,  -2.94937,  17.62645,  -9.92373,  22.56127,   6.16294,\n",
       "         -8.33438,  -2.65717,  14.24523,  15.98599,   2.01038,  -0.09782,\n",
       "         14.99629, -15.56265, -27.38744,  32.04595, -15.85495,  25.10375,\n",
       "          1.67364,   0.35034,  -6.83723,  36.41177,  17.29232,  11.32819,\n",
       "         37.84671, -27.06719,  17.65002,  -3.55392,   1.53704,   5.35837,\n",
       "         12.60524,   8.88949,   3.80764,  -4.28164,   2.36689,  19.58683,\n",
       "         27.94282,  19.559  ,  11.90183,  -0.70916, -10.12015, -20.57253,\n",
       "        -28.28183, -29.06331, -22.20339, -16.15456, -15.93576, -15.46691,\n",
       "         -6.89352,   3.83704,   7.89379,   5.00893,   9.29385,   3.41436,\n",
       "         -8.16646, -11.30676, -13.82593, -13.43346, -25.23133, -26.77259,\n",
       "        -20.99835,  -7.86115,   3.95007,   3.17149,   3.37305,  -4.74309,\n",
       "         -8.98937,  -3.14897,   2.7718 ,   1.41535,   2.86055,   4.17845,\n",
       "         -5.25985, -10.81618, -14.09817, -12.54291,  -5.57682,  -4.41758,\n",
       "         -2.56642,  -6.40237,  -4.07279,  -4.33755,  -1.85988,   7.66675,\n",
       "          2.05212,   3.8234 ,   2.64073,  11.45519,   7.50208,   3.93426,\n",
       "         -1.16869,   0.84612,  40.99038,   9.75327, -21.03166, -42.13396,\n",
       "         81.46991, -43.39825,  21.44135,  27.63521,  67.52277,  19.74126,\n",
       "        -20.39739,  -1.86349,  -3.00559, -18.6353 , -14.37438, -44.45632,\n",
       "         25.66898,  -4.75726,  12.82057,  13.7176 , -15.36502, -66.63792,\n",
       "        -40.39607, -51.36768, -22.34309, -15.87625, -27.782  , -28.49885,\n",
       "         17.70628, -27.35909,   7.14542,  14.43604,  16.23238, -13.08755,\n",
       "         -1.3786 , -16.64974,  10.01002, -38.4867 , -22.26898,  28.79523,\n",
       "         39.4897 , -37.02085,  17.7418 ,  24.68107,  -5.72172, -25.72945,\n",
       "         19.33685,  20.22212, -44.39909,   7.56936, -19.97121, -33.72089,\n",
       "        -46.33949,  29.57069,  68.11663,  11.83236,  -8.72294, -48.95233,\n",
       "         -2.40926, -30.22562, -27.79822, -23.89821, -54.14568,  10.27371]])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-630.97932])"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-610.27347, -612.57901, -626.118  , -619.56127, -625.55312,\n",
       "       -637.60107, -642.1907 , -634.42971, -627.50804, -619.68191,\n",
       "       -617.35223, -623.8103 , -616.04574, -636.25065, -637.50082,\n",
       "       -633.04812, -640.68896, -626.45105, -618.65489, -625.25689,\n",
       "       -629.92531, -634.41172, -615.08909, -623.09216, -643.27301,\n",
       "       -632.45961, -627.6684 , -651.19382, -613.41649, -606.16055,\n",
       "       -631.34133, -633.33816, -636.6595 , -627.97386, -614.26702,\n",
       "       -629.93235, -647.54873, -607.8192 , -626.66727, -618.75687,\n",
       "       -622.7678 , -612.39395, -631.23153, -650.23034, -624.33444,\n",
       "       -636.92741, -625.09424, -633.43987, -629.55691, -612.54644,\n",
       "       -627.69531, -619.01962, -626.12075, -626.73796, -625.20119,\n",
       "       -629.03996, -635.16086, -632.65539, -634.60553, -620.31176,\n",
       "       -625.40065, -630.30861, -616.92122, -627.08344, -619.96178,\n",
       "       -634.07268, -615.23944, -621.03996, -625.12534, -651.57115,\n",
       "       -656.85703, -645.33646, -649.14445, -650.90415, -626.73542,\n",
       "       -632.63191, -625.26213, -621.29261, -617.3841 , -645.61092,\n",
       "       -632.52971, -617.29375, -645.096  , -636.28565, -623.34482,\n",
       "       -627.27151, -622.2794 , -659.84826, -629.55282, -639.47035,\n",
       "       -616.13618, -630.21202, -612.04588, -653.11306, -645.0357 ,\n",
       "       -641.57307, -643.62832, -637.28837, -628.94921, -640.85203,\n",
       "       -625.99277, -655.20601, -620.52023, -630.81493, -616.07718,\n",
       "       -630.58215, -648.77802, -646.04041, -628.12842, -633.15758,\n",
       "       -636.19849, -620.9248 , -639.0863 , -628.81377, -638.98915,\n",
       "       -627.12337, -616.88168, -629.28136, -625.68069, -630.32468,\n",
       "       -650.16042, -604.09191, -630.01862, -631.84532, -614.33258,\n",
       "       -638.08904, -613.20409, -635.44178, -634.81172, -639.63198,\n",
       "       -628.78845, -642.38439, -618.63927, -638.62528, -633.85301,\n",
       "       -632.72129, -622.00134, -658.91058, -634.54056, -638.72523,\n",
       "       -616.69837, -634.88389, -630.98695, -632.06229, -610.19356,\n",
       "       -620.91968, -618.49608, -623.92992, -647.57895, -631.41261,\n",
       "       -623.60031, -611.79772, -617.58099, -646.99143, -631.12006,\n",
       "       -630.33705, -633.46359, -629.94736, -601.4633 , -617.34879,\n",
       "       -632.03718, -641.12265, -607.67224, -644.46327, -640.06382,\n",
       "       -644.34458, -631.64065, -620.73033, -623.07349, -624.00292,\n",
       "       -625.94307, -620.51782, -601.86363, -629.84832, -632.16151,\n",
       "       -630.32209, -620.53377, -632.82226, -628.25875, -624.89045,\n",
       "       -616.31677, -628.82866, -640.09999, -623.87861, -623.90353,\n",
       "       -613.59535, -626.23406, -631.63855, -617.61137, -644.02574,\n",
       "       -617.01981, -654.10523, -643.22122, -622.79173, -631.34231,\n",
       "       -632.39047, -633.43556, -646.56378])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred = clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "         print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\"\n",
    "    if show_classification_report:\n",
    "        print \"Classification report\"\n",
    "        print metrics.classification_report(y, y_pred),\"\\n\"\n",
    "      \n",
    "    if show_confusion_matrix:\n",
    "        print \"Confusion matrix\"\n",
    "        print metrics.confusion_matrix(y, y_pred),\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.884 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94       175\n",
      "          1       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.78      0.88      0.83       198\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(X_test, y_test, clf, show_confusion_matrix=False, show_classification_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using grid search with logistic regression and stochastic gradient descent with the train and test data from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "logistic_SGD = SGDClassifier() \n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'alpha': np.linspace(0.0001,0.001,10),\n",
    "                     'l1_ratio': np.linspace(0.01,0.2,10),\n",
    "                     'loss': ['hinge','log'],\n",
    "                     'penalty': ['l1','l2']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(logistic_SGD, tuned_parameters, verbose=1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_SGD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = logistic_SGD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred = clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "         print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\"\n",
    "    if show_classification_report:\n",
    "        print \"Classification report\"\n",
    "        print metrics.classification_report(y, y_pred),\"\\n\"\n",
    "      \n",
    "    if show_confusion_matrix:\n",
    "        print \"Confusion matrix\"\n",
    "        print metrics.confusion_matrix(y, y_pred),\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.924 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       175\n",
      "          1       1.00      0.35      0.52        23\n",
      "\n",
      "avg / total       0.93      0.92      0.91       198\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(X_test, y_test, logistic_SGD, show_confusion_matrix=False, show_classification_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data analysis report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Attempted analyses:\n",
    "1) KMeans Clustering without normalization\n",
    "\n",
    "2) KMeans clustering with normalized and PCA dimensionality-reduced data\n",
    "\n",
    "3) LDA classification model built by hand\n",
    "\n",
    "4) LDA classification model via scikit-learn\n",
    "\n",
    "5) Decision Trees Classification with grid search\n",
    "\n",
    "6) Random Forest Classification\n",
    "\n",
    "7) Gradient boosted regression trees\n",
    "\n",
    "8) Support Vector Machines Classification with grid search\n",
    "\n",
    "9) Classification via scikit-learn with logistic regression with stochastic gradient descent\n",
    "\n",
    "10) Classification via scikit-learn with stochastic gradient descent and grid search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodologies:\n",
    "\n",
    "Decision trees with grid search:\n",
    "\n",
    "parameters = {\n",
    "    'criterion': ['entropy','gini'],\n",
    "    'max_depth': np.linspace(1, 10, 10),\n",
    "    'min_samples_leaf': np.linspace(1, 20, 10),\n",
    "    'min_samples_split': np.linspace(2, 10, 5)\n",
    "}\n",
    "    \n",
    "\n",
    "\n",
    "Support vector machines with grid search:\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Logistic regression via scikit-learn with stochastic gradient descent\n",
    "\n",
    "parameters = [{'loss' : 'log',\n",
    "                'penanlty' : 'l2'}]\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "Classification via scikit-learn with with stochastic gradient descent\n",
    "\n",
    "tuned_parameters = [{'alpha': np.linspace(0.0001,0.001,10),\n",
    "                     'l1_ratio': np.linspace(0.01,0.2,10),\n",
    "                     'loss': ['hinge','log'],\n",
    "                     'penalty': ['l1','l2']}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results:\n",
    "1) KMeans Clustering without normalization\n",
    "\n",
    "Completeness score = 0.7616, Homogeneity score = 0.2854\n",
    "\n",
    "2) KMeans clustering with normalized and PCA dimensionality-reduced data\n",
    "\n",
    "Completeness score = 0.7576, Homogeneity score = 0.2827, #Dimensions = 32, \n",
    "\n",
    "reduced from initial 192, Cumulative % of variance = 0.9045 on 32 dimensions\n",
    "\n",
    "3) LDA classification model built by hand\n",
    "\n",
    "\n",
    "4) LDA classification model via scikit-learn\n",
    "\n",
    "Completeness score = 0.9829, Homogeneity score = 0.9830\n",
    "\n",
    "Overall accuracy = 0.98 +- 0.03\n",
    "\n",
    "5) Decision Trees Classification with grid search\n",
    "\n",
    "Classification accuracy = 0.611\n",
    "\n",
    "6) Random Forest Classification\n",
    "\n",
    "Classification accuracy = 0.803\n",
    "\n",
    "7) Gradient boosted regression trees\n",
    "\n",
    "Training classification accuracy = 0.775253\n",
    "Test classification accuracy = 0.338384\n",
    "\n",
    "8) Support Vector Machines Classification with grid search\n",
    "\n",
    "Classification accuracy = 0.9393\n",
    "\n",
    "9) Logistic regression classification via scikit-learn with stochastic gradient descent\n",
    "\n",
    "Classification accuracy = 0.884\n",
    "\n",
    "10) Classification via scikit-learn with stochastic gradient descent AND grid search\n",
    "\n",
    "Classification accuracy = 0.924\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis summary/ takeaways\n",
    "\n",
    "After trying KMeans clustering on the leaf classification dataset, we learned that we can accomplish very similar completeness and homogeneity scores whether we preprocess the data via PCA and normalization or not. Because the completeness score was fairly high (~0.762), we deduce that most of the points in a given species were assigned to the same cluster. However, because the homogeneity score was fairly low (~0.285), we deduce that the clusters contained more than one species of tree in each cluster.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "There were 8 classification algorithms applied to the dataset to see which one had the highest classification accuracy as measured using the test data with the model trained on the training data. The best model was the linear discriminant analysis, with a classification score of  ~98%. This means that the data were linearly separable, and the model was robust enough to have high predictive validity when applied to unseen data instances. The next most accurate classifiers were support vector machines (~93.93%) and stochastic gradient descent with grid search (~92.4%). In this case, the grid search selected \"hinge\" as the loss method parameter over 'log' for logistic regression. \n",
    "\n",
    "The result that we obtained with linear discriminant analysis was very impressive, and it suggests that tree leaves can be very successfully classified into their respective species by using machine learning algorithms. This could potentially be very beneficial for botany, ecology, and environmental conservationist workers, who may need to classify a species of tree leaves to determine if the species is invasive and needs to be cut down from the forest to allow for healthier growth of native flora.\n",
    "\n",
    "Some of the grid search methods offered significant improvements over the base models, but testing a large set of parameter values can take a very long time. If I had more time to exhaustively search for an optimal set of parameters, I think I could have obtained a very promising result with support vector machines or stochastic gradient descent. \n",
    "\n",
    "Something that I would like to have tried but did not have time to perform was XGBoost. I was unable to load it into python and didn't have time to figure out why it was not able to import properly, but I would like to have been able to perform grid search using XGBoost on the data for classification purposes to see how good of a result I could obtain. This package in python allows for parallel computation, so the model would take less time to run. In some of my classifers, I waited about 2 hours for them to run grid search and I still did not obtain a result, so I had to reduce the number of parameter values specified in the grid search so that the model would finish in less than approx. 15 minutes.\n",
    "\n",
    "Of course, the result of 98% via linear discriminant analysis is very good, and there is not much room left for improvement after that.\n",
    "\n",
    "Something interesting that I noted during the analysis was that the gradient boosted regression trees model was very overfit. I would like to experiment with pre-pruning of that model to see if I could minimize the accuracy loss on the test data instances. One of the most rewarding things that I learned in this project was that fine-tuning the parameters can make a very big difference in your results, and there is an art form to model and feature selection. If I had more time to work on the project, I would like to have performed some feature extraction and also to have interpreted the practical significance of the attributes. The kaggle dataset did not offer much information on why the different measurements were divided into 64 different attributes, and I don't know much about computer vision or working with binary image data, so I would have enjoyed learning more about how these tree leaves were processed into the dataset to run these classifers.\n",
    "\n",
    "\n",
    "The most challenging aspect of this project for me was performing the manual model construction for linear discriminant analysis. I ran into a Type Error each time I tried to run the script to compute the within-class scatter matrix. When I tested the code out on different permutations of values and using integers instead of matrices, I was able to run the code without any errors, but it seemed that python had some issue with me trying to add the dot product of the mean vector and data vector to the scatter matrix. I enjoyed learning more about what these models do \"under the hood\", so to speak. I have come to appreciate the convenience of using scikit learn to run these applications, and I amazed at how quickly some of these models can be run on large datasets."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
